Directory structure:
└── samwit-smolagents_examples/
    ├── README.md
    ├── requirements.txt
    ├── smol_blogwriter.py
    ├── smol_claude.py
    ├── smol_gradio.py
    ├── smol_multiagent.py
    ├── smol_ollama.py
    ├── smol_toolcalling_agent.py
    ├── smolagent_basic.py
    ├── smolagent_gemini.py
    └── smoltools/
        ├── jinaai.py
        └── visitwebpage.py

================================================
FILE: README.md
================================================
# How to Create Multi-Agents with SmolAgents

This repository contains example code files shown in the video tutorial about creating multi-agent systems using SmolAgents from Hugging Face.

https://youtu.be/XHijkFRd2TU

The examples demonstrate:

1. Basic CodeAgent - Getting started with a simple agent
2. SmolToolCallingAgent - Adding tool-calling capabilities 
3. SmolOllamaAgent - Using local Ollama models
4. SmolClaudeAgent - Integrating with Claude
5. SmolGeminiAgent - Working with Google's Gemini
6. SmolGradioAgent - Creating agent UIs with Gradio
7. SmolTools - Useful tools and utilities
8. SmolMultiAgent - Coordinating multiple agents
9. SmolBlogWriter - Building a blog writing system with agents

Each file shows a different aspect of building multi-agent systems with the SmolAgents library.



================================================
FILE: requirements.txt
================================================
smolagents
ollama
huggingface_hub
litellm
markdownify 
duckduckgo-search
transformers
beautifulsoup4
requests



================================================
FILE: smol_blogwriter.py
================================================
from smolagents import (
    CodeAgent,
    ToolCallingAgent,
    LiteLLMModel,
    ManagedAgent,
    DuckDuckGoSearchTool,
)
from smoltools.jinaai import scrape_page_with_jina_ai, search_facts_with_jina_ai
from dotenv import load_dotenv
import os

load_dotenv()

# Initialize the model
model = LiteLLMModel(model_id="gpt-4o-mini")

# Research Agent
research_agent = ToolCallingAgent(
    tools=[scrape_page_with_jina_ai, search_facts_with_jina_ai, DuckDuckGoSearchTool()],
    model=model,
    max_steps=10,
)

managed_research_agent = ManagedAgent(
    agent=research_agent,
    name="super_researcher",
    description="Researches topics thoroughly using web searches and content scraping. Provide the research topic as input.",
)

# Research Checker Agent
research_checker_agent = ToolCallingAgent(
    tools=[],
    model=model
)

managed_research_checker_agent = ManagedAgent(
    agent=research_checker_agent,
    name="research_checker",
    description="Checks the research for relevance to the original task request. If the research is not relevant, it will ask for more research.",
)

# Writer Agent
writer_agent = ToolCallingAgent(
    tools=[],
    model=model
)

managed_writer_agent = ManagedAgent(
    agent=writer_agent,
    name="writer",
    description="Writes blog posts based on the checkedresearch. Provide the research findings and desired tone/style.",
)

# Copy Editor Agent
copy_editor_agent = ToolCallingAgent(
    tools=[],
    model=model
)

managed_copy_editor = ManagedAgent(
    agent=copy_editor_agent,
    name="editor",
    description="Reviews and polishes the blog post based on the research and original task request. Order the final blog post and any lists in a way that is most engaging to someone working in AI. Provides the final, edited version in markdown.",
)

# Main Blog Writer Manager
blog_manager = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[managed_research_agent, managed_research_checker_agent, managed_writer_agent, managed_copy_editor],
    additional_authorized_imports=["re"],

    # system_prompt="""You are a blog post creation manager. Coordinate between research, writing, and editing teams.
    # Follow these steps:
    # 1. Use research_agent to gather information
    # 2. Pass research to research_checker_agent to check for relevance
    # 3. Pass research to writer_agent to create the initial draft
    # 4. Send draft to editor for final polish
    # 4. Save the final markdown file
    # """
)

def write_blog_post(topic, output_file="blog_post.md"):
    """
    Creates a blog post on the given topic using multiple agents
    
    Args:
        topic (str): The blog post topic or title
        output_file (str): The filename to save the markdown post
    """
    result = blog_manager.run(f"""Create a blog post about: {topic}
    1. First, research the topic thoroughly, focus on specific products and sources
    2. Then, write an engaging blog post not just a list
    3. Finally, edit and polish the content
    """)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(result)
    print(f"Blog post has been saved to {output_file}")
    
    return result

# print(blog_manager.system_prompt_template)
topic = "Create a blog post about the top 5 products released at CES 2025 so far. Please include specific product names and sources"
print(topic)
write_blog_post(topic)




================================================
FILE: smol_claude.py
================================================
from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel, PythonInterpreterTool, tool, TOOL_CALLING_SYSTEM_PROMPT
from typing import Optional
import os

from dotenv import load_dotenv
load_dotenv()

model = LiteLLMModel(model_id="claude-3-5-sonnet-20240620",
                     api_key=os.getenv("ANTHROPIC_API_KEY"))


@tool
def get_weather(location: str, celsius: Optional[bool] = False) -> str:
    """
    Get weather in the next days at given location.
    Args:
        location: the location
        celsius: whether to use Celsius for temperature
    """
    return f"The weather in {location} is sunny with temperatures around 7°C."

# agent = ToolCallingAgent(tools=[get_weather], model=model)


agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)
answer = agent.run("What is the weather in Tokyo?")
print(answer)


================================================
FILE: smol_gradio.py
================================================
from smolagents import (
    load_tool,
    CodeAgent,
    HfApiModel,
    GradioUI
)

# Import tool from Hub
image_generation_tool = load_tool("m-ric/text-to-image", trust_remote_code=True)

model = HfApiModel()

# Initialize the agent with the image generation tool
agent = CodeAgent(tools=[image_generation_tool], model=model)

GradioUI(agent).launch()


================================================
FILE: smol_multiagent.py
================================================
import re
from smolagents import (
CodeAgent,
ToolCallingAgent,
HfApiModel,
ManagedAgent,
DuckDuckGoSearchTool,
LiteLLMModel,
tool
)
from smoltools.jinaai import scrape_page_with_jina_ai, search_facts_with_jina_ai
import os
from dotenv import load_dotenv

load_dotenv()


# model = HfApiModel()
model = LiteLLMModel(model_id="gpt-4o-mini")
# model = LiteLLMModel(model_id="gemini/gemini-2.0-flash-exp")

web_agent = ToolCallingAgent(
    tools=[DuckDuckGoSearchTool(), scrape_page_with_jina_ai],
    model=model,
    max_steps=10,
)

managed_web_agent = ManagedAgent(
    agent=web_agent,
    name="search",
    description="Runs web searches for you. Give it your query as an argument.",
)

manager_agent = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[managed_web_agent],
    additional_authorized_imports=["time", "numpy", "pandas"],
)

# answer = manager_agent.run("What year was the movie 'Rebel Without a Cause' released and who was the star of it?")
answer = manager_agent.run("What movie was released in 1955 that stars James Dean and what is it's Rotten Tomatoes score?")

print(answer)


================================================
FILE: smol_ollama.py
================================================
from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel, PythonInterpreterTool, tool
from typing import Optional

# model = LiteLLMModel(model_id="ollama/qwen2.5-coder:7b")

model = LiteLLMModel(
    model_id="ollama_chat/llama3.2:3b",
    api_base="http://localhost:11434",  # Adjust if using a remote server
    api_key="openai_should_release_more_open_models"  # Replace with your API key if required
)

@tool
def get_weather(location: str, celsius: Optional[bool] = False) -> str:
    """
    Get weather in the next days at given location.
    Args:
        location: the location
        celsius: whether to use Celsius for temperature
    """
    return f"The weather in {location} is sunny with temperatures around 25°C."

agent = ToolCallingAgent(tools=[get_weather], model=model)


# agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model, additional_authorized_imports=["requests", "re"])

answer = agent.run("What is the weather in Tokyo?")
print(answer)


================================================
FILE: smol_toolcalling_agent.py
================================================
from smolagents import ToolCallingAgent, HfApiModel, DuckDuckGoSearchTool

model = HfApiModel(model_id="Qwen/Qwen2.5-Coder-32B-Instruct")

agent = ToolCallingAgent(tools=[DuckDuckGoSearchTool()], model=model)

answer = agent.run("Could you get me the title of the page at url 'https://huggingface.co/blog'?")
print(answer)


================================================
FILE: smolagent_basic.py
================================================
from smolagents import CodeAgent, HfApiModel
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get API key from environment variables
api_key = os.getenv("HF_TOKEN")


model = HfApiModel(model_id="Qwen/Qwen2.5-Coder-32B-Instruct")
agent = CodeAgent(tools=[], model=model)
answer = agent.run("What is the cube of 2?")
print(answer)


================================================
FILE: smolagent_gemini.py
================================================
from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel, PythonInterpreterTool, tool, TOOL_CALLING_SYSTEM_PROMPT
from typing import Optional
import os

from dotenv import load_dotenv
load_dotenv()

model = LiteLLMModel(model_id="gemini/gemini-2.0-flash-exp",
                     api_key=os.getenv("GEMINI_API_KEY"))



@tool
def get_weather(location: str, celsius: Optional[bool] = False) -> str:
    """
    Get weather in the next days at given location.
    Args:
        location: the location
        celsius: whether to use Celsius for temperature
    """
    return f"The weather in {location} is sunny with temperatures around 7°C."

agent = ToolCallingAgent(tools=[get_weather], model=model, system_prompt=TOOL_CALLING_SYSTEM_PROMPT)


# agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model, additional_authorized_imports=["requests", "bs4"])
answer = agent.run("What is the weather in Tokyo?")
print(answer)


================================================
FILE: smoltools/jinaai.py
================================================
import os
import requests
from requests.exceptions import RequestException
import datetime
from dotenv import load_dotenv
from smolagents import tool

load_dotenv()

headers = {'Authorization': 'Bearer ' + os.getenv('JINA_API_KEY')}

@tool
def scrape_page_with_jina_ai(url: str) -> str:
    """Scrapes content from a webpage using Jina AI's web scraping service.

    Args:
        url: The URL of the webpage to scrape. Must be a valid web address to extract content from.

    Returns:
        str: The scraped content in markdown format.
    """
    print(f"Scraping Jina AI..: {url}")
    # response = requests.get("https://r.jina.ai/" + url, headers=headers)
    response = requests.get("https://r.jina.ai/" + url)
    
    markdown_content = response.text

    return markdown_content

@tool
def search_facts_with_jina_ai(query: str) -> str:
    """Searches for facts and information using Jina AI's search service.

    Args:
        query: The search query string used to find relevant facts and information.

    Returns:
        str: The search results in markdown format containing relevant facts and information.
    """
    print(f"Searching Jina AI..: {query}")   
    # response = requests.get("https://s.jina.ai/" + query, headers=headers)
    response = requests.get("https://s.jina.ai/" + query)
    markdown_content = response.text

    return markdown_content


================================================
FILE: smoltools/visitwebpage.py
================================================
import requests
from requests.exceptions import RequestException
from markdownify import markdownify
import re

def visit_webpage(url: str) -> str:
    """Visits a webpage at the given URL and returns its content as a markdown string.

    Args:
        url: The URL of the webpage to visit.

    Returns:
        The content of the webpage converted to Markdown, or an error message if the request fails.
    """
    try:
        # Send a GET request to the URL
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for bad status codes

        # Convert the HTML content to Markdown
        markdown_content = markdownify(response.text).strip()

        # Remove multiple line breaks
        markdown_content = re.sub(r"\n{3,}", "\n\n", markdown_content)

        return markdown_content

    except RequestException as e:
        return f"Error fetching the webpage: {str(e)}"
    except Exception as e:
        return f"An unexpected error occurred: {str(e)}"

