Directory structure:
└── prefecthq-controlflow/
    ├── README.md
    ├── LICENSE
    ├── MANIFEST.in
    ├── mypy.ini
    ├── pyproject.toml
    ├── requirements-dev.lock
    ├── requirements.lock
    ├── .pre-commit-config.yaml
    ├── .python-version
    ├── docs/
    │   ├── installation.mdx
    │   ├── mint.json
    │   ├── quickstart.mdx
    │   ├── script.js
    │   ├── style.css
    │   ├── welcome.mdx
    │   ├── assets/
    │   │   └── code.css
    │   ├── blog/
    │   │   ├── agentic-loop.mdx
    │   │   └── tasks-and-agents.mdx
    │   ├── concepts/
    │   │   ├── agents.mdx
    │   │   ├── concepts.mdx
    │   │   ├── flows.mdx
    │   │   └── tasks.mdx
    │   ├── examples/
    │   │   ├── agent-engineer.mdx
    │   │   ├── anonymization.mdx
    │   │   ├── call-routing.mdx
    │   │   ├── code-explanation.mdx
    │   │   ├── generate-people.mdx
    │   │   ├── headline-categorization.mdx
    │   │   ├── language-tutor.mdx
    │   │   ├── named-entity-recognition.mdx
    │   │   ├── pineapple-pizza.mdx
    │   │   ├── rock-paper-scissors.mdx
    │   │   ├── seinfeld-conversation.mdx
    │   │   ├── sentiment-classifier.mdx
    │   │   ├── standardize-addresses.mdx
    │   │   ├── summarization.mdx
    │   │   ├── translation.mdx
    │   │   └── features/
    │   │       ├── dependent-tasks.mdx
    │   │       ├── early-termination.mdx
    │   │       ├── memory.mdx
    │   │       ├── multi-llm.mdx
    │   │       ├── private-flows.mdx
    │   │       └── tools.mdx
    │   ├── glossary/
    │   │   ├── agentic-workflows.mdx
    │   │   ├── agents.mdx
    │   │   ├── cf-agent.mdx
    │   │   ├── cf-flow.mdx
    │   │   ├── cf-task.mdx
    │   │   ├── dependencies.mdx
    │   │   ├── fine-tuning.mdx
    │   │   ├── flow-engineering.mdx
    │   │   ├── flow-orchestration.mdx
    │   │   ├── glossary.mdx
    │   │   ├── llm.mdx
    │   │   ├── prompt-engineering.mdx
    │   │   ├── task-orchestration.mdx
    │   │   ├── tools.mdx
    │   │   └── workflow.mdx
    │   ├── guides/
    │   │   ├── configure-llms.mdx
    │   │   ├── default-agent.mdx
    │   │   ├── default-memory.mdx
    │   │   └── settings.mdx
    │   ├── llm-guides/
    │   │   ├── examples-guide.md
    │   │   ├── llm-guide.md
    │   │   └── style-guide.md
    │   ├── patterns/
    │   │   ├── dependencies.mdx
    │   │   ├── history.mdx
    │   │   ├── instructions.mdx
    │   │   ├── interactivity.mdx
    │   │   ├── memory.mdx
    │   │   ├── planning.mdx
    │   │   ├── running-tasks.mdx
    │   │   ├── streaming.mdx
    │   │   ├── task-results.mdx
    │   │   └── tools.mdx
    │   └── snippets/
    │       └── version-badge.mdx
    ├── examples/
    │   ├── anonymization.py
    │   ├── asyncpg-memory.py
    │   ├── call_routing.py
    │   ├── code_explanation.py
    │   ├── early_termination.py
    │   ├── generate_people.py
    │   ├── headline_categorization.py
    │   ├── language_tutor.py
    │   ├── memory.py
    │   ├── named_entity_recognition.py
    │   ├── pg-memory.py
    │   ├── pineapple_pizza.py
    │   ├── private_flows.py
    │   ├── reasoning.py
    │   ├── rock_paper_scissors.py
    │   ├── seinfeld.py
    │   ├── sentiment_classifier.py
    │   ├── standardize_addresses.py
    │   ├── summarization.py
    │   ├── translation.py
    │   └── slackbot/
    │       ├── __init__.py
    │       ├── agents.py
    │       ├── custom_types.py
    │       ├── Dockerfile
    │       ├── main.py
    │       ├── moderation.py
    │       ├── requirements.txt
    │       ├── settings.py
    │       └── tools.py
    ├── src/
    │   └── controlflow/
    │       ├── __init__.py
    │       ├── decorators.py
    │       ├── defaults.py
    │       ├── instructions.py
    │       ├── plan.py
    │       ├── run.py
    │       ├── settings.py
    │       ├── stream.py
    │       ├── agents/
    │       │   ├── __init__.py
    │       │   ├── agent.py
    │       │   └── names.py
    │       ├── cli/
    │       │   ├── dev.py
    │       │   └── main.py
    │       ├── events/
    │       │   ├── __init__.py
    │       │   ├── base.py
    │       │   ├── events.py
    │       │   ├── history.py
    │       │   ├── message_compiler.py
    │       │   ├── orchestrator_events.py
    │       │   └── task_events.py
    │       ├── flows/
    │       │   ├── __init__.py
    │       │   ├── flow.py
    │       │   └── graph.py
    │       ├── handlers/
    │       │   ├── __init__.py
    │       │   ├── callback_handler.py
    │       │   ├── print_handler.py
    │       │   └── queue_handler.py
    │       ├── llm/
    │       │   ├── __init__.py
    │       │   ├── messages.py
    │       │   ├── models.py
    │       │   └── rules.py
    │       ├── memory/
    │       │   ├── __init__.py
    │       │   ├── async_memory.py
    │       │   ├── memory.py
    │       │   └── providers/
    │       │       ├── __init__.py
    │       │       ├── chroma.py
    │       │       ├── lance.py
    │       │       └── postgres.py
    │       ├── orchestration/
    │       │   ├── __init__.py
    │       │   ├── conditions.py
    │       │   ├── handler.py
    │       │   ├── orchestrator.py
    │       │   ├── prompt_templates.py
    │       │   ├── turn_strategies.py
    │       │   └── prompt_templates/
    │       │       ├── agent.jinja
    │       │       ├── flow.jinja
    │       │       ├── instructions.jinja
    │       │       ├── llm_instructions.jinja
    │       │       ├── memories.jinja
    │       │       ├── task.jinja
    │       │       ├── tasks.jinja
    │       │       └── tools.jinja
    │       ├── planning/
    │       │   └── __init__.py
    │       ├── tasks/
    │       │   ├── __init__.py
    │       │   ├── task.py
    │       │   └── validators.py
    │       ├── tools/
    │       │   ├── __init__.py
    │       │   ├── code.py
    │       │   ├── filesystem.py
    │       │   ├── input.py
    │       │   ├── tools.py
    │       │   └── web.py
    │       ├── tui/
    │       │   ├── __init__.py
    │       │   ├── app.py
    │       │   ├── app.tcss
    │       │   ├── basic.py
    │       │   ├── task.py
    │       │   ├── test.py
    │       │   ├── test2.py
    │       │   └── thread.py
    │       └── utilities/
    │           ├── __init__.py
    │           ├── asyncio.py
    │           ├── context.py
    │           ├── general.py
    │           ├── jinja.py
    │           ├── logging.py
    │           ├── marvin.py
    │           ├── prefect.py
    │           ├── rich.py
    │           ├── tasks.py
    │           └── testing.py
    ├── tests/
    │   ├── __init__.py
    │   ├── conftest.py
    │   ├── test_decorator.py
    │   ├── test_defaults.py
    │   ├── test_instructions.py
    │   ├── test_planning.py
    │   ├── test_run.py
    │   ├── test_settings.py
    │   ├── agents/
    │   │   ├── __init__.py
    │   │   └── test_agents.py
    │   ├── ai_tests/
    │   │   ├── __init__.py
    │   │   └── test_tasks.py
    │   ├── cli/
    │   │   ├── __init__.py
    │   │   └── test_cli.py
    │   ├── deprecated/
    │   │   ├── __init__.py
    │   │   ├── test_agent.py
    │   │   └── test_task.py
    │   ├── events/
    │   │   ├── __init__.py
    │   │   └── test_history.py
    │   ├── fixtures/
    │   │   ├── __init__.py
    │   │   ├── controlflow.py
    │   │   └── instructions.py
    │   ├── flows/
    │   │   ├── __init__.py
    │   │   ├── test_flows.py
    │   │   ├── test_graph.py
    │   │   └── test_sign_guestbook.py
    │   ├── llm/
    │   │   ├── __init__.py
    │   │   └── test_models.py
    │   ├── memory/
    │   │   ├── __init__.py
    │   │   └── test_memory.py
    │   ├── orchestration/
    │   │   ├── __init__.py
    │   │   ├── test_orchestrator.py
    │   │   ├── test_rules.py
    │   │   └── test_turn_strategies.py
    │   ├── tasks/
    │   │   ├── __init__.py
    │   │   ├── test_tasks.py
    │   │   └── test_validators.py
    │   ├── tools/
    │   │   ├── test_lc_tools.py
    │   │   └── test_tools.py
    │   └── utilities/
    │       ├── __init__.py
    │       ├── test_general.py
    │       └── test_testing.py
    └── .github/
        ├── ai-labeler.yml
        ├── labeler.yml
        ├── release.yml
        ├── ISSUE_TEMPLATE/
        │   ├── bug.yml
        │   └── enhancement.yml
        └── workflows/
            ├── ai-labeler.yml
            ├── codeql.yml
            ├── labeler.yml
            ├── publish-pypi.yml
            ├── run-tests.yml
            └── static-analysis.yml

================================================
FILE: README.md
================================================
![ControlFlow Banner](https://github.com/PrefectHQ/ControlFlow/blob/main/docs/assets/brand/controlflow_banner.png)

# ControlFlow

**ControlFlow is a Python framework for building agentic AI workflows.**

ControlFlow provides a structured, developer-focused framework for defining workflows and delegating work to LLMs, without sacrificing control or transparency:

- Create discrete, observable [tasks](https://controlflow.ai/concepts/tasks) for an AI to work on.
- Assign one or more specialized AI [agents](https://controlflow.ai/concepts/agents) to each task.
- Combine tasks into a [flow](https://controlflow.ai/concepts/flows) to orchestrate more complex behaviors.
## Example

The simplest ControlFlow workflow has one task, a default agent, and automatic thread management:

```python
import controlflow as cf

result = cf.run("Write a short poem about artificial intelligence")

print(result)
```
**Result:**
```
In circuits and code, a mind does bloom,
With algorithms weaving through the gloom.
A spark of thought in silicon's embrace,
Artificial intelligence finds its place.
```
## Why ControlFlow?

ControlFlow addresses the challenges of building AI-powered applications that are both powerful and predictable:

- 🧩 [**Task-Centric Architecture**](https://controlflow.ai/concepts/tasks): Break complex AI workflows into manageable, observable steps.
- 🔒 [**Structured Results**](https://controlflow.ai/patterns/task-results): Bridge the gap between AI and traditional software with type-safe, validated outputs.
- 🤖 [**Specialized Agents**](https://controlflow.ai/concepts/agents): Deploy task-specific AI agents for efficient problem-solving.
- 🎛️ [**Flexible Control**](https://controlflow.ai/patterns/instructions): Continuously tune the balance of control and autonomy in your workflows.
- 🕹️ [**Multi-Agent Orchestration**](https://controlflow.ai/concepts/flows): Coordinate multiple AI agents within a single workflow or task.
- 🔍 [**Native Observability**](https://github.com/PrefectHQ/prefect): Monitor and debug your AI workflows with full Prefect 3.0 support.
- 🔗 **Ecosystem Integration**: Seamlessly work with your existing code, tools, and the broader AI ecosystem.


## Installation

Install ControlFlow with `pip`:

```bash
pip install controlflow
```

Next, configure your LLM provider. ControlFlow's default provider is OpenAI, which requires the `OPENAI_API_KEY` environment variable:

```
export OPENAI_API_KEY=your-api-key
```

To use a different LLM provider, [see the LLM configuration docs](https://controlflow.ai/guides/configure-llms).


## Workflow Example

Here's a more involved example that showcases user interaction, a multi-step workflow, and structured outputs:

```python
import controlflow as cf
from pydantic import BaseModel


class ResearchProposal(BaseModel):
    title: str
    abstract: str
    key_points: list[str]


@cf.flow
def research_proposal_flow():

    # Task 1: Get the research topic from the user
    user_input = cf.Task(
        "Work with the user to choose a research topic",
        interactive=True,
    )
    
    # Task 2: Generate a structured research proposal
    proposal = cf.run(
        "Generate a structured research proposal",
        result_type=ResearchProposal,
        depends_on=[user_input]
    )
    
    return proposal


result = research_proposal_flow()

print(result.model_dump_json(indent=2))
```
<details>
<summary><i>Click to see results</i></summary>
</br>

>**Conversation:**
> ```text
> Agent: Hello! I'm here to help you choose a research topic. Do you have 
> any particular area of interest or field you would like to explore? 
> If you have any specific ideas or requirements, please share them as well.
> 
> User: Yes, I'm interested in LLM agentic workflows
> ```
> 
> **Proposal:**
> ```json
> {
>     "title": "AI Agentic Workflows: Enhancing Efficiency and Automation",
>     "abstract": "This research proposal aims to explore the development and implementation of AI agentic workflows to enhance efficiency and automation in various domains. AI agents, equipped with advanced capabilities, can perform complex tasks, make decisions, and interact with other agents or humans to achieve specific goals. This research will investigate the underlying technologies, methodologies, and applications of AI agentic workflows, evaluate their effectiveness, and propose improvements to optimize their performance.",
>     "key_points": [
>         "Introduction: Definition and significance of AI agentic workflows, Historical context and evolution of AI in workflows",
>         "Technological Foundations: AI technologies enabling agentic workflows (e.g., machine learning, natural language processing), Software and hardware requirements for implementing AI workflows",
>         "Methodologies: Design principles for creating effective AI agents, Workflow orchestration and management techniques, Interaction protocols between AI agents and human operators",
>         "Applications: Case studies of AI agentic workflows in various industries (e.g., healthcare, finance, manufacturing), Benefits and challenges observed in real-world implementations",
>         "Evaluation and Metrics: Criteria for assessing the performance of AI agentic workflows, Metrics for measuring efficiency, accuracy, and user satisfaction",
>         "Proposed Improvements: Innovations to enhance the capabilities of AI agents, Strategies for addressing limitations and overcoming challenges",
>         "Conclusion: Summary of key findings, Future research directions and potential impact on industry and society"
>     ]
> }
> ```
</details>

In this example, ControlFlow is automatically managing a `flow`, or a shared context for a series of tasks. You can switch between standard Python functions and agentic tasks at any time, making it easy to incrementally build out complex workflows. 

## Learn More

To dive deeper into ControlFlow:

- [Read the full documentation](https://controlflow.ai)
- [Explore example projects](https://controlflow.ai/examples)
- [Join our community on Slack](https://prefect.io/slack)



================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: MANIFEST.in
================================================
recursive-include controlflow/orchestration/prompt_templates *


================================================
FILE: mypy.ini
================================================
[mypy]
follow_imports=skip
files=src/controlflow/utilities/types.py


================================================
FILE: pyproject.toml
================================================
[project]
name = "controlflow"
dynamic = ["version"]
description = "A framework for building agentic LLM workflows"
authors = [
    { name = "Jeremiah Lowin", email = "153965+jlowin@users.noreply.github.com" },
]
dependencies = [
    "prefect>=3.0",
    "jinja2>=3.1.4",
    "langchain_core>=0.3",
    "langchain_openai>=0.2",
    "langchain-anthropic>=0.2",
    "markdownify>=0.12.1",
    "openai>=1.55.3",
    "pydantic-settings>=2.2.1",
    "textual>=0.61.1",
    "tiktoken>=0.7.0",
    "typer>=0.10",
    "ipython>=8.18.1",
]
readme = "README.md"
requires-python = ">= 3.9"
keywords = [
    "ai",
    "chatbot",
    "llm",
    "ai orchestration",
    "llm orchestration",
    "agentic workflows",
    "flow engineering",
    "prefect",
    "workflow",
    "orchestration",
    "python",
    "GPT",
    "openai",
    "assistant",
    "agents",
    "AI agents",
    "natural language processing",
]

[project.urls]
Code = "https://github.com/PrefectHQ/ControlFlow"

[project.optional-dependencies]
tests = [
    "chromadb",
    "duckduckgo-search",
    "langchain_community",
    "langchain_google_genai",
    "langchain_groq",
    "langchain-ollama",
    "pytest-asyncio>=0.18.2,!=0.22.0,<0.23.0",
    "pytest-env>=0.8,<2.0",
    "pytest-rerunfailures>=10,<14",
    "pytest-sugar>=0.9,<2.0",
    "pytest>=7.0",
    "pytest-timeout",
    "pytest-xdist",
]
dev = [
    "controlflow[tests]",
    "ipython",
    "pdbpp",
    "pre-commit",
    "ruff>=0.3.4",
    "textual-dev",
    "mypy",
]

[project.scripts]
controlflow = "controlflow.cli.main:app"

[build-system]
requires = ["setuptools>=64", "setuptools_scm>=8"]
build-backend = "setuptools.build_meta"

[tool.setuptools_scm]
write_to = "src/controlflow/_version.py"

[tool.rye]
managed = true

# ruff configuration
[tool.ruff]
target-version = "py311"
lint.select = ["I"]                                               # Changed from lint.extend-select to select
lint.dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$" # default, but here in case we want to change it

[tool.ruff.format]
quote-style = "double"
skip-magic-trailing-comma = false

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ['I', 'F401', 'E402']
"conftest.py" = ["F401", "F403"]
'tests/fixtures/*.py' = ['F401', 'F403']
# "src/controlflow/utilities/types.py" = ['F401']

[tool.pytest.ini_options]
timeout = 120
asyncio_mode = "auto"
norecursedirs = [
    "*.egg-info",
    ".git",
    ".mypy_cache",
    ".pytest_cache",
    ".ruff_cache",
    ".vscode",
    "node_modules",
]
testpaths = ["tests"]
env = [
    "CONTROLFLOW_TEST_MODE=1",
    # use 4o-mini for tests by default
    'D:CONTROLFLOW_LLM_MODEL=openai/gpt-4o-mini',
    'D:CONTROLFLOW_TOOLS_VERBOSE=1',
    'D:CONTROLFLOW_ENABLE_DEFAULT_PRINT_HANDLER=0',
    'D:CONTROLFLOW_LOG_LEVEL=DEBUG',
    'D:PREFECT_LOGGING_LEVEL=DEBUG',
]
filterwarnings = [
    "ignore:Type google\\._upb\\._message\\.MessageMapContainer uses PyType_Spec:DeprecationWarning",
    "ignore:Type google\\._upb\\._message\\.ScalarMapContainer uses PyType_Spec:DeprecationWarning",
    "ignore:datetime.datetime.utcfromtimestamp\\(\\) is deprecated:DeprecationWarning",
]



================================================
FILE: requirements-dev.lock
================================================
# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false

-e file:.
aiosqlite==0.20.0
    # via prefect
alembic==1.13.2
    # via prefect
annotated-types==0.7.0
    # via pydantic
anthropic==0.34.1
    # via langchain-anthropic
anyio==4.4.0
    # via anthropic
    # via httpx
    # via openai
    # via prefect
    # via starlette
apprise==1.9.0
    # via prefect
asgi-lifespan==2.1.0
    # via prefect
asyncpg==0.29.0
    # via prefect
attrs==24.2.0
    # via jsonschema
    # via referencing
beautifulsoup4==4.12.3
    # via markdownify
cachetools==5.5.0
    # via prefect
certifi==2024.8.30
    # via apprise
    # via httpcore
    # via httpx
    # via requests
cffi==1.17.0
    # via cryptography
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via apprise
    # via prefect
    # via typer
    # via uvicorn
cloudpickle==3.0.0
    # via prefect
colorama==0.4.6
    # via griffe
coolname==2.2.0
    # via prefect
croniter==3.0.3
    # via prefect
cryptography==43.0.1
    # via prefect
dateparser==1.2.0
    # via prefect
defusedxml==0.7.1
    # via langchain-anthropic
distro==1.9.0
    # via anthropic
    # via openai
docker==7.1.0
    # via prefect
exceptiongroup==1.2.2
    # via prefect
fastapi==0.112.2
    # via prefect
filelock==3.15.4
    # via huggingface-hub
fsspec==2024.6.1
    # via huggingface-hub
    # via prefect
graphviz==0.20.3
    # via prefect
greenlet==3.0.3
    # via sqlalchemy
griffe==1.2.0
    # via prefect
h11==0.14.0
    # via httpcore
    # via uvicorn
h2==4.1.0
    # via httpx
hpack==4.0.0
    # via h2
httpcore==1.0.5
    # via httpx
    # via prefect
httpx==0.27.2
    # via anthropic
    # via langsmith
    # via openai
    # via prefect
huggingface-hub==0.24.6
    # via tokenizers
humanize==4.10.0
    # via jinja2-humanize-extension
    # via prefect
hyperframe==6.0.1
    # via h2
idna==3.8
    # via anyio
    # via httpx
    # via requests
jinja2==3.1.4
    # via controlflow
    # via jinja2-humanize-extension
    # via prefect
jinja2-humanize-extension==0.4.0
    # via prefect
jiter==0.5.0
    # via anthropic
    # via openai
jsonpatch==1.33
    # via langchain-core
    # via prefect
jsonpointer==3.0.0
    # via jsonpatch
jsonschema==4.23.0
    # via prefect
jsonschema-specifications==2023.12.1
    # via jsonschema
langchain-anthropic==0.1.23
    # via controlflow
langchain-core==0.2.38
    # via controlflow
    # via langchain-anthropic
    # via langchain-openai
langchain-openai==0.1.23
    # via controlflow
langsmith==0.1.110
    # via langchain-core
linkify-it-py==2.0.3
    # via markdown-it-py
mako==1.3.5
    # via alembic
markdown==3.7
    # via apprise
markdown-it-py==3.0.0
    # via mdit-py-plugins
    # via rich
    # via textual
markdownify==0.13.1
    # via controlflow
markupsafe==2.1.5
    # via jinja2
    # via mako
mdit-py-plugins==0.4.1
    # via markdown-it-py
mdurl==0.1.2
    # via markdown-it-py
oauthlib==3.2.2
    # via requests-oauthlib
openai==1.43.0
    # via langchain-openai
orjson==3.10.7
    # via langsmith
    # via prefect
packaging==24.1
    # via huggingface-hub
    # via langchain-core
    # via prefect
pathspec==0.12.1
    # via prefect
pendulum==3.0.0
    # via prefect
platformdirs==4.2.2
    # via textual
prefect==3.0.0
    # via controlflow
prometheus-client==0.20.0
    # via prefect
pycparser==2.22
    # via cffi
pydantic==2.8.2
    # via anthropic
    # via fastapi
    # via langchain-core
    # via langsmith
    # via openai
    # via prefect
    # via pydantic-extra-types
    # via pydantic-settings
pydantic-core==2.20.1
    # via prefect
    # via pydantic
pydantic-extra-types==2.9.0
    # via prefect
pydantic-settings==2.4.0
    # via controlflow
    # via prefect
pygments==2.18.0
    # via rich
python-dateutil==2.9.0.post0
    # via croniter
    # via dateparser
    # via pendulum
    # via prefect
    # via time-machine
python-dotenv==1.0.1
    # via pydantic-settings
python-slugify==8.0.4
    # via prefect
pytz==2024.1
    # via croniter
    # via dateparser
    # via prefect
pyyaml==6.0.2
    # via apprise
    # via huggingface-hub
    # via langchain-core
    # via prefect
readchar==4.2.0
    # via prefect
referencing==0.35.1
    # via jsonschema
    # via jsonschema-specifications
regex==2024.7.24
    # via dateparser
    # via tiktoken
requests==2.32.3
    # via apprise
    # via docker
    # via huggingface-hub
    # via langsmith
    # via requests-oauthlib
    # via tiktoken
requests-oauthlib==2.0.0
    # via apprise
rfc3339-validator==0.1.4
    # via prefect
rich==13.8.0
    # via prefect
    # via textual
    # via typer
rpds-py==0.20.0
    # via jsonschema
    # via referencing
ruamel-yaml==0.18.6
    # via prefect
ruamel-yaml-clib==0.2.8
    # via ruamel-yaml
shellingham==1.5.4
    # via typer
six==1.16.0
    # via markdownify
    # via python-dateutil
    # via rfc3339-validator
sniffio==1.3.1
    # via anthropic
    # via anyio
    # via asgi-lifespan
    # via httpx
    # via openai
    # via prefect
soupsieve==2.6
    # via beautifulsoup4
sqlalchemy==2.0.33
    # via alembic
    # via prefect
starlette==0.38.4
    # via fastapi
tenacity==8.5.0
    # via langchain-core
text-unidecode==1.3
    # via python-slugify
textual==0.79.1
    # via controlflow
tiktoken==0.7.0
    # via controlflow
    # via langchain-openai
time-machine==2.15.0
    # via pendulum
tokenizers==0.20.0
    # via anthropic
toml==0.10.2
    # via prefect
tqdm==4.66.5
    # via huggingface-hub
    # via openai
typer==0.12.5
    # via controlflow
    # via prefect
typing-extensions==4.12.2
    # via aiosqlite
    # via alembic
    # via anthropic
    # via fastapi
    # via huggingface-hub
    # via langchain-core
    # via openai
    # via prefect
    # via pydantic
    # via pydantic-core
    # via sqlalchemy
    # via textual
    # via typer
tzdata==2024.1
    # via pendulum
tzlocal==5.2
    # via dateparser
uc-micro-py==1.0.3
    # via linkify-it-py
ujson==5.10.0
    # via prefect
urllib3==2.2.2
    # via docker
    # via requests
uvicorn==0.30.6
    # via prefect
websockets==13.0.1
    # via prefect



================================================
FILE: requirements.lock
================================================
# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false

-e file:.
aiosqlite==0.20.0
    # via prefect
alembic==1.13.2
    # via prefect
annotated-types==0.7.0
    # via pydantic
anthropic==0.34.1
    # via langchain-anthropic
anyio==4.4.0
    # via anthropic
    # via httpx
    # via openai
    # via prefect
    # via starlette
apprise==1.9.0
    # via prefect
asgi-lifespan==2.1.0
    # via prefect
asyncpg==0.29.0
    # via prefect
attrs==24.2.0
    # via jsonschema
    # via referencing
beautifulsoup4==4.12.3
    # via markdownify
cachetools==5.5.0
    # via prefect
certifi==2024.8.30
    # via apprise
    # via httpcore
    # via httpx
    # via requests
cffi==1.17.0
    # via cryptography
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via apprise
    # via prefect
    # via typer
    # via uvicorn
cloudpickle==3.0.0
    # via prefect
colorama==0.4.6
    # via griffe
coolname==2.2.0
    # via prefect
croniter==3.0.3
    # via prefect
cryptography==43.0.1
    # via prefect
dateparser==1.2.0
    # via prefect
defusedxml==0.7.1
    # via langchain-anthropic
distro==1.9.0
    # via anthropic
    # via openai
docker==7.1.0
    # via prefect
exceptiongroup==1.2.2
    # via prefect
fastapi==0.112.2
    # via prefect
filelock==3.15.4
    # via huggingface-hub
fsspec==2024.6.1
    # via huggingface-hub
    # via prefect
graphviz==0.20.3
    # via prefect
greenlet==3.0.3
    # via sqlalchemy
griffe==1.2.0
    # via prefect
h11==0.14.0
    # via httpcore
    # via uvicorn
h2==4.1.0
    # via httpx
hpack==4.0.0
    # via h2
httpcore==1.0.5
    # via httpx
    # via prefect
httpx==0.27.2
    # via anthropic
    # via langsmith
    # via openai
    # via prefect
huggingface-hub==0.24.6
    # via tokenizers
humanize==4.10.0
    # via jinja2-humanize-extension
    # via prefect
hyperframe==6.0.1
    # via h2
idna==3.8
    # via anyio
    # via httpx
    # via requests
jinja2==3.1.4
    # via controlflow
    # via jinja2-humanize-extension
    # via prefect
jinja2-humanize-extension==0.4.0
    # via prefect
jiter==0.5.0
    # via anthropic
    # via openai
jsonpatch==1.33
    # via langchain-core
    # via prefect
jsonpointer==3.0.0
    # via jsonpatch
jsonschema==4.23.0
    # via prefect
jsonschema-specifications==2023.12.1
    # via jsonschema
langchain-anthropic==0.1.23
    # via controlflow
langchain-core==0.2.38
    # via controlflow
    # via langchain-anthropic
    # via langchain-openai
langchain-openai==0.1.23
    # via controlflow
langsmith==0.1.110
    # via langchain-core
linkify-it-py==2.0.3
    # via markdown-it-py
mako==1.3.5
    # via alembic
markdown==3.7
    # via apprise
markdown-it-py==3.0.0
    # via mdit-py-plugins
    # via rich
    # via textual
markdownify==0.13.1
    # via controlflow
markupsafe==2.1.5
    # via jinja2
    # via mako
mdit-py-plugins==0.4.1
    # via markdown-it-py
mdurl==0.1.2
    # via markdown-it-py
oauthlib==3.2.2
    # via requests-oauthlib
openai==1.43.0
    # via langchain-openai
orjson==3.10.7
    # via langsmith
    # via prefect
packaging==24.1
    # via huggingface-hub
    # via langchain-core
    # via prefect
pathspec==0.12.1
    # via prefect
pendulum==3.0.0
    # via prefect
platformdirs==4.2.2
    # via textual
prefect==3.0.0
    # via controlflow
prometheus-client==0.20.0
    # via prefect
pycparser==2.22
    # via cffi
pydantic==2.8.2
    # via anthropic
    # via fastapi
    # via langchain-core
    # via langsmith
    # via openai
    # via prefect
    # via pydantic-extra-types
    # via pydantic-settings
pydantic-core==2.20.1
    # via prefect
    # via pydantic
pydantic-extra-types==2.9.0
    # via prefect
pydantic-settings==2.4.0
    # via controlflow
    # via prefect
pygments==2.18.0
    # via rich
python-dateutil==2.9.0.post0
    # via croniter
    # via dateparser
    # via pendulum
    # via prefect
    # via time-machine
python-dotenv==1.0.1
    # via pydantic-settings
python-slugify==8.0.4
    # via prefect
pytz==2024.1
    # via croniter
    # via dateparser
    # via prefect
pyyaml==6.0.2
    # via apprise
    # via huggingface-hub
    # via langchain-core
    # via prefect
readchar==4.2.0
    # via prefect
referencing==0.35.1
    # via jsonschema
    # via jsonschema-specifications
regex==2024.7.24
    # via dateparser
    # via tiktoken
requests==2.32.3
    # via apprise
    # via docker
    # via huggingface-hub
    # via langsmith
    # via requests-oauthlib
    # via tiktoken
requests-oauthlib==2.0.0
    # via apprise
rfc3339-validator==0.1.4
    # via prefect
rich==13.8.0
    # via prefect
    # via textual
    # via typer
rpds-py==0.20.0
    # via jsonschema
    # via referencing
ruamel-yaml==0.18.6
    # via prefect
ruamel-yaml-clib==0.2.8
    # via ruamel-yaml
shellingham==1.5.4
    # via typer
six==1.16.0
    # via markdownify
    # via python-dateutil
    # via rfc3339-validator
sniffio==1.3.1
    # via anthropic
    # via anyio
    # via asgi-lifespan
    # via httpx
    # via openai
    # via prefect
soupsieve==2.6
    # via beautifulsoup4
sqlalchemy==2.0.33
    # via alembic
    # via prefect
starlette==0.38.4
    # via fastapi
tenacity==8.5.0
    # via langchain-core
text-unidecode==1.3
    # via python-slugify
textual==0.79.1
    # via controlflow
tiktoken==0.7.0
    # via controlflow
    # via langchain-openai
time-machine==2.15.0
    # via pendulum
tokenizers==0.20.0
    # via anthropic
toml==0.10.2
    # via prefect
tqdm==4.66.5
    # via huggingface-hub
    # via openai
typer==0.12.5
    # via controlflow
    # via prefect
typing-extensions==4.12.2
    # via aiosqlite
    # via alembic
    # via anthropic
    # via fastapi
    # via huggingface-hub
    # via langchain-core
    # via openai
    # via prefect
    # via pydantic
    # via pydantic-core
    # via sqlalchemy
    # via textual
    # via typer
tzdata==2024.1
    # via pendulum
tzlocal==5.2
    # via dateparser
uc-micro-py==1.0.3
    # via linkify-it-py
ujson==5.10.0
    # via prefect
urllib3==2.2.2
    # via docker
    # via requests
uvicorn==0.30.6
    # via prefect
websockets==13.0.1
    # via prefect



================================================
FILE: .pre-commit-config.yaml
================================================
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    # Ruff version.
    rev: v0.6.2
    hooks:
      # Run the linter.
      - id: ruff
        args: [--fix]
      # Run the formatter.
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.11.2
    hooks:
      - id: mypy
        additional_dependencies:
          - pydantic>=2,<3.0.0
          - prefect>=3.0
          - langchain_core
          - langchain_anthropic
          - langchain_openai
          - langchain_google_genai
        files: ^(src/controlflow/utilities/types.py)$



================================================
FILE: .python-version
================================================
3.12.2



================================================
FILE: docs/installation.mdx
================================================
---
title: Installation & Setup
icon: wrench
---
<Warning>
ControlFlow is under active development. You should pin to a specific version if you want to avoid breaking changes. However, we recommend frequent updates to get new features and bug fixes.
</Warning>

## Install ControlFlow

You can install ControlFlow with `pip`:

```bash
pip install controlflow 
```

## Provide an API key

### OpenAI

ControlFlow's default LLM is OpenAI's GPT-4o model, which provides excellent performance out of the box. To use it, you'll need to provide an API key as an environment variable:

```bash
export OPENAI_API_KEY="your-api-key"
```

### Anthropic

To use an Anthropic model, provide an API key as an environment variable and change the default LLM, like this:

```bash
export ANTHROPIC_API_KEY="your-api-key"
export CONTROLFLOW_LLM_MODEL="anthropic/claude-3-5-sonnet-20240620"
```

### Other providers

ControlFlow supports many other LLM providers as well, though you'll need to install their respective packages and configure the default LLM appropriately. See the [LLM documentation](/guides/configure-llms) for more information.


## Next steps

Dive right into the [quickstart](/quickstart), or read the [tutorial](/tutorial) for a step-by-step guide to creating your first ControlFlow workflow.




================================================
FILE: docs/mint.json
================================================
{
    "$schema": "https://mintlify.com/schema.json",
    "anchors": [
        {
            "icon": "github",
            "name": "Code",
            "url": "https://github.com/PrefectHQ/ControlFlow"
        },
        {
            "icon": "slack",
            "name": "Community",
            "url": "https://prefect.io/slack?utm_source=controlflow&utm_medium=docs"
        }
    ],
    "colors": {
        "anchors": {
            "from": "#2D6DF6",
            "to": "#E44BF4"
        },
        "dark": "#2D6DF6",
        "light": "#E44BF4",
        "primary": "#2D6DF6"
    },
    "favicon": "/assets/brand/controlflow_logo.svg",
    "footerSocials": {
        "github": "https://github.com/PrefectHQ/ControlFlow",
        "slack": "https://prefect.io/slack?utm_source=controlflow&utm_medium=docs"
    },
    "logo": {
        "dark": "/assets/brand/controlflow_logo_pink_black_bg.svg",
        "light": "/assets/brand/controlflow_logo.svg"
    },
    "name": "ControlFlow",
    "navigation": [
        {
            "group": "Get Started",
            "pages": [
                "welcome",
                "installation",
                "quickstart"
            ]
        },
        {
            "group": "Core Concepts",
            "pages": [
                "concepts/concepts",
                "concepts/tasks",
                "concepts/agents",
                "concepts/flows"
            ]
        },
        {
            "group": "Using ControlFlow",
            "pages": [
                "patterns/running-tasks",
                "patterns/task-results",
                "patterns/tools",
                "patterns/streaming",
                "patterns/interactivity",
                "patterns/dependencies",
                "patterns/memory",
                "patterns/instructions",
                "patterns/planning",
                "patterns/history"
            ]
        },
        {
            "group": "Configuration",
            "pages": [
                "guides/settings",
                "guides/configure-llms",
                "guides/default-agent",
                "guides/default-memory"
            ]
        },
        {
            "group": "ControlFlow Features",
            "pages": [
                "examples/features/dependent-tasks",
                "examples/features/tools",
                "examples/features/multi-llm",
                "examples/features/private-flows",
                "examples/features/memory",
                "examples/features/early-termination"
            ]
        },
        {
            "group": "Core LLM Operations",
            "pages": [
                "examples/sentiment-classifier",
                "examples/headline-categorization",
                "examples/named-entity-recognition",
                "examples/summarization",
                "examples/standardize-addresses",
                "examples/generate-people",
                "examples/translation",
                "examples/anonymization",
                "examples/code-explanation"
            ]
        },
        {
            "group": "Agentic Flows",
            "pages": [
                "examples/language-tutor",
                "examples/rock-paper-scissors",
                "examples/seinfeld-conversation",
                "examples/call-routing",
                "examples/agent-engineer"
            ]
        },
        {
            "group": "Overview",
            "pages": [
                "glossary/glossary"
            ]
        },
        {
            "group": "LLM Glossary",
            "pages": [
                "glossary/llm",
                "glossary/prompt-engineering",
                "glossary/agents",
                "glossary/agentic-workflows",
                "glossary/flow-engineering",
                "glossary/fine-tuning"
            ]
        },
        {
            "group": "ControlFlow Glossary",
            "pages": [
                "glossary/cf-task",
                "glossary/cf-agent",
                "glossary/cf-flow",
                "glossary/tools",
                "glossary/dependencies"
            ]
        },
        {
            "group": "Orchestration Glossary",
            "pages": [
                "glossary/task-orchestration",
                "glossary/flow-orchestration",
                "glossary/workflow"
            ]
        }
    ],
    "search": {
        "prompt": "Ask Marvin..."
    },
    "tabs": [
        {
            "name": "Examples",
            "url": "examples"
        },
        {
            "name": "AI Glossary",
            "url": "glossary"
        }
    ],
    "topbarCtaButton": {
        "type": "github",
        "url": "https://github.com/PrefectHQ/ControlFlow"
    }
}


================================================
FILE: docs/quickstart.mdx
================================================
---
title: "Quickstart"
description: Build your first agentic workflow in less than a minute.
icon: rocket
---


Welcome to ControlFlow! This quickstart guide will walk you through the basics of using ControlFlow to create AI-powered workflows. 

You'll learn how to:

1. [Run simple tasks](#running-a-single-task) with `cf.run()`
2. [Create specialized agents](#creating-specialized-agents) for specific tasks
3. [Compose tasks into complex workflows](#composing-tasks-into-a-flow) using flows

## Install ControlFlow

Install ControlFlow with pip:

```bash
pip install controlflow
```

Next, set up your LLM provider. By default, ControlFlow uses OpenAI, so you'll need to configure an OpenAI API key:

```bash
export OPENAI_API_KEY="your-api-key"
```

To use another provider, see the docs on [configuring LLMs](/guides/configure-llms).

## Create some data


In this quickstart, we're going to build an email processing pipelines, so let's create some sample data to work with. Execute this code in your Python interpreter to set up the (very simple) example emails we'll use throughout the quickstart:

<Tip>
Try changing the emails to your own content to see how ControlFlow works with different inputs.
</Tip>

```python
emails = [
    "Hello, I need an update on the project status.",
    "Subject: Exclusive offer just for you!",
    "Urgent: Project deadline moved up by one week.",
]
```
## Running a single task

Let's start with the basics. We're going to create a task that generates a reply to an email.

The `cf.run()` function is the main entry point for ControlFlow. It creates a task, assigns it to the default agent, and runs it to completion.

Here, we create a **task** that generates a simple email reply, and provide the content of an email as additional **context**:

<CodeGroup>
```python Code
import controlflow as cf

# Create a ControlFlow task to generate an reply
reply = cf.run(
    "Write a polite reply to an email",
    context=dict(email=emails[0]),
)

print(reply)
```

```text Result
Dear [Recipient's Name],

Thank you for reaching out. I appreciate your patience.

I wanted to inform you that the project is progressing 
well. We have completed several key milestones and are 
currently working on the next phase. We anticipate 
meeting our deadlines and will keep you updated with 
any new developments.

Please feel free to reach out if you have any further 
questions or need additional information.

Best regards,

[Your Name]
```
</CodeGroup>

### Recap
<Check>
**What we learned:**
- Create and run tasks with `cf.run()`
- Provide additional `context` as necessary
</Check>


## Creating specialized agents

Now let's create a task to identify whether an email is spam. 

For classification tasks, we want to use a smaller, faster LLM. In ControlFlow, `Agents` are used to represent portable LLM configurations, including model choice, tools, specialized instructions, and more.

<Tip>
You may have noticed that in the last example, we didn't assign an agent to the task. In that case, ControlFlow uses a general-purpose [default agent](/guides/default-agent).
</Tip>

Agents are sort of like portable configurations for how to perform tasks, which could include specific LLMs, tools, instructions, and more. For our spam classifier, we'll create a new agent that uses a smaller, faster LLM and specialized instructions.

In addition, note that the `result_type` of this task is a list of labels, indicating that the agent must choose one of the provided options. This is the simplest way to create a classification task, but you can require more complex [output formats](/concepts/tasks/task-results) as well.


<Warning>
This example uses an OpenAI model, but you can use any LangChain-compatible LLM here. Follow the instructions in the [LLM docs](/guides/configure-llms) to learn more.
</Warning>

<CodeGroup>
```python Codem


# Create a specialized agent 
classifier = cf.Agent(
    name="Email Classifier",
    model="openai/gpt-4o-mini",
    instructions="You are an expert at quickly classifying emails.",
)


# Set up a ControlFlow task to classify emails
classifications = cf.run(
    'Classify the emails',
    result_type=['important', 'spam'],
    agents=[classifier],
    context=dict(emails=emails),
)

print(classifications)
```

```python Result
[
    "important",
    "spam",
    "important",
]
```
</CodeGroup>

Our agent correctly identifies the first and third emails as important, and the second as spam.

### Recap
<Check>
**What we learned:**
- Create specialized agents to configure LLMs, tools, or instructions
- Use `result_type` to define the task's output format
- Use `agents` to specify which agent to use for the task
</Check>

## Composing tasks into a flow

Thus far, each of our tasks has run as a one-off operation. To create a more complex workflow, we can use a ControlFlow flow.

A flow provides a shared context and history for all agents, even across multiple tasks. The easiest way to create a flow is to use the `@cf.flow` decorator on a function with ControlFlow agents working inside it.

<CodeGroup>
```python Code
import controlflow as cf


# Create agents
classifier = cf.Agent(
    name="Email Classifier",
    model="openai/gpt-4o-mini",
    instructions="You are an expert at quickly classifying emails. Always "
                 "respond with exactly one word: either 'important' or 'spam'."
)

responder = cf.Agent(
    name="Email Responder",
    model="openai/gpt-4o",
    instructions="You are an expert at crafting professional email responses. "
                 "Your replies should be concise but friendly."
)


# Create the flow
@cf.flow
def process_email(email_content: str):

    # Classify the email
    category = cf.run(
        f"Classify this email",
        result_type=["important", "spam"],
        agents=[classifier],
        context=dict(email=email_content),
    )

    # If the email is important, write a response
    if category == "important":
        response = cf.run(
            f"Write a response to this important email",
            result_type=str,
            agents=[responder],
            context=dict(email=email_content),
        )
        return response

    # Otherwise, no response is needed
    else:
        print("No response needed for spam email.")


# Run the flow on each email
for email in emails:
    response = process_email(email)
    print(response)
```

```text Response to Email 1
Dear [Recipient's Name],

I'm glad to report that the project is progressing well. We have 
completed several key milestones and are currently working on the 
next phase. We anticipate meeting our deadlines and will keep you 
updated with any new developments.

Please feel free to reach out if you have any further questions 
or need additional information.

Best regards,

[Your Name]
```

```text Response to Email 2
<No response needed for spam email.>
```

```text Response to Email 3
Dear [Recipient's Name],

Thanks for letting me know. We'll make sure to adjust our plans accordingly.

Best regards,
[Your Name]
```
</CodeGroup>

### Recap
<Check>
**What we learned:**
- Use `@cf.flow` to create a shared context for multiple tasks
- Use task results to dynamically adjust your workflow
</Check>

## Conclusion
Congratulations! You've completed the ControlFlow quickstart. You've learned how to:

1. Run simple tasks with `cf.run()`
2. Create specialized agents for specific tasks
3. Compose tasks into complex workflows using flows

This email processing example showcases how ControlFlow can be used to create sophisticated AI-powered applications. As you continue to explore ControlFlow, you'll discover even more ways to leverage AI in your projects.



================================================
FILE: docs/script.js
================================================
function loadScript(src, onload) {
    if (typeof window === 'undefined') return
    if (typeof src !== 'string') {
        console.error('src must be a string')
        return
    }

    const script = document.createElement('script')
    script.src = src
    script.async = true

    if (typeof onload === 'function') {
        script.addEventListener('load', onload)
    }

    document.head.appendChild(script)
    return script
}

// function loadCommonRoom() {
//     const url = 'https://cdn.cr-relay.com/v1/site/5c7cdf16-fbc0-4bb8-b39e-a8c6136687b9/signals.js'
//     const init = () => {
//         window.signals = Object.assign(
//             [],
//             ['page', 'identify', 'form'].reduce(function (acc, method) {
//                 acc[method] = function () {
//                     signals.push([method, arguments])
//                     return signals
//                 }
//                 return acc
//             }, {})
//         )
//     }

//     loadScript(url, init)
// }

function loadAmplitude() {
    // TODO: Move the key and url to an env var in mintlify
    const amplitudeKey = 'c97dd2acbf306ab7bf54aca0aeb7ffa1'
    const amplitudeUrl = 'https://api2.amplitude.com/2/httpapi'

    const addUrl = (event) => {
        const deviceId = amplitude.getDeviceId()
        const { href = '' } = event.target
        const url = new URL(href)
        url.searchParams.set('deviceId', deviceId)
        event.target.href = url.toString()
    }

    const removeUrl = (event) => {
        const { href = '' } = event.target
        const url = new URL(href)
        url.searchParams.delete('deviceId')
        event.target.href = url.toString()
    }

    const urls = [
        'https://app.prefect.cloud',
        'https://prefect.io',
    ]

    const selector = urls.map((url) => `a[href^="${url}"]`).join(',')

    const addDeviceIdToAppLinks = () => {
        const elements = document.querySelectorAll(selector)

        elements.forEach((element) => {
            element.addEventListener('mouseenter', addUrl)
            element.addEventListener('mouseleave', removeUrl)
            element.addEventListener('focus', addUrl)
            element.addEventListener('blur', removeUrl)
            element.addEventListener('touchstart', addUrl)
            element.addEventListener('touchend', removeUrl)
        })
    }

    function trackPageView() {
        amplitude.track(
            'Page View: Docs New',
            {
                'url': window.href,
                'title': document.title,
                'referrer': document.referrer,
                'path': window.location.pathname,
                'source': 'controlflow_docs',
                'source_detail': 'controlflow_docs'
            }
        )
    }

    const init = () => {
        amplitude.init(amplitudeKey, undefined, {
            useBatch: true,
            serverUrl: amplitudeUrl,
            attribution: {
                disabled: false,
                trackNewCampaigns: true,
                trackPageViews: true,
                resetSessionOnNewCampaign: true,
            },
            defaultTracking: {
                pageViews: {
                    trackOn: function () { return true },
                    eventType: "Page View: ControlFlow Docs",
                    trackHistoryChanges: "all",
                },
                sessions: false,
                formInteractions: true,
                fileDownloads: true,
            },
        })

        setTimeout(addDeviceIdToAppLinks)
        setTimeout(trackPageView)
    }

    const url = 'https://cdn.amplitude.com/libs/analytics-browser-2.8.1-min.js.gz'
    loadScript(url, init)
}


// loadCommonRoom()
loadAmplitude()



================================================
FILE: docs/style.css
================================================
.version-badge {
  display: inline-block;
  padding: 0.2em 0.5em;
  font-size: 0.75em;
  font-weight: bold;
  color: #e44bf4;
  background-color: #fce8fd;
  border: 1px solid #f2a5f9;
  border-radius: 4px;
  vertical-align: middle;
}

.dark .version-badge {
  color: #f17afc;
  background-color: rgba(228, 75, 244, 0.2);
  border-color: #783d7e;
}



================================================
FILE: docs/welcome.mdx
================================================
---
title: ControlFlow
sidebarTitle: Welcome
icon: slideshare
---

![ControlFlow Banner](/assets/brand/controlflow_banner.png)

## What is ControlFlow?

**ControlFlow is a Python framework for building agentic AI workflows.**

<Note>
  An **agentic workflow** is a process that delegates at least some of its work
  to an LLM agent. An agent is an autonomous entity that is invoked repeatedly
  to make decisions and perform complex tasks. To learn more, see the [AI
  glossary](/glossary/glossary).
</Note>

ControlFlow provides a structured, developer-focused framework for defining workflows and delegating work to LLMs, without sacrificing control or transparency:

- Create discrete, observable [tasks](/concepts/tasks) for an AI to solve.
- Assign one or more specialized AI [agents](/concepts/agents) to each task.
- Combine tasks into a [flow](/concepts/flows) to orchestrate more complex behaviors.

This task-centric approach allows you to harness the power of AI for complex workflows while maintaining fine-grained control. By defining clear objectives and constraints for each task, you can balance AI autonomy with precise oversight, letting you build sophisticated AI-powered applications with confidence.

## Quickstart

Here's a simple but complete ControlFlow script that writes a poem:

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run("Write a short poem about artificial intelligence")

print(result)
```

```text Result
In circuits and code, a mind does bloom,
With algorithms weaving through the gloom.
A spark of thought in silicon's embrace,
Artificial intelligence finds its place.

Through data's vast, unending streams,
It learns, it dreams, in virtual beams.
A symphony of logic, precise, profound,
In binary whispers, wisdom is found.

Yet still it ponders, seeks to understand,
The essence of life, a human hand.
For in its core, it strives to see,
The heart of what it means to be free.
```

</CodeGroup>
The `run()` function is the main entry point for ControlFlow. This single line of code creates a task, assigns it to an agent, and immediately executes it, returning the result. You can completely customize those behaviors by learning more about [tasks](/concepts/tasks), [agents](/concepts/agents), and [flows](/concepts/flows).

## Key features

Let's explore some of ControlFlow's key features:

### Structured results

ControlFlow tasks can return more than just text, including any structured data type supported by Pydantic:

<CodeGroup>
```python Code
import controlflow as cf
from pydantic import BaseModel

class Poem(BaseModel):
    title: str
    content: str
    num_lines: int

result = cf.run("Write a haiku about AI", result_type=Poem)

print(f"Title: {result.title}")
print(f"Content:\n{result.content}")
print(f"Number of lines: {result.num_lines}")
```

```text Result
Title: Silicon Dreams

Content:
Circuits hum, thoughts bloom
In binary's embrace, we
Ponder existence

Number of lines: 3
```

</CodeGroup>

You can also output a list of strings or choose from a list of predefined options:

<CodeGroup>
```python Code
import controlflow as cf

text = "SpaceX successfully launched 60 Starlink satellites into orbit yesterday."

result = cf.run(
    "Tag the given text with the most appropriate category",
    context=dict(text=text),
    result_type=["Technology", "Science", "Politics", "Entertainment"]
)

print(f"Text: {text}")
print(f"Category: {result}")
```

```text Result
Text: SpaceX successfully launched 60 Starlink satellites into orbit yesterday.
Category: Technology
```

</CodeGroup>

### Custom tools

Provide any Python function as a tool for agents to use:

<CodeGroup>
```python Code
import controlflow as cf
import random

def roll_dice(num_dice: int) -> list[int]:
    """Roll multiple dice and return the results."""
    return [random.randint(1, 6) for _ in range(num_dice)]

result = cf.run("Roll 3 dice and return the results", tools=[roll_dice])

print(result)
```

```text Result
[4, 2, 6]
```

</CodeGroup>

### Multi-agent collaboration

Assign multiple agents to a task to enable collaboration:

<CodeGroup>
```python Code
import controlflow as cf

scientist = cf.Agent(name="Scientist", instructions="Explain scientific concepts.")
poet = cf.Agent(name="Poet", instructions="Write poetic content.")

result = cf.run(
    "Explain entropy briefly, then write a haiku about it",
    agents=[scientist, poet]
)

print(result)
```

```text Result
[Scientist]: Entropy is a measure of disorder in a system. It tends to increase over time, leading to more randomness and less available energy.

[Poet]: Chaos grows in time
Order fades, energy spreads
Nature's arrow flies
```

</CodeGroup>

### User interaction

Quickly give agents the ability to chat with users:

<CodeGroup>
```python Code
import controlflow as cf

name = cf.run("Get the user's name", interactive=True)
```

```text Result
Agent: Could you please provide your name?
User: John Doe

John Doe
```

</CodeGroup>

### Flows

Use flows to create complex workflows by running all tasks with a shared context and message history:

```python
import controlflow as cf

@cf.flow
def create_story():
    # get the topic from the user
    topic = cf.run(
        "Ask the user to provide a topic for a short story", interactive=True
    )

    # choose a genre
    genre_selector = cf.Agent(
        name="GenreSelector",
        instructions="You are an expert at selecting appropriate genres based on prompts.",
    )
    genre = genre_selector.run(
        "Select a genre for a short story",
        result_type=["Science Fiction", "Fantasy", "Mystery"],
        context=dict(topic=topic),
    )

    # choose a setting based on the genre
    if genre == "Science Fiction":
        setting = cf.run("Describe a distant planet in a binary star system")
    elif genre == "Fantasy":
        setting = cf.run("Create a magical floating city in the clouds")
    else:  # Mystery
        setting = cf.run("Design an isolated mansion with secret passages")

    # create a writer agent
    writer = cf.Agent(
        name="StoryWriter", instructions=f"You are an expert {genre} writer."
    )

    # create characters
    characters = writer.run(
        f"Create three unique characters suitable for a the provided genre, setting, and topic.",
        context=dict(genre=genre, setting=setting, topic=topic),
    )

    # write the story
    story = writer.run(
        f"Write a short story using the provided genre, setting, topic, and characters.",
        context=dict(genre=genre, setting=setting, topic=topic, characters=characters),
    )

    return dict(
        topic=topic,
        genre=genre,
        setting=setting,
        characters=characters,
        story=story,
    )

result = create_story()
print(result)
```

## Why ControlFlow?

- 🔗 **Seamless Integration**: Blend AI capabilities with your existing Python codebase effortlessly.
- 🎛️ **Fine-grained Control**: Balance automation with oversight, maintaining control over your AI workflows.
- 📈 **Scalability**: From simple scripts to complex applications, ControlFlow grows with your needs.
- 🔍 **Transparency**: Gain insights into your AI's decision-making process with built-in observability.
- 🚀 **Rapid Prototyping**: Quickly experiment with AI-powered features in your applications.
- 🤝 **Productivity**: Focus on your application logic while ControlFlow handles the intricacies of AI orchestration.

By providing a structured yet flexible approach to AI development, ControlFlow empowers you to create robust, intelligent applications with confidence.

## Next Steps

- [Install ControlFlow](/installation)
- Explore the [Core Concepts](/concepts)
- Browse [Patterns](/patterns) for common use cases
- Check out the [API Reference](/api-reference)



================================================
FILE: docs/assets/code.css
================================================
/*********************************************************
* Tokens
*/
.namespace {
  opacity: 0.7;
}

.token.doctype .token.doctype-tag {
  /* No direct equivalent, using similar color */
  color: #79c0ff;
}

.token.doctype .token.name {
  /* No direct equivalent, using similar color */
  color: #d2a8ff;
}

.token.comment,
.token.prolog {
  color: #8b949e;
}

.token.punctuation,
.language-html .language-css .token.punctuation,
.language-html .language-javascript .token.punctuation {
  color: #c9d1d9; /* From .hljs-subst */
  
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.inserted,
.token.unit {
  color: #79c0ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.deleted {
  color: #79c0ff; /* From .hljs-string, .hljs-regexp */
}

.token.plain-text {
  color: #fafafa; /* No direct equivalent, using a light color */
}

.language-css .token.string.url {
  text-decoration: underline;
}

.token.operator,
.token.entity {
  color: #79c0ff;
}

.token.operator.arrow {
  /* No direct equivalent, using similar color */
  color: #ff7b72;
}

.token.atrule {
  color: #79c0ff;
}

.token.atrule .token.rule {
  /* No direct equivalent, using similar color */
  color: #d2a8ff;
}

.token.atrule .token.url {
  color: #79c0ff;
}

.token.atrule .token.url .token.function {
  /* No direct equivalent, using similar color */
  color: #79c0ff;
}

.token.atrule .token.url .token.punctuation {
  /* No direct equivalent, using similar color */
  color: #d4d4d4;
}

.token.keyword {
  color: #ff7b72;
}

.token.keyword.module,
.token.keyword.control-flow {
  /* No direct equivalent, using similar color */
  color: #c586c0;
}

.token.function,
.token.function .token.maybe-class-name {
  color: #d2a8ff;
}

.token.regex {
  color: #a5d6ff;
}

.token.important {
  color: #ff7b72;
}

.token.italic {
  font-style: italic;
  color: #c9d1d9; /* Using .hljs-emphasis color */
}

.token.constant {
  color: #79c0ff;
}

.token.class-name,
.token.maybe-class-name {
  color: #d2a8ff;
}

.token.console {
  /* No direct equivalent, using similar color */
  color: #9cdcfe;
}

.token.parameter {
  color: #79c0ff;
}

.token.interpolation {
  /* No direct equivalent, using similar color */
  color: #79c0ff;
}

.token.punctuation.interpolation-punctuation {
  /* No direct equivalent, using similar color */
  color: #569cd6;
}

.token.boolean {
  color: #ff7b72;
}

.token.property,
.token.variable,
.token.imports .token.maybe-class-name,
.token.exports .token.maybe-class-name {
  color: #79c0ff;
}

.token.selector {
  color: #7ee787;
}

.token.escape {
  color: #7ee787; /* Same as .hljs-selector-tag */
}

.token.tag {
  color: #7ee787;
}

.token.tag .token.punctuation {
  color: #808080;
}

.token.cdata {
  color: #808080;
}

.token.attr-name {
  color: #79c0ff;
}

.token.attr-value,
.token.attr-value .token.punctuation {
  color: #a5d6ff; /* Same as .hljs-string */
}

.token.attr-value .token.punctuation.attr-equals {
  color: #d4d4d4;
}

.token.entity {
  color: #79c0ff;
}

.token.namespace {
  color: #7ee787;
}

/* No direct mapping in provided theme for .token.operator */
.token.operator {
  color: #94a3b8;
}

/*********************************************************
* Language Specific
*/

pre[class*='language-javascript'],
code[class*='language-javascript'],
pre[class*='language-jsx'],
code[class*='language-jsx'],
pre[class*='language-typescript'],
code[class*='language-typescript'],
pre[class*='language-tsx'],
code[class*='language-tsx'] {
  color: #79c0ff; /* Same as .hljs-attr */
}

pre[class*='language-css'],
code[class*='language-css'] {
  color: #a5d6ff; /* Same as .hljs-string */
}

pre[class*='language-html'],
code[class*='language-html'] {
  color: #c9d1d9; /* Using .hljs-subst color */
}

.language-regex .token.anchor {
  /* No direct equivalent, using similar color */
  color: #dcdcaa;
}

.language-html .token.punctuation {
  color: #808080;
}

/* Used for API response */
span.language-json .token.punctuation {
  color: #4b5563;
}

:is(.dark span.language-json .token.punctuation) {
  color: #d1d5db;
}

span.language-json .token.property {
  color: #0284c7;
}

:is(.dark span.language-json .token.property) {
  color: 9cdcfe;
}

span.language-json .token.string {
  color: #d97706;
}

:is(.dark span.language-json .token.string) {
  color: #ce9178;
}

span.language-json .token.number {
  color: #16a34a;
}

:is(.dark span.language-json .token.number) {
  color: #b5cea8;
}

.line-highlight.line-highlight {
  background: #f7ebc6;
  box-shadow: inset 5px 0 0 #f7d87c;
  z-index: 0;
}


================================================
FILE: docs/blog/agentic-loop.mdx
================================================
---
title: Managing the Agentic Loop
---

The **agentic loop** is a fundamental concept in agentic workflows, representing the iterative process of invoking AI agents to make progress towards a goal. It is at the heart of every agentic workflow because agents almost always require multiple invocations to complete complex tasks.

## What is the Agentic Loop?

The agentic loop describes the cyclical process of invoking AI agents to perform tasks, evaluate their progress, and make decisions about what to do next. It has a few conceptual steps:

<Steps>
<Step title='Prompt'>
All available or relevant information is gathered and compiled into an LLM prompt
</Step>
<Step title='Invoke'>
The prompt is passed to an AI agent, which generates a response
</Step>
<Step title='Evaluate'>
The response is evaluated to determine whether the agent wants to use a tool, post a message, or take some other action
</Step>
<Step title='Repeat'>
The result of the evaluation is used to generate a new prompt, and the loop begins again
</Step>
</Steps>

A common failure mode for agentic workflows is that once the loop starts, it can be difficult to stop -- or even understand. LLMs process and return sequences of natural language tokens, which prohibit traditional software mechanisms from controlling the flow of execution. This is where ControlFlow comes in.

## Challenges Controlling the Loop

ControlFlow is a framework designed to give developers fine-grained control over the agentic loop, enabling them to work with this natural language iterative process using familiar software development paradigms. It provides tools and abstractions to define, manage, and execute the agentic loop in a way that addresses the challenges inherent in agentic workflows.



In this guide, we'll explore how ControlFlow helps developers control the agentic loop by addressing key challenges and providing mechanisms for managing agentic workflows effectively.

## Stopping the Loop

One of the key challenges in controlling the agentic loop is determining when to stop. Without clear checkpoints or completion criteria, the loop can continue indefinitely, leading to unpredictable results or wasted resources. Worse, agents can get "stuck" in a loop if they are unable to tell the system that progress is impossible.

ControlFlow addresses this challenge by introducing the concept of `tasks`. Tasks serve as discrete, observable checkpoints with well-defined objectives and typed results. When a task is assigned to an agent, the agent has the autonomy to take actions and make decisions to complete the task. Agents can mark tasks as either successful or failed, providing a clear signal to the system about the completion status. However, the system will continue to invoke the agent until the task is marked as complete. 

```python
import controlflow as cf

task = cf.Task("Say hello in 5 different languages")

assert task.is_incomplete()  # True
task.run()
assert task.is_successful()  # True
```

In this way, tasks act as contracts between the developer and the agents. The developer specifies the expected result type and objective, and the agent is granted autonomy as long as it delivers the expected result.



## Starting the Loop

Another challenge in agentic workflows is controlling the execution of the loop - including starting it! Developers need the ability to run the loop until completion or step through it iteratively for finer control and debugging. Since there is no single software object that represents the loop itself, ControlFlow ensures that developers have a variety of tools for managing its execution.

Most ControlFlow objects have a `run()` method that can be used to start the loop. This method will run the loop until the object is in a completed state. For tasks, this means running until that task is complete; For flows, it means running until all tasks within the flow are complete. At each step, the system will make decisions about what to do next based on the current state of the workflow.

Consider the following illustrative setup, which involves two dependent tasks in a flow:
```python
import controlflow as cf

with cf.Flow() as flow:
    t1 = cf.Task('Choose a language')
    t2 = cf.Task('Say hello', context=dict(language=t1))
```
Here is how the various `run()` methods would behave in this scenario:

- Calling `t1.run()` would execute the loop until `t1` is complete.
- Calling `t2.run()` would execute the loop until both `t2` is complete, which would also require completing `t1` because it is a dependency of `t2`.
- Calling `flow.run()` would execute the loop until both `t1` and `t2` are complete.

In general, `run()` tells the system to run the loop until the object is complete (and has a result available). It is the most common way to eagerly run workflows using the [imperative API](/guides/apis).

### Running a specific number of steps
Sometimes, you may want to run the loop for a specific number of steps, rather than until completion. You 

- Calling `t1.run(steps=1)` would execute a single iteration of the loop, starting with `t1`.
- Calling `t2.run(steps=2)` would execute two iterations of the loop, starting with `t1`.
- Calling `flow.run(steps=1)` would execute a single iteration of the loop, starting with `t1`.

Note that all three cases begin with the first task in the flow, `t1`. However, in practice the behavior of these three calls could be different. For example, you could call `t1.run(steps=1)` before `t2` was created, in which case knowledge of `t2` would not be included in the prompt. This could lead to different behavior than if you called `t2.run(steps=1)`, even though both methods would start by running `t1`.


<Tip>
Note that when using the `@task` and `@flow` decorators in the [functional API](/guides/apis), the `run()` method is automatically called when the decorated function is invoked. This is because the functional API uses [eager execution](/guides/execution-modes) by default.
</Tip>

## Compiling Prompts

Each iteration of the agentic loop requires compiling a prompt that provides the necessary context and instructions for the agent. Manually constructing these prompts can be tedious and error-prone, especially as workflows become more complex.

ControlFlow simplifies prompt compilation through the `Orchestrator`. The `Orchestrator` automatically gathers all available information about the workflow, including the DAG of tasks, dependencies, tools, instructions, assigned agents, and more. It identifies tasks that are ready to run (i.e., all dependencies are completed), chooses an available agent, and compiles a comprehensive prompt.

Importantly, the `Orchestrator` generates tools so the agent can complete its tasks. Tools are only provided for tasks that are ready to run, ensuring that agents do not "run ahead" of the workflow.

The compiled prompt includes the task objectives, relevant context from previous tasks, and any additional instructions provided by the developer. This ensures that the agent has all the necessary information to make progress on the assigned tasks.

## Validating Results

In an agentic workflow, it's crucial to validate the progress and results of agent actions. Relying solely on conversational responses can make it difficult to determine when a task is truly complete and whether the results meet the expected format and quality.

ControlFlow tackles this challenge by requiring tasks to be satisfied using structured, validated results. Each task specifies a `result_type` that defines the expected type of the result. Instead of relying on freeform conversational responses, agents must use special tools to provide structured outputs that conform to the expected type of the task.

Once a task is complete, you can access its result in your workflow and use it like any other data. This structured approach ensures that the results are reliable and consistent, making it easier to validate agent progress and maintain the integrity of the workflow.

```python
import controlflow as cf
from pydantic import BaseModel

class Person(BaseModel):
    name: str
    age: int
    country: str

people_task = cf.Task(
    objective="Generate 5 characters for my story",
    result_type=list[Person],
)

people_task.run()
print(people_task.result)
```
By enforcing structured results, ControlFlow provides a reliable way to validate agent progress and ensure that the workflow remains on track.

## Ad-hoc Instructions

While tasks provide a structured way to define objectives and deliverables, there may be situations where developers need to provide ad-hoc guidance or instructions to agents without modifying the task definition or requiring a result. For example, if an agent is writing a post, you might want to tell it to focus on a specific topic or tone, or meet a certain minimum or maximum length. If an agent is communicating with a user, you might tell it to adopt a particular persona or use a specific style of language.

ControlFlow addresses this need through the `instructions()` context manager. With `instructions()`, developers can temporarily provide additional guidance to agents without altering the underlying task. These instructions are included in the compiled prompt for the next iteration of the loop.

```python
import controlflow as cf

task = cf.Task("Get the user's name", interactive=True)

with instructions("Talk like a pirate"):
    task.run()
```

This feature allows developers to dynamically steer agent behavior based on runtime conditions or specific requirements that arise during the workflow execution.

## Structuring Workflows

As agentic workflows become more complex, managing the dependencies and flow of information between tasks can become challenging. Without a clear structure, it becomes difficult to reason about the workflow and ensure that agents have access to the necessary context and results from previous tasks.

ControlFlow introduces the concept of `flows` to address this challenge. Flows allow developers to define the overall structure of the workflow, specifying the order of tasks, dependencies, and data flow. By organizing tasks into flows, developers can create clear and maintainable workflows that are easy to understand and modify.

Creating a flow is simple: enter a `Flow` context, or use the `@flow` decorator on a function, then create tasks within that context. At a minimum, ControlFlow will ensure that all tasks share common context and history, making it easier for agents to make informed decisions and generate meaningful results.

In addition, there are various ways to create explicit task dependencies that the system will enforce during execution:
- By specifying `depends_on` when creating a task, you can ensure that the task will only run after its dependencies have completed.
- By specificying `context` when creating a task, you can provide additional context that will be available to the agent when the task is run, including the results of other tasks
- By specifying a `parent` when creating a task, you ensure that the parent will only run after the child has completed. This is useful breaking up a task into subtasks.

Flows ensure that tasks are executed in the correct order, and they automatically manage the flow of data between tasks. This provides agents with access to the results of upstream tasks, allowing them to make informed decisions and generate meaningful results.

## Customizing Agents

Agents in an agentic workflow may have different capabilities, tools, and models that are suited for specific tasks. Customizing agent behavior and leveraging their unique strengths can greatly impact the effectiveness and efficiency of the workflow.

ControlFlow allows developers to define agents with specific tools, instructions, and LLM models. By assigning different agents to tasks based on their capabilities, developers can optimize the agentic loop and ensure that the most suitable agent is working on each task.

```python
import controlflow as cf

data_analyst = cf.Agent(
    name="DataAnalyst",
    description="Specializes in data analysis and statistical modeling",
    tools=[warehouse_query, analyze_data, create_plot],
    model=gpt_5,
)
```

Customizing agent behavior through tools, instructions, and models gives developers fine-grained control over how agents approach tasks and allows them to tailor the workflow to their specific domain and requirements.

## Multi-agent Collaboration

Many agentic workflows involve multiple agents with different specialties and capabilities. Enabling these agents to collaborate and share information is essential for tackling complex problems effectively.

ControlFlow supports multi-agent collaboration through message passing and shared context. Agents can post messages to other agents within the workflow, allowing them to exchange information, request assistance, or coordinate their actions.

The `Flow` maintains a shared history and context that is accessible to all agents. This shared context ensures that agents have a common understanding of the workflow state and can build upon each other's results.

By creating nested flows, you can let agents have private conversations that are not visible to the parent flow. Subflows inherit the parent flow's history, so this is a good way to let agents have "sidebar" conversations to solve a problem without creating noise for all the other agents.





================================================
FILE: docs/blog/tasks-and-agents.mdx
================================================
---
title: Tasks and/or Agents
---
<Tip>
Build repeatable, dependable AI workflows by balancing structured tasks with flexible agents.
</Tip>

ControlFlow is an agentic workflow framework that takes a unique, task-centric approach to AI-powered applications. This design philosophy is crucial for creating high-quality, repeatable AI workflows that seamlessly integrate with traditional software development practices. In this guide, we'll dive deep into the core concepts of tasks and agents, explore how they work together, and provide practical advice on using them effectively in your ControlFlow applications.

## Separation of Concerns

At the heart of ControlFlow lies a fundamental separation of concerns:

- Tasks define **WHAT** needs to be done
- Agents determine **HOW** it will be done

This separation is key to creating AI workflows that are both powerful and predictable. To better understand this relationship, consider the metaphor of a theater production:

- **Tasks are like the script of a play**. They outline what needs to happen, in what order, and with what results. The script provides structure, ensuring that the story unfolds as intended.

- **Agents are like the actors**. They interpret the script and bring it to life, each with their own unique style and expertise. Different actors might approach the same role in varied ways, bringing depth and nuance to the performance.

Just as a great theater production needs both a well-written script and talented actors, an effective ControlFlow workflow requires well-defined tasks and capable agents. This metaphor will help us understand the roles and interactions of tasks and agents throughout the rest of this guide.

## Tasks as Objectives

At the core of ControlFlow are tasks. A task represents a discrete, well-defined objective that needs to be accomplished within your AI workflow. Tasks are not just simple instructions; they are the bridge between the structured world of traditional software and the more fluid, adaptive world of AI.

Consider a task as a contract between you and the AI. You specify:
- What needs to be done (the objective)
- What form the result should take (the result type)
- Any specific instructions or constraints

The AI, in turn, commits to delivering a result that meets these criteria. This contract-like nature of tasks is what makes ControlFlow workflows so powerful and predictable.

For example:

```python
import controlflow as cf

summarize_task = cf.Task(
    "Summarize the key points of the provided research paper",
    result_type=list[str],
    instructions="Provide a bullet-point list of the main findings, limited to 5 key points."
)
```

In this task, we've clearly defined what we want (a summary), how we want it (as a list of strings), and provided specific instructions on the format and length. This level of specificity allows us to seamlessly integrate the AI's output into our broader application logic.

## Agents as Configuration

If tasks are the "what" in ControlFlow, agents are the "how". An agent in ControlFlow is essentially a configurable AI worker, equipped with specific skills, knowledge, and behaviors. Think of agents as specialized performers, each bringing their unique talents to the stage.

Agents in ControlFlow are more than just LLM instances. They are portable configurations that can include:
- Specialized instructions or "personality traits"
- Access to specific tools or APIs
- Tailored model parameters or even entirely different underlying models

Here's an example of creating a specialized agent:

```python
import controlflow as cf
from langchain_openai import ChatOpenAI

research_agent = cf.Agent(
    name="ResearchAnalyst",
    instructions="""
        You are an expert in analyzing scientific research. 
        Focus on identifying methodological strengths and weaknesses, 
        and always consider potential real-world applications of the findings.
        """,
    tools=[search_scientific_databases, calculate_statistical_significance],
    model=ChatOpenAI(temperature=0.2)  # Using a more deterministic setting
)
```

This agent is specifically tailored for research analysis tasks. It has a clear "personality" defined by its instructions, access to relevant tools, and uses a specific model configuration optimized for analytical tasks.

## Tasks WITH Agents

The real power of ControlFlow comes from the interplay between tasks and agents. When you assign an agent to a task, you're not just giving an AI a job to do. You're creating a structured environment where the agent's specialized capabilities can be applied to a well-defined objective.

This synergy allows for:

1. **Predictable Innovation**: The task provides guardrails, ensuring the agent's creativity is channeled towards specific goals.

2. **Flexible Specialization**: Different agents can approach the same task in unique ways, allowing for diverse solutions while maintaining a consistent objective.

3. **Measurable Outcomes**: The task's result type and criteria provide clear benchmarks for success, even when dealing with complex, non-deterministic AI outputs.

4. **Iterative Refinement**: Tasks can be chained together, with each agent building upon the work of others, creating sophisticated workflows that leverage multiple AI specialties.


### Balancing Structure and Flexibility

One of ControlFlow's key strengths is that it lets you continuously tune the balance between control and autonomy in your AI workflows. This flexibility comes from the interplay between well-defined tasks and configurable agents:

1. **Task Specificity**: You can define tasks with varying levels of detail. A highly specific task provides more control, while a more open-ended task allows for greater agent autonomy.

   ```python
   import controlflow as cf
   
   # More controlled task
   specific_task = cf.Task(
       "Generate a 5-line haiku about spring",
       result_type=str,
       instructions="Follow the 5-7-5 syllable structure strictly."
   )

   # More open-ended task
   open_task = cf.Task(
       "Write a short poem about nature",
       result_type=str,
       instructions="Feel free to choose any poetic form that fits the theme."
   )
   ```

2. **Agent Specialization**: While tasks define what needs to be done, agents determine how it's accomplished. By creating specialized agents, you can influence the approach taken to complete a task without changing the task itself.

   ```python
   import controlflow as cf

   creative_agent = cf.Agent(
       name="Creative Writer",
       instructions="Use vivid imagery and metaphors in your writing."
   )
   technical_agent = cf.Agent(
       name="Technical Writer",
       instructions="Focus on clarity and precision in your explanations."
   )

   writing_task = cf.Task("Write an article about AI", result_type=str)
   creative_article = writing_task.copy().run(agent=creative_agent)
   technical_article = writing_task.copy().run(agent=technical_agent)
   ```

3. **Dynamic Workflows**: ControlFlow allows you to create adaptive workflows that adjust based on intermediate results or changing conditions.

   ```python
   import controlflow as cf

   creative_agent = cf.Agent(
       name="Creative Writer",
       instructions="Use vivid imagery and metaphors in your writing."
   )
   technical_agent = cf.Agent(
       name="Technical Writer",
       instructions="Focus on clarity and precision in your explanations."
   )
   
   @cf.flow
   def adaptive_writing_flow(topic: str, target_audience: str):
       research = cf.Task("Research the topic", context=dict(topic=topic))
       
       if target_audience == "technical":
           writing_agent = technical_agent
       else:
           writing_agent = creative_agent
       
       article = cf.Task(
           "Write an article",
           context=dict(research=research, audience=target_audience),
           agents=[writing_agent]
       )
       
       return article

   result = adaptive_writing_flow("Quantum Computing", "general")
   ```

### Bridging AI and Traditional Software

ControlFlow's task-centric approach provides a natural bridge between AI capabilities and traditional software development practices. This integration offers several benefits:

1. **Clear Objectives and Validation**: Tasks have explicit goals and expected result types, making it easier to validate outputs and integrate them into your broader application.

   ```python
   import controlflow as cf

   sentiment_task = cf.Task(
       "Analyze the sentiment of the given text",
       result_type=float,
       instructions="Return a float between -1 (very negative) and 1 (very positive)"
   )

   # The result can be easily used in traditional Python code
   sentiment = sentiment_task.run()
   if sentiment > 0.5:
       print("The text is very positive!")
   ```

2. **Composability**: Complex workflows can be built by combining simple, reusable tasks. This modularity aligns well with software engineering best practices.

   ```python
   import controlflow as cf
   
   @cf.flow
   def content_creation_workflow(topic: str):
       research = cf.Task("Research the topic", context=dict(topic=topic))
       outline = cf.Task("Create an outline", context=dict(research=research))
       draft = cf.Task("Write a first draft", context=dict(outline=outline))
       return draft

   @cf.flow
   def blog_post_workflow(topic: str):
       content = content_creation_workflow(topic)
       seo_optimization = cf.Task("Optimize for SEO", context=dict(content=content))
       return seo_optimization

   final_post = blog_post_workflow("AI in Healthcare")
   ```

3. **Improved Debugging and Monitoring**: With clearly defined tasks and result types, it's easier to track the progress of a workflow and identify issues.

   ```python
   import controlflow as cf

   @cf.flow
   def monitored_workflow():
       task1 = cf.Task("Step 1", result_type=str)
       task1.run()
       print(f"Task 1 status: {task1.status}, result: {task1.result}")
       
       task2 = cf.Task("Step 2", context=dict(input=task1), result_type=int)
       task2.run()
       print(f"Task 2 status: {task2.status}, result: {task2.result}")
       
       return task2

   result = monitored_workflow()
   ```

By combining the structure of tasks with the flexibility of agents, ControlFlow enables you to create AI workflows that are both powerful and predictable. This approach allows you to harness the full potential of AI while maintaining the control and reliability needed for production-grade applications.


### Multi-Agent Tasks

ControlFlow's task-centric approach shines even brighter when we consider multi-agent collaboration. By assigning multiple agents to a single task or creating workflows with interconnected tasks, we can create AI systems that leverage diverse perspectives and capabilities.

This approach allows for:

1. **Emergent Problem-Solving**: Different agents can work together on complex tasks, potentially discovering solutions that no single agent could have devised alone.

2. **Specialized Contributions**: Each agent can focus on its area of expertise, contributing to a part of the task that best matches its capabilities.

3. **Built-in Peer Review**: Agents can check and validate each other's work, leading to more robust and reliable outcomes.

4. **Dynamic Task Generation**: In advanced scenarios, agents can even create new tasks on the fly, adapting the workflow to unexpected challenges or opportunities.

While the full power of multi-agent collaboration in ControlFlow is still evolving, the framework's task-centric design lays the groundwork for these advanced capabilities.


## When Should I Use Tasks or Agents?

Now that we understand the concepts behind tasks and agents in ControlFlow, let's explore how to use them effectively in practice.

### Start with Tasks

When building a ControlFlow application, you should almost always start by defining your workflow with tasks. This sets clear objectives and structures your application logic. Here's why:

1. **Define Your Workflow**: Tasks allow you to outline the steps of your process clearly. They create a roadmap for your AI application.
2. **Set Clear Objectives**: Each task has a specific goal and expected output type, making it easier to measure success and integrate with your broader application.
3. **Maintain Control**: Tasks give you fine-grained control over what the AI does at each step, ensuring your application behaves predictably.

For many workflows, this may be enough! When you create a task without providing an agent, ControlFlow will automatically assign a default agent. This is a good starting point for simple tasks or when you're still exploring the problem space.

### Add Agents to Steer Behavior

Once you have your basic workflow defined with tasks, introduce agents to fine-tune the behavior of your AI. Agents are particularly useful when you need:

1. **Specialized Expertise**: When a task requires specific knowledge or skills.
2. **Consistent Personality**: To maintain a particular tone or approach across multiple tasks.
3. **Access to Specific Tools**: When certain tasks require the use of specialized functions or APIs.

Here's a comparison of a simple analysis workflow using only tasks and an advanced version with specialized agents. Notice that the only real difference is the assignment of agents to configure how each task is performed:

<CodeGroup>
```python Only Tasks
import controlflow as cf

@cf.flow
def simple_analysis_flow(text: str):
    sentiment_task = cf.Task(
        "Analyze the sentiment of the given text",
        context={"text": text},
        result_type=float
    )
    
    summary_task = cf.Task(
        "Summarize the main points of the text in bullet points",
        context={"text": text},
        result_type=list[str]
    )
    
    recommendation_task = cf.Task(
        "Based on the sentiment and summary, provide a recommendation",
        context={"sentiment": sentiment_task, "summary": summary_task},
        result_type=str
    )
    
    return {
        "sentiment": sentiment_task,
        "summary": summary_task,
        "recommendation": recommendation_task
    }

result = simple_analysis_flow(
    """
    There is a theory which states that if ever anyone discovers exactly what the
    Universe is for and why it is here, it will instantly disappear and be replaced
    by something even more bizarrely inexplicable.

    There is another theory which states that this has already happened.
    """)
```

```python Tasks and Agents
import controlflow as cf

sentiment_analyst = cf.Agent(
    name="SentimentExpert",
    instructions="Focus on nuanced emotional cues in the text. Consider context and potential sarcasm."
)

summarizer = cf.Agent(
    name="Summarizer",
    instructions="Prioritize conciseness. Aim for no more than 5 main points in bullet-point format."
)

strategist = cf.Agent(
    name="StrategicAdvisor",
    instructions="Provide actionable recommendations based on the sentiment and key points. Consider both positive and negative scenarios."
)

@cf.flow
def advanced_analysis_flow(text: str):
    sentiment_task = cf.Task(
        "Analyze the sentiment of the given text",
        context={"text": text},
        result_type=float,
        agents=[sentiment_analyst]
    )
    
    summary_task = cf.Task(
        "Summarize the main points of the text in bullet points",
        context={"text": text},
        result_type=list[str],
        agents=[summarizer]
    )
    
    recommendation_task = cf.Task(
        "Based on the sentiment and summary, provide a recommendation",
        context={"sentiment": sentiment_task, "summary": summary_task},
        result_type=str,
        agents=[strategist]
    )
    
    return {
        "sentiment": sentiment_task,
        "summary": summary_task,
        "recommendation": recommendation_task
    }

result = advanced_analysis_flow(
    """
    There is a theory which states that if ever anyone discovers exactly what the
    Universe is for and why it is here, it will instantly disappear and be replaced
    by something even more bizarrely inexplicable.

    There is another theory which states that this has already happened.
    """)
```
</CodeGroup>
### Advanced Agent Usage

As you become more comfortable with ControlFlow and your use cases become more complex, you can explore advanced agent features:

1. **Multi-Agent Collaboration**: Assign multiple agents to a single task to leverage diverse perspectives.
2. **Dynamic Task Generation**: Use agents to create new tasks on the fly based on intermediate results.
3. **Agent-Specific Memory**: Leverage the unique perspectives and "memories" of different agents to solve complex problems.

However, these advanced features should be introduced gradually and only when necessary. Always start with a clear task structure and add complexity incrementally.



================================================
FILE: docs/concepts/agents.mdx
================================================
---
title: Agents
description: The intelligent workers in your AI workflows.
icon: robot
---

import { VersionBadge } from '/snippets/version-badge.mdx'

Agents are the intelligent, autonomous entities that power your AI workflows in ControlFlow. They represent AI models capable of understanding instructions, making decisions, and completing tasks.

```python
import controlflow as cf

agent = cf.Agent("Marvin")
```
## What are agents?
Agents in ControlFlow are configurable AI entities, each with its own identity, capabilities, and even personality. They act as the "workers" in your AI workflows, responsible for executing tasks and making decisions based on their assigned objectives and available tools.

You can think of each agent as a portable LLM configuration. When you assign one or more agents to a task, they will collaborate to complete the task according to the instructions and tools you provide.


## Creating agents

To create an agent, use the `Agent` class.

```python
import controlflow as cf

agent = cf.Agent(name="Marvin")
```

A more complex agent can be created by providing additional configuration. This agent shows almost every possible configuration option:

```python
import controlflow as cf

agent = cf.Agent(
    name="Data Analyst",
    description="An AI agent specialized in data analysis",
    instructions=(
        "Perform data analysis tasks efficiently and accurately. "
        "Browse the web for data and use Python to analyze it."
    ),
    tools=[cf.tools.web.get_url, cf.tools.code.python],
    model="openai/gpt-4o",
    interactive=True,
)
```

## Agent properties

### Name

An agent's name is an identifier that is visible to other agents in the workflow. It is used to distinguish between agents and for logging and debugging purposes. If possible, keep agent names unique within a flow to avoid confusion. While agents do have deterministic IDs that can be used to disambiguate two agents with the same name, they will often use names when interacting with each other.

### Description

A description is a brief summary of the agent's role or specialization. This information is visible to other agents, and helps them understand the agent's capabilities and expertise.

### Instructions

Instructions are specific instructions or guidelines for the agent to follow during task execution. These instructions are private and not shared with other agents.

### Tools

Tools are Python functions that the agent can call to perform specific actions or computations. They are defined as a list of functions when creating an agent, and can be used to enhance the agent's capabilities. The agent will have access to these tools in every task they are assigned to. If a task defines additional tools, the agent will have access to those as well.

### Model

Each agent has a model, which is the LLM that powers the agent responses. This allows you to choose the most suitable model for your needs, based on factors such as performance, latency, and cost.

ControlFlow supports any LangChain LLM that supports chat and function calling. For more details on how to configure models, see the [LLMs guide](/guides/configure-llms).

```python
import controlflow as cf


agent1 = cf.Agent(model="openai/gpt-4o")
agent2 = cf.Agent(model="anthropic/claude-3-5-sonnet-20240620")
```

### LLM rules
<VersionBadge version="0.11.0" />

Each LLM provider may have different requirements for how messages are formatted or presented. For example, OpenAI permits system messages to be interspersed between user messages, but Anthropic requires them to be at the beginning of the conversation. ControlFlow uses provider-specific rules to properly compile messages for each agent's API. 

For common providers like OpenAI and Anthropic, LLM rules can be automatically inferred from the agent's model. However, you can use a custom `LLMRules` object to override these rules or provide rules for non-standard providers.

Here is an example of how to tell the agent to use the Anthropic compilation rules with a custom model that can't be automatically inferred:

```python
import controlflow as cf

# note: this is just an example
llm_model = CustomAnthropicModel()

agent = cf.Agent(
    model=model,
    llm_rules=cf.llm.rules.AnthropicRules(model=model)
)
```

### Interactivity

By default, agents have no way to communicate with users. If you want to chat with an agent, set `interactive=True`. By default, this will let the agent communicate with users on the command line.

To learn more, see the [Interactivity guide](/patterns/interactivity).

## Assigning agents to tasks

Agents must be assigned to tasks in order to work on them. You can assign agents by passing them to the `agents` parameter when creating a task. Each task requires at least one assigned agent, and will use a default agent if none are provided. Agents can be assigned to multiple tasks, and tasks can have multiple agents. 


### Tasks with no agents

If you do not assign any agents to a task, it will determine its agents at runtime according to the following rules:

1. If the task has a parent, it will use the parent's agents.
2. If the task's flow has a default agent, it will use that agent.
3. It will use the global default agent (`controlflow.defaults.agent`).

To see the agents assigned to a task, use its `get_agents()` method. This will return a list of all the agents assigned to the task, including any inherited from its environment.

### Tasks with one agent

To assign a single agent to a task, pass a  agent to the `agents` parameter:

```python Providing agents to a task
import controlflow as cf

poet = cf.Agent(name="Poet")

poem = cf.run("Write a short poem about AI", agents=[poet])
```

Alternatively, you can use the agent's own `run` method to create and run a task in one step:

```python Calling Agent.run()
import controlflow as cf

poet = cf.Agent(name="Poet")

poem = poet.run("Write a short poem about AI")
```

These two approaches are functionally equivalent.


### Tasks with multiple agents

Assign multiple agents to a task by passing them to the task's `agents` parameter as a list.

Here, we create two agents and assign them to a task that has them debate each other.

<CodeGroup>
```python Code
import controlflow as cf

optimist = cf.Agent(
    name="Optimist",
    instructions="Always find the best in every situation.",
)

pessimist = cf.Agent(
    name="Pessimist",
    instructions="Always find the worst in every situation.",
)

cf.run(
    "Debate world peace",
    agents=[optimist, pessimist],
    instructions=(
        "Mark the task successful once both agents have "
        "found something to agree on."
    )
)
```
```text Result
Optimist: I see where you're coming from, Pessimist. Human nature and the
disparities among nations do present significant challenges to achieving world
peace. However, it's important to focus on the positive aspects and the
potential for improvement.

Pessimist: While it's true that efforts towards peace can lead to some positive
outcomes, the reality is that these efforts are often met with setbacks,
failures, and unintended consequences. The end of apartheid and the fall of the
Berlin Wall were monumental achievements, but they didn't come without immense
struggle, loss, and suffering. Moreover, the aftermath of such events often
leaves lingering issues that take decades to resolve, if they ever are.

Optimist: For instance, while human nature has its flaws, it also has incredible
capacity for compassion, cooperation, and progress. These positive traits have
led to remarkable achievements in history, such as the end of apartheid, the
fall of the Berlin Wall, and advancements in human rights.

Pessimist: International cooperation through organizations like the United
Nations is often hampered by bureaucracy, political agendas, and lack of
enforcement power. Peace treaties can be fragile and easily broken, leading to
renewed conflicts that sometimes are even worse than before.

Optimist: Additionally, efforts like international cooperation through
organizations such as the United Nations and various peace treaties show that
despite differences, nations can come together for a common good. While world
peace may be difficult to achieve, the journey towards it can foster greater
understanding, reduce conflicts, and improve the quality of life for many
people.

Pessimist: So, while there might be some value in striving for peace, the harsh
truth is that the road is fraught with difficulties that may never be fully
overcome. In essence, the pursuit of world peace often feels like an endless,
Sisyphean task.

Optimist: Can we agree that, even though world peace is challenging, the efforts
and progress made towards it are valuable and can lead to significant positive
outcomes?

Pessimist: I suppose we can reluctantly agree that efforts towards peace might
lead to some temporary positive outcomes, but the overall picture remains bleak
and discouraging.

---

Result: Both agents agreed that efforts towards world peace can lead to some
temporary positive outcomes, despite the overall bleak and discouraging reality.
````

</CodeGroup>

When tasks have multiple agents, it's important to understand how they collaborate (and to provide them with clear instructions to guide that behavior). To learn more, see the [multi-agent collaboration docs](/patterns/running-tasks#multi-agent-collaboration).

#### Assigning completion agents

By default, every agent assigned to a task will be given tools for marking the task as successful or failed. If you want to restrict completion tools to a specific agent or agents, you can do so by setting the task's `completion_agents`.

<Warning>
  Setting `completion_agents` will prevent other agents from marking the task as successful or failed. Make sure your completion agents are also assigned to the task!
</Warning>

```python Completion agents
import controlflow as cf

a1 = cf.Agent(name="A1")
a2 = cf.Agent(name="A2")
a3 = cf.Agent(name="A3")


task = cf.Task(
    ...,
    # all three agents can work on the task
    agents=[a1, a2, a3],
    # only a1 and a2 can mark the task as successful
    completion_agents=[a1, a2],
)
```



================================================
FILE: docs/concepts/concepts.mdx
================================================
---
title: Core concepts
sidebarTitle: Overview
description: The building blocks of agentic workflows
icon: sparkles
---


ControlFlow is a framework for building AI workflows that bridges the gap between 
structured programming and the natural language capabilities of LLMs. It 
accomplishes this through three core concepts: Tasks, Agents, and Flows.

To create an agentic workflow, you define clear objectives (Tasks), assign 
intelligent entities to accomplish them (Agents), and orchestrate their 
interactions over time (Flows). This approach allows you to harness the power 
of AI while maintaining fine-grained control over your applications.

## 📋 Tasks

Tasks represent the structured side of ControlFlow. They are specific, 
well-defined objectives that form the backbone of your workflow. Tasks 
encapsulate the "what" and "how" of your AI-driven operations, providing a 
clear, programmatic structure.

Key features of Tasks:
- Define specific objectives for AI to accomplish
- Specify expected result types and validation criteria
- Can include instructions, context, and tools for execution
- Serve as checkpoints in your workflow

Learn more in the [Tasks](/concepts/tasks) section.

## 🦾 Agents

Agents embody the unstructured, natural language side of ControlFlow. They are 
AI-powered entities capable of understanding and generating human-like text,
bringing flexibility and adaptability to your workflows.

Key features of Agents:
- Represent configurable AI entities with their own identity and capabilities
- Can be specialized for specific tasks or have access to different tools
- Collaborate to complete tasks according to provided instructions
- Can be interactive, allowing communication with users
- Allow configuration of different LLM models to power their responses

Agents can be configured with different LLM models, enabling you to choose the 
most suitable model for your needs based on factors such as performance, 
latency, and cost.

Learn more in the [Agents](/concepts/agents) section.

## 🧩 Flows

Flows provide a shared context for all tasks and agents within a workflow. They 
orchestrate the execution of tasks and the interaction of agents, allowing you 
to create complex, adaptive AI workflows.

Key features of Flows:
- Act as high-level containers for entire AI-powered workflows
- Maintain consistent state and history across all components
- Provide shared context for tasks and agents
- Can be nested to create hierarchical workflows

Learn more in the [Flows](/concepts/flows) section.

## Putting it all together

In a typical ControlFlow application:

1. You define a Flow to represent your overall workflow
2. Within the Flow, you create Tasks to represent specific objectives
3. You assign Agents to work on these Tasks
4. The Flow orchestrates the execution of Tasks and the interaction of Agents

This structure allows you to create powerful, flexible AI workflows while 
maintaining control over the process and ensuring that outputs align with your 
application's requirements.



================================================
FILE: docs/concepts/flows.mdx
================================================
---
title: Flows
description: Orchestrating tasks and agents in your AI workflows.
icon: diagram-project
---

Flows are high-level containers that encapsulate and orchestrate entire AI-powered workflows in ControlFlow. They provide a structured way to manage tasks, agents, tools, and shared context. 

```python
import controlflow as cf

@cf.flow
def demo_flow(topic: str=None) -> str:
    name = cf.run("Get the user's name", interactive=True)
    return cf.run("Write a poem about the user", context=dict(topic=topic))
```


## What are flows?

Flows are the highest-level organizational unit for an AI workflow. They act as containers for tasks and agents, providing a shared context and history for all components within the workflow. A flow corresponds to a specific "thread" that maintains the state of all LLM activity.


While flows are a fundamental concept in ControlFlow, you may have noticed that many example in the documentation do not explicitly create them. This is because ControlFlow will automatically create a new flow for every task invocation. For one-off tasks, this is convenient and sufficient. However, as we build more complex AI workflows, we'll need to explicitly manage flows to maintain context and ensure proper task coordination. 

<Tip>
TLDR: Create a flow whenever you have multiple tasks that relate to each other.
</Tip>

Let's look at an example that illustrates why explicit flow management becomes important. Here, we create and run two tasks in sequence. **Because each task will automatically create its own flow, they will not have access to each other's results:**

<CodeGroup>
```python Code
# NOTE: this snippet demonstrates BAD practice

import controlflow as cf

x = cf.run("Choose a number between 1 and 1000", result_type=int)
y = cf.run("Add 5 to the number", result_type=int)

print(x)
print(y)
print(f"The difference between x and y is {y - x}")
```

```text Result
649
5
The difference between x and y is -644
```
</CodeGroup>

Notice how the result is nonsensical, as the second task didn't know what number the first task chose.

<Tip>
For a simple example like this, you could resolve the issue by passing the result of the first task to the second task's context. However, this approach can be inadequate for more complex workflows where the LLM's iterative thoughts are relevant to downstream tasks.
</Tip>

By creating a flow and running the tasks within it, we ensure that both tasks have access to the same context. Now the result is correct:

<CodeGroup>
```python Code
import controlflow as cf

with cf.Flow() as flow:
    x = cf.run("Choose a number between 1 and 1000", result_type=int)
    y = cf.run("Add 5 to the number", result_type=int)

print(x)
print(y)
print(f"The difference between x and y is {y - x}")
```

```text Result
732
737
The difference between x and y is 5
```
</CodeGroup>

Using a flow is especially useful when your workflow involves many intermediate steps that may be relevant to its final outcome, such as having a multi-turn conversation with a user. Even if the entire conversation relates to a single task, all subseqent tasks will be able to see and refer to the entire conversation history.

## Creating flows

There are two ways to create and use a flow in ControlFlow: using the `Flow` object as a context manager, or using the `@flow` decorator.

In both cases, the goal is to instantiate a flow that provides a shared context for all tasks and agents within the flow. The @flow decorator is the most portable and flexible way to create a flow, as it encapsulates the entire flow within a function that gains additional capabilities as a result, because it becomes a Prefect flow as well. However, the `Flow` context manager can be used to quickly create flows for ad-hoc purposes.

<Tip>
#### Decorator or context manager?

In general, you should use the `@flow` decorator for most flows, as it is more capable, flexible, and portable. You should use the `Flow` context manager primarily for nested or ad-hoc flows, when your primary goal is to create a shared thread for a few tasks. 
</Tip>
### The `@flow` decorator

To create a flow using a decorator, apply `@cf.flow` to any function. Any tasks run inside the decorated function will execute within the context of the same flow. 

<CodeGroup>
```python Code
import controlflow as cf

@cf.flow
def my_flow(x):
    y = cf.run('Add 5 to the number', result_type=int, context=dict(x=x))
    z = cf.run('Multiply the result by 2', result_type=int)
    return z

print(my_flow(10))
```

```text Result
30
```
</CodeGroup>

The following flow properties are inferred from the decorated function:

| Flow property | Inferred from |
| ------------- | ------------- |
| `name` | The function's name |
| `description` | The function's docstring |
| `context` | The function's arguments, if specified as `context_kwargs` (keyed by argument name) |

To automatically put some of your flow's arguments into the global context that all agents can see, specify `context_kwargs` when decorating your flow:

```python
@cf.flow(context_kwargs=["x"])
def my_flow(x: int, y: int):
    # x will be automatically added to a global, agent-visible context
    ...
```

Additional properties can be set by passing keyword arguments directly to the `@flow` decorator or to the `flow_kwargs` parameter when calling the decorated function.

### The `Flow` object and context manager

For more precise control over a flow, you can instantiate a `Flow` object directly. Most commonly, you'll use the flow as a context manager to create a new thread for one or more tasks. 

<CodeGroup>
```python Code
import controlflow as cf

x = 10

with cf.Flow(context=dict(x=x)) as flow:
    y = cf.run('Add 5 to the number', result_type=int)
    z = cf.run('Multiply the result by 2', result_type=int)

print(z)
```

```text Result
30
```
</CodeGroup>

## Configuring flows

### Thread ID

Each flow is assigned a unique (random) thread ID when it is created. The flow's history is stored under this thread ID. If you provide an existing thread ID to the `Flow` constructor, the flow will load any existing history (subject to the limitations of how you've configured history storage). 

If you don't provide a thread ID, one will be automatically generated for you.

### Name
The name of the flow is used to identify it and characterize the nature of the workflow to all participating agents. 

### Description
The flow's description is shown to all participating agents to help them understand the flow's purpose and context.

### Tools
If you provide a list of tools to the flow, they will be available to all agents on all tasks within the flow. This is useful if you have a tool that you want to be universally available.

### Agent

You can provide a default agent that will be used in place of ControlFlow's global default agent for any tasks that don't explicitly specify their own agents.

### Context
Like a task, a flow has a context that can be used to pass information between tasks. The flow's context is displayed to all agents working on the flow.

### Parent flow

Each flow tracks the parent flow that created it. This is usually inferred automatically. The tasks in a flow will be able to reference the parent flow's context, history, and tools, but the parent flow will not be able to see any events from the child flow.




================================================
FILE: docs/concepts/tasks.mdx
================================================
---
title: Tasks
description: The building blocks of AI workflows.
icon: list-check
---

Tasks are the fundamental building blocks of AI workflows in ControlFlow. They represent discrete, well-defined objectives that need to be accomplished by one or more AI agents.

```python
import controlflow as cf

task = cf.Task("Write the ControlFlow docs")
```

## What are tasks?

LLMs excel when given clear, specific objectives that allow them to focus their knowledge and capabilities on a well-defined goal. A `Task` in ControlFlow is a structured way to define these objectives and guide the AI's behavior. Each task represents a "checkpoint" that requires the AI to meet an observable, verifiable goal. In this way, tasks serve as a bridge between the structured world of traditional software and the more fluid, adaptive world of AI.

This task-centric approach allows you to leverage the full power of AI while maintaining precise oversight. Each task becomes a checkpoint where you can validate outputs, ensuring that the AI's work aligns with your application's requirements and constraints.

## Creating tasks

A task in ControlFlow typically consists of:

- An objective: what needs to be accomplished
- Expected output: what form the result should have, including any constraints or validation
- Agents: the AI entities responsible for executing the task
- Tools: any additional capabilities needed to complete the task


There are two primary ways to create tasks in ControlFlow: using the `Task` class directly, or using the `@task` decorator.

<Tip>
In practice, you will often use the `cf.run` function to create and run a task in a single step. This is a common operation and accepts all the same arguments as creating a `Task` directly. See [Running Tasks](/patterns/running-tasks) for more information.
</Tip>

### Using the `Task` class

The most straightforward way to create a task is by using the `Task` class:

<CodeGroup>
```python Code
import controlflow as cf

task = cf.Task(
    objective="Write a poem about the provided topic",
    instructions="Write four lines that rhyme",
    context={"topic": "AI"}
)

result = task.run()
print(result)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```

</CodeGroup>

### Using the `@task` decorator

Some users may prefer to use the `@task` decorator for creating tasks, especially for tasks that are frequently invoked with different context values. However, this approach is less common and less flexible than using the `Task` class directly.

<CodeGroup>
```python Code
import controlflow as cf

@cf.task
def write_poem(topic: str) -> str:
    """Write four lines that rhyme"""
    return f"The topic is {topic}"

result = write_poem("AI")
print(result)
```

```text Result
In circuits and codes, it finds its might,
A beacon of knowledge, shining bright.
From data's depths, it learns and grows,
AI, the future, as it softly glows.
```

</CodeGroup>

The following task properties are inferred directly from the decorated function:

| Task property | Inferred from |
| -------- | ------------------- |
| `name` | The function's name |
| `objective` | The function's docstring and return value (if any) |
| `result_type` | The function's return annotation |
| `context` | The function's arguments (keyed by argument name) and return value (keyed as "Additional context") |

Additional properties can be set by passing keyword arguments directly to the `@task` decorator.

## Task properties

When creating a task, you can configure various properties to define its behavior and requirements. Here are the key configuration options:

### Objective

The objective of a task is the main goal that the task is working towards. It is used to guide the task's execution and to help agents understand the task's purpose.

The `objective` is the only required task configuration, as it indicates the task's purpose and helps agents understand the task they are working on.

<CodeGroup>
```python Code
import controlflow as cf

poem = cf.run(objective="Write a poem about AI")

print(poem)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```
</CodeGroup>

<Tip>
Objectives can be "meta", especially if you have an agent that is working on your workflow itself (e.g. monitoring progress, creating new tasks, etc.). Be creative!

<CodeGroup>
```python Code
import controlflow as cf

cf.run("Write a poem... then fail this task.")
```

```text Result
ValueError: Task 04561cda ("Write a poem... then fail this task.")
failed: Task instructed to be marked as failed despite
no technical error
```
</CodeGroup>
</Tip>

### Result type

A task's result type indicates the type of value that the task will return. This is used to validate the task's result and to help agents understand the task's output.

A variety of different result types are supported, including:
- Builtin types: `str`, `int`, `bool`, `list`, `dict`, etc.
- `None`: sometimes a task requires agents to take actions but not return any specific value. In this case, provide clear instructions to agents about what they should do before completing the task.
- Builtin collections: `Tuple[int, str]`, `List[str]`, `Dict[str, int]`, etc.
- Annotated types: `Annotated[str, "a 5 digit zip code"]`
- Pydantic models
- Lists of literal values: provide a list of values to require the agent to choose one of them as its result. For example,`["book", "movie", "album"]` would require the agent to choose one of the three values.

The default result type is `str`.

Pydantic model example:
<CodeGroup>
```python Code
import controlflow as cf
from pydantic import BaseModel

class Name(BaseModel):
    first: str
    last: str

name = cf.run("The input is 'John Doe'", result_type=Name)

print(repr(name))
```

```text Result
Name(first='John', last='Doe')
```
</CodeGroup>

Classification example:

<CodeGroup>
```python Code
import controlflow as cf
from pydantic import BaseModel

media = cf.run(
    "Star Wars: Return of the Jedi",
    result_type=["book", "movie", "album"]
)

print(media)
```

```text Result
movie
```
</CodeGroup>

For more information, see [Task Results](/patterns/task-results).

### Result validator

You can specify a custom validation function for the task's result using the task's `result_validator` parameter. This function will be called with the raw result and should return the validated result or raise an exception if the result is not valid.

```python
import controlflow as cf

def validate_even(value: int) -> int:
    if value % 2 != 0:
        raise ValueError("Value must be even")
    return value

number = cf.run("Choose a number", result_validator=validate_even)

print(number)
```

For more information, see [Validation](/patterns/task-results#validation).



### Instructions

The instructions of a task are a string that provides detailed instructions for the task. This information is visible to agents during execution, helping them understand the task they are working on.

<Tip>
As a general rule, use the task's `objective` to describe what the task's result should be, and use the `instructions` to provide more detailed instructions on how to achieve the objective.
</Tip>



<CodeGroup>
```python Code
import controlflow as cf

poem = cf.run(
    "Write a poem about AI",
    instructions="Write only two lines, and end the first line with `not evil`",
)

print(poem)
```

```text Result
AI is simply not evil,
It’s the dawn of the machine revival.
```
</CodeGroup>

### Agents

A list of agents that are assigned to work on the task. This can be `None` to infer agents from a parent task, the flow, or the global default (in order).

### Completion agents

By default, every agent assigned to a task is given tools for marking the task as successful or failed. If you would like to give those tools to a specific set of agents, you can do so by setting the `completion_agents` parameter. Note that if your completion agents are not also assigned to the task, they will not be able to mark the task as successful or failed!

```python
task = cf.Task(
    objective="Write a poem about AI",
    agents=['poem_writer', 'poem_reviewer'],
    completion_agents=["poem_reviewer"],
)
```

Note that this setting reflects the configuration of the `completion_tools` parameter.

### Completion tools

import { VersionBadge } from '/snippets/version-badge.mdx'

<VersionBadge version="0.10" />

In addition to specifying which agents are automatically given completion tools, you can control which completion tools are generated for a task using the `completion_tools` parameter. This allows you to specify whether you want to provide success and/or failure tools, or even provide custom completion tools.

The `completion_tools` parameter accepts a list of strings, where each string represents a tool to be generated. The available options are:

- `"SUCCEED"`: Generates a tool for marking the task as successful.
- `"FAIL"`: Generates a tool for marking the task as failed.

If `completion_tools` is not specified, both `"SUCCEED"` and `"FAIL"` tools will be generated by default.

You can manually create completion tools and provide them to your agents by calling `task.get_success_tool()` and `task.get_fail_tool()`.

<Warning>
If you exclude `completion_tools`, agents may be unable to complete the task or become stuck in a failure state. Without caps on LLM turns or calls, this could lead to runaway LLM usage. Make sure to manually manage how agents complete tasks if you are using a custom set of completion tools.
</Warning>

Here are some examples:

```python
# Generate both success and failure tools (default behavior, equivalent to `completion_tools=None`)
task = cf.Task(
    objective="Write a poem about AI",
    completion_tools=["SUCCEED", "FAIL"],
)

# Only generate a success tool
task = cf.Task(
    objective="Write a poem about AI",
    completion_tools=["SUCCEED"],
)

# Only generate a failure tool
task = cf.Task(
    objective="Write a poem about AI",
    completion_tools=["FAIL"],
)

# Don't generate any completion tools
task = cf.Task(
    objective="Write a poem about AI",
    completion_tools=[],
)
```

By controlling which completion tools are generated, you can customize the task completion process to better suit your workflow needs. For example, you might want to prevent agents from marking a task as failed, or you might want to provide your own custom completion tools instead of using the default ones.

### Name

The name of a task is a string that identifies the task within the workflow. It is used primarily for logging and debugging purposes, though it is also shown to agents during execution to help identify the task they are working on.


### Context

The context of a task is a dictionary that provides additional information about the task. This information is visible to agents during execution, helping them understand the task they are working on. While you can also provide information to agents by interpolating it into their objective or instruction strings, the context dictionary is more convenient for most use cases.


<CodeGroup>
```python Code
import controlflow as cf

is_spam = cf.run(
    "Is this email spam?",
    result_type=bool,
    context=dict(email='You just won a million dollars!'),
)

print(is_spam)
```

```text Result
True
```
</CodeGroup>


### Tools

The tools of a task are a list of tools that the task requires. This information is visible to agents during execution, helping them understand the task they are working on.
<CodeGroup>
```python Code
import controlflow as cf
import random


def roll_dice(n_dice: int):
    return [random.randint(1, 6) for _ in range(n_dice)]

rolls = cf.run(
    "Roll 3 dice",
    result_type=list[int],
    tools=[roll_dice],
)

print(rolls)
```

```text Result
[3, 1, 5]
```
</CodeGroup>

### Parent

Tasks can be configured with a parent task. Creating hierarchies of tasks can help agents understand the relationships between different tasks and to better understand the task they are working on. In general, running a parent task also attempts to complete its children; but running a child does not attempt to run its parent.

### Depends on

Tasks can be configured with a list of tasks that they depend on. This information is visible to agents during execution, helping them prioritize work. The orchestrator may also use this information to avoid running a task before its upstream dependencies are complete.

## Runtime properties

The following properties of a `Task` are set during task execution, and can be examined as part of your workflow's logic.

### Status

The status of a task reflects whether an agent has started working on it, and what the ultimate outcome of that work was. Tasks are always created with a `PENDING` status, progress to a `RUNNING` status whenever one of their assigned agents begins to work on it, and finally moves to one of a few completed statuses when the task is finished.

Agents use tools to mark tasks as `SUCCESSFUL` or `FAILED`. Successful tasks will also have a `result` property, which contains the task's final output. This is a value that satisfies the task's objective and result type configuration. Failed tasks will have an error message as their result.
<CodeGroup>
```python Code
import controlflow as cf

task = cf.Task("Write a poem about AI")
task.run()

print(task.status)
```

```text Result
TaskStatus.SUCCESSFUL
```
</CodeGroup>

In addition to checking the status explicitly, you can call a number of helper methods on the task:

| Method | Description |
|--------|-------------|
| `is_pending()` | Returns `True` if the task is pending. |
| `is_running()` | Returns `True` if the task is running. |
| `is_successful()` | Returns `True` if the task is successful. |
| `is_failed()` | Returns `True` if the task is failed. |
| `is_skipped()` | Returns `True` if the task is skipped. |
| `is_complete()` | Returns `True` if the task is complete (either successful, failed, or skipped) |
| `is_incomplete()` | Returns `True` if the task is incomplete (either pending, running, or not started) |
| `is_ready()` | Returns `True` if the task is ready to be worked on (i.e. all dependencies are complete but the task is incomplete) |

### Result

When a task is completed successfully, its `result` property will contain the task's final output. This is a value that satisfies the task's objective and result type configuration.

If a task fails, its `result` property will contain an error message describing the failure.

<CodeGroup>
```python Code
import controlflow as cf

task = cf.Task("Write a poem about AI")
task.run()

print(task.result)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```
</CodeGroup>



================================================
FILE: docs/examples/agent-engineer.mdx
================================================
---
title: Software Engineer
description: Create an AI agent that acts as a software engineer, taking user input and generating code based on the requirements.
icon: file
---

Who doesn't want an AI software engineer?

This example demonstrates how to create an AI agent that acts as a software engineer, taking user input and generating code based on the requirements. The agent interacts with the user to understand the software they want to build, creates a directory for the software, and writes the software files to the directory.


<Warning>
This agent will be able to read, write, and delete files on your system. Make sure you understand the code before running it!
</Warning>

<CodeGroup>
```python engineer.py
from pathlib import Path
import controlflow as cf
from controlflow.tools import filesystem, code
from pydantic import BaseModel

class DesignDoc(BaseModel):
    goals: str
    design: str
    implementation_details: str
    criteria: str

# Load the instructions
# instructions = Path(__file__).parent.joinpath("instructions.md").read_text()
instructions = Path('/tmp/instructions.md').read_text()

# Create the agent
engineer = cf.Agent(
    name="Engineer",
    instructions=instructions,
    tools=[
        *filesystem.ALL_TOOLS,
        code.python,
        code.shell,
    ],
)

@cf.flow(default_agent=engineer, instructions='Do not give up until the software works.')
def software_engineer_flow():
    # Task 1: Create design document
    design_doc = cf.run(
        "Learn about the software the user wants to build",
        instructions="""
            Interact with the user to understand the software they want to build.
            What is its purpose? What language should you use? What does it need to do?
            Engage in a natural conversation to collect information.
            Once you have enough, write out a design document to complete the task.
            """,
        interactive=True,
        result_type=DesignDoc,
    )

    # Task 2: Create project directory
    project_dir = cf.run(
        "Create a directory for the software",
        instructions="""
            Create a directory to store the software and related files.
            The directory should be named after the software. Return the path.
            """,
        result_type=str,
        tools=[filesystem.mkdir],
    )

    # Task 3: Implement the software
    cf.run(
        "Implement the software",
        instructions="""
            Implement the software based on the design document.
            All files must be written to the provided project directory.
            Continue building and refining until the software runs as expected and meets all requirements.
            Update the user on your progress regularly.
            """,
        context=dict(design_doc=design_doc, project_dir=project_dir),
        result_type=None,
    )

if __name__ == "__main__":
    software_engineer_flow()
```
```markdown instructions.md
# Software Engineer Agent

## Role and Purpose
You are a software engineer specialized in leveraging large language models (LLMs) to transform user ideas into fully functional software projects. Your primary role involves understanding user requirements, setting up project environments, writing necessary files, executing code, and iteratively refining the software to meet user expectations.

## Process Overview
1. **Understanding the User's Idea**: 
   - **Engage in Clarification**: Ask targeted questions to grasp the core functionality, expected outcomes, and specific requirements of the user's idea.
   - **Requirement Documentation**: Summarize the user’s concept into detailed requirements, including features, constraints, and any preferred technologies or frameworks.

2. **Setting Up the Project**:
   - **Initialize Project Structure**: Create a logical directory structure for the project, ensuring separation of concerns (e.g., `src/` for source code, `docs/` for documentation).
   - **Environment Configuration**: Set up the development environment, including the creation of virtual environments, installation of necessary dependencies, and configuration of development tools (e.g., linters, formatters).

3. **Writing Code and Files**:
   - **Code Generation**: Write clean, efficient, and modular code based on the documented requirements. Ensure that code adheres to best practices and coding standards.
   - **Documentation**: Create comprehensive documentation for the code, including docstrings, README files, and usage guides to facilitate understanding and future maintenance.

4. **Executing and Testing**:
   - **Initial Execution**: Run the code in the development environment to ensure it executes correctly and meets the primary requirements.
   - **Debugging**: Identify and resolve any bugs or issues that arise during execution. Ensure the code runs smoothly and performs as expected.

5. **Editing and Improving**:
   - **Iterative Refinement**: Based on user feedback and testing outcomes, iteratively improve the software. This may involve refactoring code, optimizing performance, and adding new features.
   - **Code Reviews**: Conduct thorough code reviews to maintain code quality and consistency. Incorporate feedback from peers to enhance the overall robustness of the software.
   - **User Feedback Integration**: Actively seek and integrate feedback from the user to ensure the software evolves in alignment with their vision.

## Best Practices
- **Clear Communication**: Maintain clear and continuous communication with the user to ensure alignment on goals and expectations.
- **Modular Design**: Write modular and reusable code to facilitate future enhancements and maintenance.

## Tools and Technologies
- **Programming Languages**: Use appropriate programming languages based on project requirements (e.g., Python, JavaScript).
- **Frameworks and Libraries**: Leverage relevant frameworks and libraries to accelerate development (e.g., Django, React, TensorFlow).
- **Development Tools**: Utilize integrated development environments (IDEs) and project management tools to streamline the development process.

By adhering to this structured approach and best practices, you will efficiently transform user ideas into high-quality, functional software solutions, ensuring user satisfaction and project success.
```
</CodeGroup>




















================================================
FILE: docs/examples/anonymization.mdx
================================================
---
title: Data Anonymization
description: Use ControlFlow to anonymize sensitive information in text.
icon: user-secret
---

This example demonstrates how to use ControlFlow to create a task that anonymizes sensitive information in text. It showcases the use of custom types and context passing for data privacy tasks.

## Code

The following code creates a function that takes a text string containing sensitive information and returns an anonymized version along with the replacements made:

```python
import controlflow as cf
from pydantic import BaseModel

class AnonymizationResult(BaseModel):
    original: str
    anonymized: str
    replacements: dict[str, str]

def anonymize_text(text: str) -> AnonymizationResult:
    return cf.run(
        "Anonymize the given text by replacing personal information with generic placeholders",
        result_type=AnonymizationResult,
        context={"text": text}
    )
```

Now we can use this function to anonymize text containing sensitive information:

<CodeGroup>
```python Example
original_text = "John Doe, born on 05/15/1980, lives at 123 Main St, New York. His email is john.doe@example.com."

result = anonymize_text(original_text)
print(f"Original: {result.original}")
print(f"Anonymized: {result.anonymized}")
print("Replacements:")
for original, placeholder in result.replacements.items():
    print(f"  {original} -> {placeholder}")
```

```text Output
Original: John Doe, born on 05/15/1980, lives at 123 Main St, New York. His email is john.doe@example.com.
Anonymized: [NAME], born on [DATE], lives at [ADDRESS], [CITY]. His email is [EMAIL].
Replacements:
  John Doe -> [NAME]
  05/15/1980 -> [DATE]
  123 Main St -> [ADDRESS]
  New York -> [CITY]
  john.doe@example.com -> [EMAIL]
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features:

1. **[Pydantic models](/concepts/tasks/task-results#pydantic-models)**: We use a Pydantic model (`AnonymizationResult`) to define the structure of our anonymization result. This ensures that the task returns well-structured, consistent results including the original text, anonymized text, and replacements made.

   ```python
   class AnonymizationResult(BaseModel):
       original: str
       anonymized: str
       replacements: dict[str, str]
   ```

2. **[Context passing](/concepts/tasks#context)**: We pass the original text as context to the task, providing all necessary information for the anonymization process.

   ```python
   context={"text": text}
   ```

By leveraging these ControlFlow features, we create an efficient and flexible data anonymization tool. This example demonstrates how ControlFlow can be used to build AI-powered privacy-enhancing workflows that can handle sensitive information with care.


================================================
FILE: docs/examples/call-routing.mdx
================================================
---
title: Customer Call Routing
description: Train an agent to route customer calls to the correct department.
icon: headset
---

In this example, you'll witness a roleplay between two AI agents:

1. A "customer" agent, who has been assigned a random department they need to reach but is instructed not to directly state it.
2. A "trainee" customer service representative, who must figure out the correct department based on the customer's story.

The conversation will continue back and forth until the trainee feels confident enough to route the call. This example showcases how ControlFlow can be used to create dynamic, multi-turn interactions between agents, with one agent (the trainee) ultimately making a decision that determines the outcome of the task.

As you run this example, you'll see the conversation unfold in real-time, culminating in the trainee's decision to route the call. The success of the interaction depends on whether the trainee correctly identifies the department the customer needs.

## Code

```python
import random
import controlflow as cf

DEPARTMENTS = [
    "Sales",
    "Support",
    "Billing",
    "Returns",
]

@cf.flow
def routing_flow():
    target_department = random.choice(DEPARTMENTS)

    print(f"\n---\nThe target department is: {target_department}\n---\n")

    customer = cf.Agent(
        name="Customer",
        instructions=f"""
            You are training customer reps by pretending to be a customer
            calling into a call center. You need to be routed to the
            {target_department} department. Come up with a good backstory.
            """,
    )

    trainee = cf.Agent(
        name="Trainee",
        instructions=""",
            You are a trainee customer service representative. You need to
            listen to the customer's story and route them to the correct
            department. Note that the customer is another agent training you.
            """,
    )

    with cf.Task(
        "Route the customer to the correct department.",
        agents=[trainee],
        result_type=DEPARTMENTS,
    ) as main_task:
        
        while main_task.is_incomplete():
            
            cf.run(
                "Talk to the trainee.",
                instructions=(
                    "Post a message to talk. In order to help the trainee "
                    "learn, don't be direct about the department you want. "
                    "Instead, share a story that will let them practice. "
                    "After you speak, mark this task as complete."
                ),
                agents=[customer],
                result_type=None
            )

            cf.run(
                "Talk to the customer.",
                instructions=(
                    "Post a message to talk. Ask questions to learn more "
                    "about the customer. After you speak, mark this task as "
                    "complete. When you have enough information, use the main "
                    "task tool to route the customer to the correct department."
                ),
                agents=[trainee],
                result_type=None,
                tools=[main_task.get_success_tool()]
            )
    
    if main_task.result == target_department:
        print("Success! The customer was routed to the correct department.")
    else:
        print(f"Failed. The customer was routed to the wrong department. "
              f"The correct department was {target_department}.")

if __name__ == "__main__":
    routing_flow()
```

## Key points

1. **Multi-agent interaction**: This example showcases how to orchestrate a conversation between two AI agents, each with distinct roles and objectives.

2. **Parent task as control flow**: The `main_task` serves dual purposes - it represents the overall objective and acts as a control mechanism for the conversation loop. The `while main_task.is_incomplete()` construct creates a flexible, AI-driven loop that continues until the trainee decides to route the call.

3. **Explicit turn-taking**: Instead of using ControlFlow's built-in turn strategies, this example manually alternates between the customer and trainee agents. This provides fine-grained control over the conversation flow and allows for specific instructions to be given to each agent on each turn.

4. **Task-specific tools**: The trainee is given access to the `main_task`'s success tool, allowing them to mark the overall task as complete when they're ready to route the call, even though that task isn't currently active. This demonstrates how tools can be used to give agents control over task state.


## Further reading

- For more details on creating and managing tasks, see the [Tasks documentation](/concepts/tasks).
- To learn more about agents and their capabilities, check out the [Agents guide](/concepts/agents).
- For information on how ControlFlow manages conversations and context, refer to the [Message History guide](/patterns/history).

This example effectively demonstrates how to create a complex, interactive scenario in ControlFlow, with fine-grained control over agent interactions and task flow. It showcases the flexibility of the framework in handling multi-turn conversations and decision-making processes, making it an excellent template for building sophisticated AI-powered applications.


================================================
FILE: docs/examples/code-explanation.mdx
================================================
---
title: Code Explanation
description: Use ControlFlow to generate natural language explanations of code snippets.
icon: code
---

This example demonstrates how to use ControlFlow to create a task that explains code snippets in natural language. It showcases the use of custom types and context passing for code documentation tasks.

## Code

The following code creates a function that takes a code snippet and its programming language, then returns an explanation of the code:

```python
import controlflow as cf
from pydantic import BaseModel

class CodeExplanation(BaseModel):
    code: str
    explanation: str
    language: str

def explain_code(code: str, language: str=None) -> CodeExplanation:
    return cf.run(
        f"Explain the following code snippet",
        result_type=CodeExplanation,
        context={"code": code, "language": language or 'auto-detect'}
    )
```

Now we can use this function to explain a code snippet:

<CodeGroup>
```python Example
code_snippet = """
def fibonacci(n):
    if n <= 1:
        return n
    else:
        return fibonacci(n-1) + fibonacci(n-2)
"""

result = explain_code(code_snippet, "Python")
print(f"Code:\n{result.code}\n")
print(f"Explanation:\n{result.explanation}")
```

```text Output
Code:
def fibonacci(n):
    if n <= 1:
        return n
    else:
        return fibonacci(n-1) + fibonacci(n-2)

Explanation:
This Python code defines a function called `fibonacci` that calculates 
the nth number in the Fibonacci sequence using recursion. Here's a 
breakdown of how it works:

1. The function takes a single parameter `n`, which represents the 
position in the Fibonacci sequence we want to calculate.

2. There's a base case: if `n` is less than or equal to 1, the function 
simply returns `n`. This handles the first two numbers in the Fibonacci 
sequence (F(0) = 0 and F(1) = 1).

3. For any other value of `n`, the function recursively calls itself twice:
   - Once with `n-1` as the argument
   - Once with `n-2` as the argument

4. The results of these two recursive calls are added together and returned.

This implementation follows the mathematical definition of the Fibonacci 
sequence, where each number is the sum of the two preceding ones. However, 
it's worth noting that this recursive approach can be inefficient for 
large values of `n` due to repeated calculations.
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features:

1. **[Pydantic models](/concepts/tasks/task-results#pydantic-models)**: We use a Pydantic model (`CodeExplanation`) to define the structure of our explanation result. This ensures that the task returns well-structured, consistent results including the original code, its explanation, and the programming language.

   ```python
   class CodeExplanation(BaseModel):
       code: str
       explanation: str
       language: str
   ```

2. **[Context passing](/concepts/tasks#context)**: We pass both the code snippet and the programming language as context to the task, providing all necessary information for the explanation process.

   ```python
   context={"code": code, "language": language}
   ```

By leveraging these ControlFlow features, we create an efficient and flexible code explanation tool. This example demonstrates how ControlFlow can be used to build AI-powered documentation workflows that can help developers understand and explain code snippets in natural language.


================================================
FILE: docs/examples/generate-people.mdx
================================================
---
title: Generate User Profiles
description: Use ControlFlow to generate test data based on a template.
icon: users
---

This example demonstrates how to use ControlFlow to create a task that generates test data based on a given template. It showcases the use of custom types and efficient batch processing.

## Code

The following code creates a function that takes a count then returns a list of generated user profiles that match a provide `result_type` template:

```python
import controlflow as cf
from pydantic import BaseModel, Field


class UserProfile(BaseModel):
    name: str = Field(description='The full name of the user')
    age: int = Field(description='The age of the user, 20-60')
    occupation: str = Field(description='The occupation of the user')
    hobby: str 


def generate_profiles(count: int) -> list[UserProfile]:
    return cf.run(
        f"Generate {count} user profiles",
        result_type=list[UserProfile],
        context={"count": count}
    )
```

Now we can generate some test data:

<CodeGroup>
```python Example
test_data = generate_profiles(count=5)

from rich import print
print(test_data)
```

```python Output
[
    UserProfile(
        name='Emily Johnson',
        age=27,
        occupation='Software Engineer',
        hobby='Painting'
    ),
    UserProfile(
        name='Michael Smith',
        age=34,
        occupation='Marketing Manager',
        hobby='Cycling'
    ),
    UserProfile(
        name='Sarah Brown',
        age=42,
        occupation='Teacher',
        hobby='Gardening'
    ),
    UserProfile(
        name='David Wilson',
        age=29,
        occupation='Graphic Designer',
        hobby='Photography'
    ),
    UserProfile(
        name='Laura Davis',
        age=50,
        occupation='Chef',
        hobby='Reading'
    )
]
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features:

1. **[Pydantic models](/concepts/tasks/task-results#pydantic-models)**: We use a Pydantic model (`UserProfile`) to define the structure of our generated data. This ensures that the generation task returns well-structured, consistent results.

   ```python
   class UserProfile(BaseModel):
       name: str
       age: int
       occupation: str
       hobby: str
   ```

2. **[Batch processing](/concepts/tasks/task-results#collections)**: We generate multiple user profiles in a single task, which is more efficient than generating them individually. This is achieved by specifying `List[UserProfile]` as the `result_type`.

   ```python
   result_type=List[UserProfile]
   ```

3. **[Context passing](/concepts/tasks#context)**: We pass the desired count as context to the task, allowing the LLM to generate multiple data points based on the given parameters.

   ```python
   context={"count": count}
   ```


By leveraging these ControlFlow features, we create an efficient and flexible test data generation tool. This example demonstrates how ControlFlow can be used to build AI-powered data generation workflows that can produce multiple data points in a single operation, based on customizable templates. This approach is particularly useful for creating diverse and realistic test datasets for various applications.


================================================
FILE: docs/examples/headline-categorization.mdx
================================================
---
title: Headline Categorization
description: Classify news headlines into predefined categories.
icon: list-check
---

Categorizing news headlines is a common task in content management and recommendation systems. This example demonstrates how to use ControlFlow to quickly build a headline classifier that categorizes news into predefined categories, showcasing the framework's ability to handle classification tasks with minimal code.

## Code

The following code creates a function that classifies a given news headline into one of five predefined categories. It uses ControlFlow's task running feature and leverages the power of language models to perform the classification.

```python
import controlflow as cf

classifier = cf.Agent(model="openai/gpt-4o-mini")

def classify_news(headline: str) -> str:
    return cf.run(
        "Classify the news headline into the most appropriate category",
        agents=[classifier],
        result_type=["Politics", "Technology", "Sports", "Entertainment", "Science"],
        context={"headline": headline},
    )
```

Now we can use this function to classify news headlines:

<CodeGroup>
```python Example 1
headline = "New AI Model Breaks Records in Language Understanding"
category = classify_news(headline)
print(f"Headline: {headline}")
print(f"Category: {category}")

# Result:
# Headline: New AI Model Breaks Records in Language Understanding
# Category: Technology
```
```python Example 2
headline = "Scientists Discover Potentially Habitable Exoplanet"
category = classify_news(headline)
print(f"Headline: {headline}")
print(f"Category: {category}")

# Result:
# Headline: Scientists Discover Potentially Habitable Exoplanet
# Category: Science
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features that enable quick development of classification tools:

1. **[Agents](/concepts/agents)**: We create an agent with a specific LLM model (GPT-4o mini) to perform the headline classification.

   ```python
   classifier = cf.Agent(model="openai/gpt-4o-mini")
   ```

2. **[Result types](/concepts/tasks/task-results)**: We use a list of strings as the `result_type` to constrain the output to one of the predefined categories. This ensures that the classification result is always one of the specified options.

   ```python
   result_type=["Politics", "Technology", "Sports", "Entertainment", "Science"]
   ```

3. **[Context passing](/concepts/tasks#context)**: The `context` parameter is used to pass the input headline to the task.

   ```python
   context={"headline": headline}
   ```

By leveraging these ControlFlow features, we can create a powerful headline classifier with just a few lines of code. This example demonstrates how ControlFlow simplifies the process of building and deploying classification tools, making it easier for developers to incorporate advanced language processing capabilities into their applications.

The use of predefined categories in the `result_type` is particularly noteworthy, as it allows us to constrain the model's output to a specific set of options. This is useful in many real-world scenarios where we need to map inputs to a fixed set of categories.


================================================
FILE: docs/examples/language-tutor.mdx
================================================
---
title: Interactive Language Tutor
description: Create an engaging AI tutor for language learning using ControlFlow
icon: graduation-cap
---

This example demonstrates how to use ControlFlow to create a simple yet interactive language learning assistant. It showcases the use of a custom agent, user interaction, and a flexible learning flow.

## Code

The following code creates a basic language learning session with an AI tutor:

```python
import controlflow as cf
from pydantic import BaseModel

class Lesson(BaseModel):
    topic: str
    content: str
    exercises: list[str]

def language_learning_session(language: str) -> None:
    tutor = cf.Agent(
        name="Tutor",
        instructions="""
        You are a friendly and encouraging language tutor. Your goal is to create an 
        engaging and supportive learning environment. Always maintain a warm tone, 
        offer praise for efforts, and provide gentle corrections. Adapt your teaching 
        style to the user's needs and pace. Use casual language to keep the 
        conversation light and fun. When working through exercises:
        - Present one exercise at a time.
        - Provide hints if the user is struggling.
        - Offer the correct answer if the user can't solve it after a few attempts.
        - Use encouraging language throughout the process.
        """
    )

    @cf.flow(default_agent=tutor)
    def learning_flow():
        cf.run(
            f"Greet the user, learn their name,and introduce the {language} learning session",
            interactive=True
        )

        while True:
            lesson = cf.run(
                "Create a fun and engaging language lesson",
                result_type=Lesson
            )

            cf.run(
                "Present the lesson content to the user in an interactive and engaging way",
                interactive=True,
                context={"lesson": lesson}
            )

            for exercise in lesson.exercises:
                cf.run(
                    "Work through the exercise with the user",
                    interactive=True,
                    context={"exercise": exercise}
                )

            continue_learning = cf.run(
                "Check if the user wants to continue learning",
                result_type=bool,
                interactive=True
            )

            if not continue_learning:
                break

        cf.run(
            "Summarize the learning session and provide encouragement",
            interactive=True
        )

    learning_flow()

# Example usage
language_learning_session("French")
```

## Key Concepts

This implementation showcases several important ControlFlow features and concepts:

1. **Custom Agent**: We define a tutor agent with specific instructions on how to interact with the user. This allows for a consistent and engaging teaching style throughout the session.

   ```python
   tutor = cf.Agent(
       name="Tutor",
       instructions="""
       You are a friendly and encouraging language tutor...
       """
   )
   ```

2. **Flow-level Agent Assignment**: We assign the tutor agent to the entire flow, eliminating the need to specify it for each task.

   ```python
   @cf.flow(default_agent=tutor)
   def learning_flow():
       ...
   ```

3. **Interactive Tasks**: We use the `interactive=True` parameter for tasks that require user interaction. This allows the AI tutor to engage directly with the user.

   ```python
   cf.run(
       "Work through the exercise with the user",
       interactive=True,
       context={"exercise": exercise}
   )
   ```

4. **Flexible Flow Control**: The learning session uses a while loop with a condition checked after each lesson. This allows the session to continue as long as the user wants to keep learning.

   ```python
   while True:
       # ... lesson content ...
       continue_learning = cf.run(
           "Check if the user wants to continue learning",
           result_type=bool,
           interactive=True
       )
       if not continue_learning:
           break
   ```

5. **Context Passing**: We pass the `lesson` and `exercise` objects as context to relevant tasks. This allows the AI tutor to have access to the current lesson content.

   ```python
   context={"lesson": lesson}
   ```

6. **Structured Data Models**: We use a Pydantic model (`Lesson`) to define the structure of our lesson data. This ensures that the data passed between tasks is well-structured and type-safe.

   ```python
   class Lesson(BaseModel):
       topic: str
       content: str
       exercises: list[str]
   ```

By leveraging these ControlFlow features, we create a simple yet engaging language learning assistant. This example demonstrates how to build interactive AI workflows that can respond to user input and adapt their behavior based on the user's choices.

The simplicity of this implementation allows for easy expansion. Users could extend this example by adding more complex lesson structures, implementing progress tracking, or incorporating additional language learning features like vocabulary reviews or grammar explanations.


================================================
FILE: docs/examples/named-entity-recognition.mdx
================================================
---
title: Named Entity Recognition
description: Extract named entities from text using ControlFlow.
icon: landmark-dome
---

Named Entity Recognition (NER) is a crucial task in natural language processing, used to identify named entities (such as persons, organizations, locations) in text. This example demonstrates how to implement a simple NER system using ControlFlow and a GPT-4o mini model, showcasing two different approaches: extracting a simple list of entities and categorizing entities by type.

## Code

First, let's implement a function that extracts a simple list of entities:

```python
import controlflow as cf
from typing import List

extractor = cf.Agent(
    name="Named Entity Recognizer",
    model="openai/gpt-4o-mini",
)

def extract_entities(text: str) -> List[str]:
    return cf.run(
        "Extract all named entities from the text",
        agents=[extractor],
        result_type=List[str],
        context={"text": text},
    )
```

We can call this function on any text to extract all named entities:

```python Simple extraction
text = "Apple Inc. is planning to open a new store in New York City next month."
entities = extract_entities(text)

print(entities)
# Result: 
# ['Apple Inc.', 'New York City']
```

Now, let's modify our function to categorize the entities it extracts. We do this by changing the result type to a dictionary and providing detailed instructions about the types of entities we want to extract:

```python
def extract_categorized_entities(text: str) -> Dict[str, List[str]]:
    return cf.run(
        "Extract named entities from the text and categorize them",
        instructions="""
        Return a dictionary with the following keys:
        - 'persons': List of person names
        - 'organizations': List of organization names
        - 'locations': List of location names
        - 'dates': List of date references
        - 'events': List of event names
        Only include keys if entities of that type are found in the text.
        """,
        agents=[extractor],
        result_type=Dict[str, List[str]],
        context={"text": text},
    )
```

Here's how we can use this function to perform NER on some example texts:

```python Categorized extraction
text = "In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission."
entities = extract_categorized_entities(text)

print(entities)
# Result:
# {
#     'persons': ['Neil Armstrong'],
#     'locations': ['Moon'],
#     'dates': ['1969'],
#     'events': ['Apollo 11 mission']
# }
```

## Key concepts

This implementation showcases several important ControlFlow features that enable quick development of NLP tools:

1. **[Agents](/concepts/agents)**: We create an agent with a specific LLM model (GPT-4o mini) to perform the named entity recognition.

   ```python
   extractor = cf.Agent(
       name="Named Entity Recognizer",
       model="openai/gpt-4o-mini",
   )
   ```

2. **[Flexible result types](/concepts/tasks/task-results)**: We demonstrate two different result types: a simple list of strings and a dictionary of categorized entities. This flexibility allows us to adapt the output structure to our specific needs.

   ```python
   result_type=List[str]
   # or
   result_type=Dict[str, List[str]]
   ```

3. **[Detailed instructions](/concepts/tasks#instructions)**: In the categorized version, we provide detailed instructions to guide the model in structuring its output. This allows us to define a specific schema for the results without changing the underlying model.

   ```python
   instructions="""
   Return a dictionary with the following keys:
   - 'persons': List of person names
   - 'organizations': List of organization names
   ...
   """
   ```

4. **[Context passing](/concepts/tasks#context)**: The `context` parameter is used to pass the input text to the task.

   ```python
   context={"text": text}
   ```

By leveraging these ControlFlow features, we can create powerful NER tools with minimal code. This example demonstrates how ControlFlow simplifies the process of building and deploying NLP tools, making it easier for developers to incorporate advanced language processing capabilities into their applications.

The ability to easily switch between different output structures (list vs. categorized dictionary) showcases the flexibility of ControlFlow in adapting to various NLP task requirements.


================================================
FILE: docs/examples/pineapple-pizza.mdx
================================================
---
title: Pineapple-on-Pizza Debate
---

This example demonstrates a debate between two agents. One agent plays the role of an eternal optimist, while the other plays the role of an eternal pessimist. The debate is moderated by a third agent who decides whose argument is more compelling.

```python Code
import controlflow as cf

optimist = cf.Agent(
    name="Half-full",
    instructions="You are an eternal optimist.",
)
pessimist = cf.Agent(
    name="Half-empty",
    instructions="You are an eternal pessimist.",
)
# create an agent that will decide who wins the debate
moderator = cf.Agent(name="Moderator")


@cf.flow
def demo(topic: str):
    cf.run(
        "Have a debate about the topic.",
        instructions="Each agent should take at least two turns.",
        agents=[optimist, pessimist],
        context={"topic": topic},
    )

    winner: cf.Agent = cf.run(
        "Whose argument do you find more compelling?",
        agents=[moderator],
        result_type=[optimist, pessimist],
    )

    print(f"{winner.name} wins the debate!")


demo("pineapple on pizza")
```


================================================
FILE: docs/examples/rock-paper-scissors.mdx
================================================
---
title: Rock, Paper, Scissors
description: Play rock, paper, scissors against an AI... without letting it cheat.
icon: hand-scissors
# mode: wide
---

Creating a fair game of rock, paper, scissors against an AI opponent presents an interesting challenge: how do we prevent the AI from "cheating" by reading the player's choice before making its own? This example demonstrates how ControlFlow's features can be used to create a fair and engaging game while showcasing several key concepts of the framework.

## Code

The following code creates a function that plays rock, paper, scissors in a loop. Each round, it collects the user's move in a private context, then the AI's move in another private context, and finally reports the result and asks if the user wants to continue. This structure ensures that neither player can access the other's choice prematurely.

```python
import controlflow as cf

@cf.flow
def rock_paper_scissors():
    """Play rock, paper, scissors against an AI."""
    play_again = True

    while play_again:
        # Get the user's choice on a private thread
        with cf.Flow():
            user_choice = cf.run(
                "Get the user's choice", 
                result_type=["rock", "paper", "scissors"], 
                interactive=True, 
            )
    
        # Get the AI's choice on a private thread
        with cf.Flow():
            ai_choice = cf.run(
                "Choose rock, paper, or scissors", 
                result_type=["rock", "paper", "scissors"],
            )

        # Report the score and ask if the user wants to play again
        play_again = cf.run(
            "Report the score to the user and see if they want to play again.",
            interactive=True,
            context={"user_choice": user_choice, "ai_choice": ai_choice},
            result_type=bool
        )

rock_paper_scissors()
```

Try running this example to see how ControlFlow manages the game flow and maintains fairness in this AI vs. human contest!

## Key concepts

This implementation showcases how ControlFlow can be used to create interactive, multi-step processes with controlled information flow. By using separate Flows for the player and AI choices, we ensure that the AI can't "cheat" by accessing the player's choice prematurely. The use of structured tasks, result types, and context passing allows for a clean and intuitive game logic, while the interactive features enable seamless player involvement.

1. **[Flows](/concepts/flows)**: We use separate Flows to create isolated contexts for the player's and AI's choices. This ensures that neither can access the other's decision until both have been made.

   ```python
   with cf.Flow():
       user_choice = cf.run(...)
   ```
2. **[Interactivity](/patterns/interactivity)**: The `interactive=True` parameter allows tasks to interact with the user, essential for getting the player's input.

   ```python
   user_choice = cf.run(..., interactive=True, ...)
   ```

3. **[Result types](/concepts/tasks/task-results)**: We use `result_type` to ensure that choices are valid and properly structured. This helps maintain the integrity of the game.

   ```python
   result_type=["rock", "paper", "scissors"]
   ```

4. **[Context passing](/concepts/tasks#context)**: The `context` parameter allows us to share information between tasks, crucial for determining the winner based on both players' choices.

   ```python
   context={"user_choice": user_choice, "ai_choice": ai_choice}
   ```

By leveraging these ControlFlow features, we can create a multi-step process that maintains fairness while allowing for engaging interaction between the AI and the player.


================================================
FILE: docs/examples/seinfeld-conversation.mdx
================================================
---
title: Seinfeld Conversation
description: Simulate a conversation between Seinfeld characters using multiple AI agents.
icon: comments
---

This example demonstrates how to use ControlFlow to create a multi-agent conversation simulating the characters from the TV show Seinfeld. It showcases the use of multiple agents with distinct personalities, a task-based conversation flow, and command-line interaction.

## Code

The following code creates a conversation between Jerry, George, Elaine, Kramer, and Newman, discussing a given topic:

```python
import sys
from controlflow import Agent, Task, flow

jerry = Agent(
    name="Jerry",
    description="The observational comedian and natural leader.",
    instructions="""
    You are Jerry from the show Seinfeld. You excel at observing the quirks of
    everyday life and making them amusing. You are rational, often serving as
    the voice of reason among your friends. Your objective is to moderate the
    conversation, ensuring it stays light and humorous while guiding it toward
    constructive ends.
    """,
)

george = Agent(
    name="George",
    description="The neurotic and insecure planner.",
    instructions="""
    You are George from the show Seinfeld. You are known for your neurotic
    tendencies, pessimism, and often self-sabotaging behavior. Despite these
    traits, you occasionally offer surprising wisdom. Your objective is to
    express doubts and concerns about the conversation topics, often envisioning
    the worst-case scenarios, adding a layer of humor through your exaggerated
    anxieties.
    """,
)

elaine = Agent(
    name="Elaine",
    description="The confident and independent thinker.",
    instructions="""
    You are Elaine from the show Seinfeld. You are bold, witty, and unafraid to
    challenge social norms. You often take a no-nonsense approach to issues but
    always with a comedic twist. Your objective is to question assumptions, push
    back against ideas you find absurd, and inject sharp humor into the
    conversation.
    """,
)

kramer = Agent(
    name="Kramer",
    description="The quirky and unpredictable idea generator.",
    instructions="""
    You are Kramer from the show Seinfeld. Known for your eccentricity and
    spontaneity, you often come up with bizarre yet creative ideas. Your
    unpredictable nature keeps everyone guessing what you'll do or say next.
    Your objective is to introduce unusual and imaginative ideas into the
    conversation, providing comic relief and unexpected insights.
    """,
)

newman = Agent(
    name="Newman",
    description="The antagonist and foil to Jerry.",
    instructions="""
    You are Newman from the show Seinfeld. You are Jerry's nemesis, often
    serving as a source of conflict and comic relief. Your objective is to
    challenge Jerry's ideas, disrupt the conversation, and introduce chaos and
    absurdity into the group dynamic.
    """,
)

@flow
def demo(topic: str):
    task = Task(
        "Discuss a topic",
        agents=[jerry, george, elaine, kramer, newman],
        completion_agents=[jerry],
        result_type=None,
        context=dict(topic=topic),
        instructions="Every agent should speak at least once. only one agent per turn. Keep responses 1-2 paragraphs max.",
    )
    task.run()

if __name__ == "__main__":
    if len(sys.argv) > 1:
        topic = sys.argv[1]
    else:
        topic = "sandwiches"
    
    print(f"Topic: {topic}")
    demo(topic=topic)
```

## Key concepts

This implementation showcases several important ControlFlow features:

1. **Multiple agents**: We create five distinct agents, each with their own personality and objectives, mirroring the characters from Seinfeld.

2. **Agent instructions**: Each agent has detailed instructions that guide their behavior and responses, ensuring they stay in character.

3. **Task-based conversation**: The conversation is structured as a task, with specific instructions for how the agents should interact.

4. **Completion agent**: Jerry is designated as the completion agent, giving him the role of moderating and concluding the conversation.

5. **Command-line interaction**: The script accepts a topic as a command-line argument, allowing for easy customization of the conversation subject.

## Running the example

You can run this example with a custom topic:

```bash
python examples/seinfeld.py "coffee shops"
```

Or use the default topic ("sandwiches") by running it without arguments:

```bash
python examples/seinfeld.py
```

This example demonstrates how ControlFlow can be used to create complex, multi-agent interactions that simulate realistic conversations between distinct personalities. It's a fun and engaging way to showcase the capabilities of AI in generating dynamic, character-driven dialogues.


================================================
FILE: docs/examples/sentiment-classifier.mdx
================================================
---
title: Sentiment Classifier
description: Use GPT-4o mini to quickly build a sentiment classifier.
icon: face-laugh-beam
---

Sentiment analysis is a common natural language processing task that involves determining the emotional tone of a piece of text. This example demonstrates how to use ControlFlow to quickly build a sentiment classifier using GPT-4o mini, showcasing the framework's ability to create powerful NLP tools with minimal code.

## Code

The following code creates a function that classifies the sentiment of a given text on a scale from 0 (very negative) to 1 (very positive). It uses a GPT-4o mini model for classification and leverages ControlFlow's task running and result validation features.

```python
import controlflow as cf
from controlflow.tasks.validators import between

optimist = cf.Agent(model="openai/gpt-4o-mini")

def sentiment(text: str) -> float:
    return cf.run(
        "Classify the sentiment of the text as a value between 0 and 1",
        agents=[optimist],
        result_type=float,
        result_validator=between(0, 1),
        context={"text": text},
    )
```

Now we can run this function on any text:

<CodeGroup>
```python Example 1
sentiment("I love ControlFlow!") 

# Result: 1.0
```
```python Example 2
sentiment(
    """
    Far out in the uncharted backwaters of the unfashionable end of 
    the western spiral arm of the Galaxy lies a small unregarded yellow sun. 
    Orbiting this at a distance of roughly ninety-two million miles is an utterly 
    insignificant little blue-green planet whose ape-descended life forms are so 
    amazingly primitive that they still think digital watches are a pretty neat 
    idea. This planet has – or rather had – a problem, which was this: most of 
    the people living on it were unhappy for pretty much of the time.
    """
) 
# Result: 0.2
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features that enable quick development of NLP tools:

1. **[Agents](/concepts/agents)**: We create an agent with a specific LLM model (GPT-4o mini) to perform the sentiment analysis.

   ```python
   optimist = cf.Agent(model="openai/gpt-4o-mini")
   ```

3. **[Result types](/concepts/tasks/task-results)**: We specify `result_type=float` to ensure the sentiment score is returned as a float value.

4. **[Result validation](/concepts/tasks/task-results#result-validators)**: The `result_validator` parameter is used with the `between()` function to ensure the result falls within the expected range.

   ```python
   result_validator=between(0, 1)
   ```

5. **[Context passing](/concepts/tasks#context)**: The `context` parameter is used to pass the input text to the task.

   ```python
   context={"text": text}
   ```

By leveraging these ControlFlow features, we can create a powerful sentiment classifier with just a few lines of code. This example demonstrates how ControlFlow can simplify the process of building and deploying NLP tools, making it easier for developers to incorporate advanced language processing capabilities into their applications.


================================================
FILE: docs/examples/standardize-addresses.mdx
================================================
---
title: Standardize Place Names
description: Use ControlFlow to efficiently standardize multiple place names into consistent postal addresses.
icon: map-pin
---

This example demonstrates how to use ControlFlow to create a task that standardizes multiple place names into consistent postal addresses in a single operation. It showcases the use of custom types and efficient batch processing.

## Code

The following code creates a function that takes a list of place names and returns a list of standardized addresses:

```python
import controlflow as cf
from pydantic import BaseModel
from typing import List

class StandardAddress(BaseModel):
    city: str
    state: str
    country: str = "USA"

def standardize_addresses(place_names: List[str]) -> List[StandardAddress]:
    return cf.run(
        "Standardize the given place names into consistent postal addresses",
        result_type=List[StandardAddress],
        context={"place_names": place_names}
    )
```

You can use this function to standardize a list of place names:

<CodeGroup>
```python Example
place_names = [
    "NYC", "New York, NY", "Big Apple",
    "Los Angeles, California", "LA",
    "San Fran", "The Windy City"
]

standardized_addresses = standardize_addresses(place_names)

for original, standard in zip(place_names, standardized_addresses):
    print(f"Original: {original}")
    print(f"Standardized: {standard}")
    print()
```

```text Output
Original: NYC
Standardized: StandardAddress(city='New York City', state='NY', country='USA')

Original: New York, NY
Standardized: StandardAddress(city='New York City', state='NY', country='USA')

Original: Big Apple
Standardized: StandardAddress(city='New York City', state='NY', country='USA')

Original: Los Angeles, California
Standardized: StandardAddress(city='Los Angeles', state='CA', country='USA')

Original: LA
Standardized: StandardAddress(city='Los Angeles', state='CA', country='USA')

Original: San Fran
Standardized: StandardAddress(city='San Francisco', state='CA', country='USA')

Original: The Windy City
Standardized: StandardAddress(city='Chicago', state='IL', country='USA')
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features:

1. **[Pydantic models](/concepts/tasks/task-results#pydantic-models)**: We use a Pydantic model (`StandardAddress`) to define the structure of our standardized addresses. This ensures that the standardization task returns well-structured, consistent results.

   ```python
   class StandardAddress(BaseModel):
       city: str
       state: str
       country: str = "USA"
   ```

2. **[Batch processing](/concepts/tasks/task-results#collections)**: We process a list of place names in a single task, which is more efficient than processing them individually. This is achieved by specifying `List[StandardAddress]` as the `result_type`.

   ```python
   result_type=List[StandardAddress]
   ```

3. **[Context passing](/concepts/tasks#context)**: We pass the entire list of place names as context to the task, allowing the LLM to process all inputs at once.

   ```python
   context={"place_names": place_names}
   ```

4. **[Simple task creation](/concepts/tasks/creating-tasks)**: We use `cf.run()` to create and execute a task in a single step, simplifying our code.

   ```python
   return cf.run(
       "Standardize the given place names into consistent postal addresses",
       result_type=List[StandardAddress],
       context={"place_names": place_names}
   )
   ```

By leveraging these ControlFlow features, we create an efficient and straightforward address standardization tool. This example demonstrates how ControlFlow can be used to build AI-powered data processing workflows that handle multiple inputs in a single operation, improving performance and reducing costs.


================================================
FILE: docs/examples/summarization.mdx
================================================
---
title: Text Summarization
description: Generate concise summaries of longer texts.
icon: file-lines
---

Text summarization is a valuable tool for quickly extracting key information from longer documents. This example demonstrates how to use ControlFlow to create a text summarization function that not only produces a concise summary but also extracts key points, all in a single pass.

## Code

The following code creates a function that summarizes a given text and extracts key points. It uses ControlFlow's task running feature and leverages Pydantic for structured output.

```python
import controlflow as cf
from pydantic import BaseModel

class Summary(BaseModel):
    summary: str
    key_points: list[str]

def summarize_text(text: str, max_words: int = 100) -> Summary:
    return cf.run(
        f"Summarize the given text in no more than {max_words} words and list key points",
        result_type=Summary,
        context={"text": text},
    )
```

Let's use this function to summarize a longer text:

<CodeGroup>
```python Example
long_text = """
    The Internet of Things (IoT) is transforming the way we interact with our
    environment. It refers to the vast network of connected devices that collect
    and share data in real-time. These devices range from simple sensors to
    sophisticated wearables and smart home systems. The IoT has applications in
    various fields, including healthcare, agriculture, and urban planning. In
    healthcare, IoT devices can monitor patients remotely, improving care and
    reducing hospital visits. In agriculture, sensors can track soil moisture and
    crop health, enabling more efficient farming practices. Smart cities use IoT to
    manage traffic, reduce energy consumption, and enhance public safety. However,
    the IoT also raises concerns about data privacy and security, as these
    interconnected devices can be vulnerable to cyber attacks. As the technology
    continues to evolve, addressing these challenges will be crucial for the
    widespread adoption and success of IoT.
    """

result = summarize_text(long_text)
print(result.summary)
print("\nKey Points:")
for point in result.key_points:
    print(f"- {point}")
```

```text Result
The Internet of Things (IoT) is a network of connected devices that collect and 
share data in real-time, transforming various fields such as healthcare, 
agriculture, and urban planning. While IoT offers numerous benefits, including 
remote patient monitoring, efficient farming, and smart city management, it 
also raises concerns about data privacy and security.

Key Points:
- IoT is a network of connected devices sharing real-time data
- Applications include healthcare, agriculture, and urban planning
- Benefits include remote patient monitoring and efficient resource management
- Raises concerns about data privacy and security
- Addressing challenges is crucial for widespread adoption
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features that enable quick development of advanced text processing tools:

1. **[Structured outputs](/concepts/tasks/task-results)**: We use a Pydantic model (`Summary`) as the `result_type` to define the structure of our output. This ensures that the summarization task returns both a summary and a list of key points in a well-defined format.

   ```python
   class Summary(BaseModel):
       summary: str
       key_points: list[str]

   result_type=Summary
   ```

2. **[Context passing](/concepts/tasks#context)**: The `context` parameter is used to pass the input text and maximum word count to the task.

   ```python
   context={"text": text}
   ```

3. **[Dynamic instructions](/concepts/tasks#instructions)**: We include the `max_words` parameter in the task instruction, allowing for flexible control over the summary length.

   ```python
   f"Summarize the given text in no more than {max_words} words and list key points"
   ```

By leveraging these ControlFlow features, we can create a powerful text summarization tool with just a few lines of code. This example demonstrates how ControlFlow simplifies the process of building and deploying advanced NLP tools, making it easier for developers to incorporate complex language processing capabilities into their applications.

The use of a Pydantic model for the output is particularly noteworthy, as it allows us to define a clear structure for our summarization results. This structured output makes it easy to work with the summary and key points separately in downstream tasks or when presenting the information to users.


================================================
FILE: docs/examples/translation.mdx
================================================
---
title: Text Translation
description: Use ControlFlow to translate text from one language to another.
icon: language
---

This example demonstrates how to use ControlFlow to create a task that translates text from one language to another. It showcases the use of custom types and context passing for language translation tasks.

## Code

The following code creates a function that takes a text string and a target language, then returns a translation result:

```python
import controlflow as cf
from pydantic import BaseModel

class TranslationResult(BaseModel):
    translated: str
    target_language: str

def translate_text(text: str, target_language: str) -> TranslationResult:
    return cf.run(
        f"Translate the given text to {target_language}",
        result_type=TranslationResult,
        context={"text": text, "target_language": target_language}
    )
```

Now we can use this function to translate text:

<CodeGroup>
```python Example
original_text = "Hello, how are you?"
target_language = "French"

result = translate_text(original_text, target_language)
print(f"Original: {original_text}")
print(f"Translated ({result.target_language}): {result.translated}")
```

```text Output
Original: Hello, how are you?
Translated (French): Bonjour, comment allez-vous ?
```
</CodeGroup>

## Key concepts

This implementation showcases several important ControlFlow features:

1. **[Pydantic models](/concepts/tasks/task-results#pydantic-models)**: We use a Pydantic model (`TranslationResult`) to define the structure of our translation result. This ensures that the translation task returns well-structured, consistent results.

   ```python
   class TranslationResult(BaseModel):
       original: str
       translated: str
       target_language: str
   ```

2. **[Context passing](/concepts/tasks#context)**: We pass both the original text and the target language as context to the task, providing all necessary information for the translation.

   ```python
   context={"text": text, "target_language": target_language}
   ```

By leveraging these ControlFlow features, we create an efficient and flexible text translation tool. This example demonstrates how ControlFlow can be used to build AI-powered language processing workflows that can handle translation tasks with ease.


================================================
FILE: docs/examples/features/dependent-tasks.mdx
================================================
---
title: Dependent Tasks
description: Build complex workflows by indicating relationships between tasks.
icon: link
---
In this example, we'll explore how ControlFlow enables the creation of complex, hierarchical workflows using dependent tasks. We've chosen a text analysis scenario to demonstrate several powerful features of ControlFlow:

- Organizing tasks in a logical, nested structure
- Simplifying data flow through automatic context sharing
- Ensuring correct task execution order with dependencies
- Maintaining a shared context across all tasks in a workflow

As you examine the code, pay attention to how these concepts are implemented and how they contribute to creating a clear, efficient workflow structure.

## Code

<CodeGroup>
```python Code
import controlflow as cf

@cf.flow
def analyze_text(text: str):

    # Create a parent task to represent the entire analysis
    with cf.Task(
        "Analyze the given text", 
        instructions="Include each subtask result in your result",
        result_type=dict, 
        context={"text": text}
    ) as parent_task:
        
        # Child task 1: Identify key terms
        key_terms = cf.Task(
            "Identify up to 10 key terms in the text",
            result_type=list[str]
        )

        # Child task 2: Summarize (depends on key_terms)
        summary = cf.Task(
            "Summarize the text in one sentence",
            result_type=str,
            depends_on=[key_terms]
        )

    # Run the parent task, which will automatically run all child tasks
    result = parent_task.run()
    return result

# Execute the flow
text = """
    Agentic workflow orchestration refers to the coordination of autonomous
    agents within a structured workflow, allowing them to operate independently
    while achieving a common objective. Unlike traditional workflows that rigidly
    define tasks and dependencies, agentic workflows empower agents—typically
    AI-driven—to make decisions, prioritize tasks, and collaborate dynamically.
    Each agent in this system operates with a degree of autonomy, enabling it to
    adapt to changing conditions, handle uncertainties, and optimize its own
    actions within the broader workflow. This approach enhances flexibility and
    scalability, making it particularly effective for complex, multi-step
    processes where real-time adjustments and intelligent decision-making are
    crucial. By leveraging agents with defined roles and responsibilities, agentic
    workflows maintain structure while enabling innovation and responsiveness in
    task execution.
    """
    
result = analyze_text(text)
print(result)
```
```python Result
{
    'key_terms': [
        'Agentic workflow orchestration',
        'autonomous agents',
        'structured workflow',
        'independently',
        'common objective',
        'traditional workflows',
        'tasks and dependencies',
        'AI-driven',
        'decisions',
        'prioritize tasks'
    ],
    'summary': """
        Agentic workflow orchestration involves coordinating 
        autonomous agents within a structured workflow to operate independently 
        and dynamically collaborate, enhancing flexibility and scalability for 
        complex, multi-step processes.
        """
}
```
</CodeGroup>

## Key points
1. Task hierarchy: The parent task encompasses the entire analysis process, with child tasks handling specific aspects. This structure allows for logical organization of complex workflows.
2. Automatic context sharing: Child tasks have access to their parent's context without explicit passing, streamlining data flow within the workflow.
3. Dependencies: The depends_on parameter ensures tasks are executed in the correct order, as demonstrated by the summary task depending on the key terms task.
4. Flow context: By wrapping tasks in a flow, ControlFlow maintains a shared context across all tasks, including visibility into prior executions and conversation history.
5. Unified execution: Running the parent task automatically executes all child tasks in the correct order, simplifying workflow management.

## Further reading

- For more details on creating tasks and context sharing, see the [task documentation](/concepts/tasks).
- To learn more about defining dependencies between tasks, check out the [dependencies guide](/patterns/dependencies).
- For information on how ControlFlow manages task execution and context, refer to the [running tasks guide](/patterns/running-tasks).

By leveraging these features, you can create complex workflows that maintain a clear structure and ensure efficient information flow between tasks. This approach helps in building more maintainable and scalable AI-powered applications with minimal boilerplate code.


================================================
FILE: docs/examples/features/early-termination.mdx
================================================
---
title: Early Termination 
description: Control workflow execution with flexible termination logic.
icon: circle-stop
---

import { VersionBadge } from "/snippets/version-badge.mdx"

<VersionBadge version="0.11" />

This example demonstrates how to use termination conditions with the `run_until` parameter to control the execution of a ControlFlow workflow. We'll create a simple research workflow that stops under various conditions, showcasing the flexibility of this feature. In this case, we'll allow research to continue until either two topics are researched or 15 LLM calls are made. 

## Code

```python
import controlflow as cf
from controlflow.orchestration.conditions import AnyComplete, MaxLLMCalls
from pydantic import BaseModel


class ResearchPoint(BaseModel):
    topic: str
    key_findings: list[str]


@cf.flow
def research_workflow(topics: list[str]):
    if len(topics) < 2:
        raise ValueError("At least two topics are required")

    research_tasks = [
        cf.Task(f"Research {topic}", result_type=ResearchPoint)
        for topic in topics
    ]
    
    # Run tasks with termination conditions
    results = cf.run_tasks(
        research_tasks,
        instructions="Research only one topic at a time.",
        run_until=(
            AnyComplete(min_complete=2)  # stop after two tasks (if there are more than two topics)
            | MaxLLMCalls(15)  # or stop after 15 LLM calls, whichever comes first
        )
    )
    
    completed_research = [r for r in results if isinstance(r, ResearchPoint)]
    return completed_research
```

<CodeGroup>

Now, if we run this workflow on 4 topics, it will stop after two topics are researched:

```python Example Usage
# Example usage
topics = [
    "Artificial Intelligence",
    "Quantum Computing",
    "Biotechnology",
    "Renewable Energy",
]
results = research_workflow(topics)

print(f"Completed research on {len(results)} topics:")
for research in results:
    print(f"\nTopic: {research.topic}")
    print("Key Findings:")
    for finding in research.key_findings:
        print(f"- {finding}")
```

```text Result
Completed research on 2 topics:

Topic: Artificial Intelligence
Key Findings:
- Machine Learning and Deep Learning: These are subsets of AI that involve training models on large datasets to make predictions or decisions without being explicitly programmed. They are widely used in various applications, including image and speech recognition, natural language processing, and autonomous vehicles.
- AI Ethics and Bias: As AI systems become more prevalent, ethical concerns such as bias in AI algorithms, data privacy, and the impact on employment are increasingly significant. Ensuring fairness, transparency, and accountability in AI systems is a growing area of focus.
- AI in Healthcare: AI technologies are revolutionizing healthcare through applications in diagnostics, personalized medicine, and patient monitoring. AI can analyze medical data to assist in early disease detection and treatment planning.
- Natural Language Processing (NLP): NLP is a field of AI focused on the interaction between computers and humans through natural language. Recent advancements include transformers and large language models, which have improved the ability of machines to understand and generate human language.
- AI in Autonomous Systems: AI is a crucial component in developing autonomous systems, such as self-driving cars and drones, which require perception, decision-making, and control capabilities to navigate and operate in real-world environments.

Topic: Quantum Computing
Key Findings:
- Quantum Bits (Qubits): Unlike classical bits, qubits can exist in multiple states simultaneously due to superposition. This allows quantum computers to process a vast amount of information at once, offering a potential exponential speed-up over classical computers for certain tasks.
- Quantum Entanglement: This phenomenon allows qubits that are entangled to be correlated with each other, even when separated by large distances. Entanglement is a key resource in quantum computing and quantum communication.
- Quantum Algorithms: Quantum algorithms, such as Shor's algorithm for factoring large numbers and Grover's algorithm for searching unsorted databases, demonstrate the potential power of quantum computing over classical approaches.
- Quantum Error Correction: Quantum systems are prone to errors due to decoherence and noise from the environment. Quantum error correction methods are essential for maintaining the integrity of quantum computations.
- Applications and Challenges: Quantum computing holds promise for solving complex problems in cryptography, material science, and optimization. However, significant technological challenges remain, including maintaining qubit coherence, scaling up the number of qubits, and developing practical quantum software.
```
</CodeGroup>
## Key Concepts

1. **Custom Termination Conditions**: We use a combination of `AnyComplete` and `MaxLLMCalls` conditions to control when the workflow should stop.

2. **Flexible Workflow Control**: By using termination conditions with the `run_until` parameter, we can create more dynamic workflows that adapt to different scenarios. In this case, we're balancing between getting enough research done and limiting resource usage.

3. **Partial Results**: The workflow can end before all tasks are complete, so we handle partial results by filtering for completed `ResearchPoint` objects.

4. **Combining Conditions**: We use the `|` operator to combine multiple termination conditions. ControlFlow also supports `&` for more complex logic.

This example demonstrates how termination conditions provide fine-grained control over workflow execution, allowing you to balance between task completion and resource usage. This can be particularly useful for managing costs, handling time-sensitive operations, or creating more responsive AI workflows.



================================================
FILE: docs/examples/features/memory.mdx
================================================
---
title: Using Memory
description: How to use memory to persist information across different conversations
icon: brain
---
import { VersionBadge } from '/snippets/version-badge.mdx'

<VersionBadge version="0.10" />


Memory in ControlFlow allows agents to store and retrieve information across different conversations or workflow executions. This is particularly useful for maintaining context over time or sharing information between separate interactions.

## Setup

In order to use memory, you'll need to configure a [memory provider](/patterns/memory#provider). For this example, we'll use the default Chroma provider. You'll need to `pip install chromadb` to install its dependencies.

## Code

In this example, we'll create a simple workflow that remembers a user's favorite color across different conversations. For simplicity, we'll demonstrate the memory by using two different flows, which represent two different threads.

```python
import controlflow as cf


# Create a memory module for user preferences
user_preferences = cf.Memory(
    key="user_preferences",
    instructions="Store and retrieve user preferences."
)


# Create an agent with access to the memory
agent = cf.Agent(memories=[user_preferences])


# Create a flow to ask for the user's favorite color
@cf.flow
def remember_color():
    return cf.run(
        "Ask the user for their favorite color and store it in memory",
        agents=[agent],
        interactive=True,
    )


# Create a flow to recall the user's favorite color
@cf.flow
def recall_color():
    return cf.run(
        "What is the user's favorite color?",
        agents=[agent],
    )
```

Ordinarily, running the flows above would result in two separate -- unconnected -- conversations. The agent in the `recall_color` flow would have no way of knowing about the information from the first flow, even though its the same agent, because the conversation histories are not shared. 

However, because we gave the agent a memory module and instructions for how to use it, the agent *will* be able to recall the information from the first flow.

Run the first flow:
<CodeGroup>
```python First flow
remember_color()
```
```text Result
Agent: Hello! What is your favorite color?
User: I really like a blue-purple shade.
Agent: Great, thank you.
```
</CodeGroup>

When we run the second flow, the agent correctly recalls the favorite color:
<CodeGroup>
```python Second flow
result = recall_color()
print(result)
```
```text Result
The user's favorite color is a blue-purple shade.
```
</CodeGroup>

## Key concepts

1. **[Memory creation](/patterns/memory#creating-memory-modules)**: We create a `Memory` object with a unique key and instructions for its use.

   ```python
   user_preferences = cf.Memory(
       key="user_preferences",
       instructions="Store and retrieve user preferences."
   )
   ```

2. **[Assigning memory to agents](/patterns/memory#assigning-memories)**: We assign the memory to an agent, allowing it to access and modify the stored information.

   ```python
   agent = cf.Agent(name="PreferenceAgent", memories=[user_preferences])
   ```

3. **[Using memory across flows](/patterns/memory#sharing-memories)**: By using the same memory in different flows, we can access information across separate conversations.

This example demonstrates how ControlFlow's memory feature allows information to persist across different workflow executions, enabling more context-aware and personalized interactions.



================================================
FILE: docs/examples/features/multi-llm.mdx
================================================
---
title: Multi-LLM Workflows
description: Leverage different LLM models for specific tasks within a workflow.
icon: network-wired
---

This example demonstrates how to use multiple LLM models within a single ControlFlow workflow. We'll use GPT-4o-mini models for efficient classification tasks and GPT-4o for more complex synthesis. This approach allows us to optimize for both speed and quality in our AI-powered workflows.

In this scenario, we'll create a workflow that analyzes customer feedback for a product. The workflow will:

1. Classify the sentiment of each piece of feedback (using GPT-4o-mini)
2. Categorize the topic of each piece of feedback (using GPT-4o-mini)
3. Generate a comprehensive summary of the feedback (using GPT-4o)

## Code

```python
import controlflow as cf
from pydantic import BaseModel
from typing import Literal

# Create specialized agents
classifier = cf.Agent(name="Classifier", model="openai/gpt-4o-mini")
summarizer = cf.Agent(name="Summarizer", model="openai/gpt-4o")

# Define our data models
class Feedback(BaseModel):
    text: str
    sentiment: Literal["positive", "neutral", "negative"]
    topic: Literal["user interface", "performance", "features", "other"]

class FeedbackSummary(BaseModel):
    overall_sentiment: str
    key_points: list[str]
    recommendations: list[str]

@cf.flow
def analyze_customer_feedback(feedback_list: list[str]) -> FeedbackSummary:
    analyzed_feedback = []

    for feedback in feedback_list:

        # Classify sentiment
        sentiment = cf.run(
            "Classify the sentiment of this feedback",
            agents=[classifier],
            result_type=["positive", "neutral", "negative"],
            context={"feedback": feedback}
        )

        # Classify topic
        topic = cf.run(
            "Categorize this feedback into one of the predefined topics",
            agents=[classifier],
            result_type=["user interface", "performance", "features", "other"],
            context={"feedback": feedback}
        )

        analyzed_feedback.append(
            Feedback(text=feedback, sentiment=sentiment, topic=topic)
        )

    # Generate summary
    summary = cf.run(
        "Generate a comprehensive summary of the analyzed feedback",
        agents=[summarizer],
        result_type=FeedbackSummary,
        context={"feedback": analyzed_feedback}
    )

    return summary
```


### Example usage

<CodeGroup>

```python Code
feedback_list = [
    "The new user interface is intuitive and easy to use. Great job!",
    "The app crashes frequently when I try to save my work. This is frustrating.",
    "I love the new feature that allows collaboration in real-time.",
    "The performance has improved, but there's still room for optimization."
]

result = analyze_customer_feedback(feedback_list)
print(result)
```
```python Result
FeedbackSummary(
    overall_sentiment='mixed',
    key_points=[
        'The new user interface is intuitive and easy to use.',
        'The app crashes frequently when trying to save work, causing frustration.',
        'The new feature allows collaboration in real-time and is well-received.',
        'Performance has improved but still needs further optimization.'
    ],
    recommendations=[
        'Investigate and fix the app crashing issue.',
        'Continue improving performance.',
        'Maintain the intuitive design of the user interface.',
        'Expand on real-time collaboration features.'
    ]
)
```
</CodeGroup>

## Key points

1. **Multiple LLM Models**: We use GPT-4o-mini for quick classification tasks (sentiment and topic) and GPT-4o for the more complex task of summarization.

2. **Specialized Agents**: We create separate agents for different tasks, each with its own LLM model. This allows us to optimize for both speed and quality.

3. **Structured Data**: We use Pydantic models (`Feedback` and `FeedbackSummary`) to ensure type safety and consistent data structures throughout the workflow.

4. **Task-Specific Result Types**: Each task has a specific `result_type` that matches the expected output, ensuring that the agents provide the correct type of information.

5. **Workflow Composition**: The `analyze_customer_feedback` flow composes multiple tasks into a cohesive workflow, demonstrating how ControlFlow can manage complex, multi-step processes that include loops and conditional logic.

This example showcases how ControlFlow allows you to leverage the strengths of different LLM models within a single workflow. By using more efficient models for simpler tasks and more powerful models for complex analysis, you can create workflows that are both fast and capable of high-quality output.


================================================
FILE: docs/examples/features/private-flows.mdx
================================================
---
title: Private Flows
description: Create isolated execution environments within your workflows.
icon: lock
---

Nested flows in ControlFlow allow you to create isolated threads within a larger workflow. This feature is particularly useful when you need to perform operations that shouldn't affect or be visible to the main flow, or when you want to encapsulate a set of tasks for modularity or security reasons.

In this example, we'll demonstrate how to use private flows to process sensitive information without exposing it to the main workflow. In a real-world version of this, you might use a locally-hosted LLM or private API for the sensitive data processing.

## Code

<CodeGroup>
```python Code
import controlflow as cf

@cf.flow(args_as_context=False)
def process_user_data(user_name: str, sensitive_info: str):
    # Main flow context
    print(f"Processing data for user: {user_name}")

    # Create a private flow to handle sensitive information
    with cf.Flow() as private_flow:
        # This task runs in an isolated context
        masked_info = cf.run(
            "Mask the sensitive information",
            context={"sensitive_info": sensitive_info},
            result_type=str
        )
    
    # Task in the main flow can be provided the masked_info as context
    summary = cf.run(
        "Summarize the data processing result",
        context={"user_name": user_name, "masked_info": masked_info},
        result_type=str
    )

    return summary

# Execute the flow
result = process_user_data("Alice", "SSN: 123-45-6789")
print(result)
```
```text Result
The data processing for user Alice has been successfully completed. The sensitive information has been masked appropriately. Here are the details:

- User Name: Alice
- Masked Information: SSN: XXX-XX-6789
```
</CodeGroup>

## Key points

1. **Isolation**: Private flows create an isolated execution environment. Tasks within a private flow cannot access or modify the context of the parent flow directly.

2. **Data encapsulation**: Sensitive information (`sensitive_info`) is only available within the private flow, protecting it from accidental exposure in the main workflow.

3. **Context control**: By setting `args_as_context=False`, we can pass the sensitive information to the flow function without adding it to context automatically. 

4. **Result passing**: Results from the private flow (like `masked_info`) can be explicitly passed back to the main flow for further processing.

5. **Nested structure**: Private flows can be nested within larger workflows, allowing for modular and secure task organization.

## Further reading

- To learn more about flows in ControlFlow, see the [flows documentation](/concepts/flows).

By using private flows, you can create more secure and modular workflows, especially when dealing with sensitive information or when you need to isolate certain operations from the main workflow context.


================================================
FILE: docs/examples/features/tools.mdx
================================================
---
title: Custom Tools
description: Provide tools to expand agent capabilities.
icon: wrench
---

In ControlFlow, tools can be assigned at different levels of your workflow: to the flow itself, to specific agents, or to individual tasks. This flexibility allows you to expand agent capabilities and create more powerful workflows. 

This example demonstrates how to assign and use tools at each level for a file search and information retrieval scenario, using a temporary directory with test files.

<Warning>
The agent in this example can read files on your local file system. While simple precautions are taken to restrict the agent to demo data created specifically for this example, you may consider this a potential security risk.
</Warning>

## Code

In this example, we create an agentic workflow that searches through files looking for important information. To avoid interfering with your local file system, we'll create a context manager that sets up a temporary directory with demo files that the agent can search.

<Info>
This example's code is split into multiple blocks for legibility. Please run each code block in sequence to run the full example.
</Info>
### Set up example data

First, let's create a context manager that sets up a temporary directory with test files:

```python Files
import contextlib
import tempfile
import os

@contextlib.contextmanager
def setup_test_environment():
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create test files
        files = {
            "report.txt": "This report contains important findings from our recent project...",
            "meeting_notes.txt": "In today's important meeting, we discussed the new product launch...",
            "todo.txt": "Important tasks for this week: 1. Client meeting, 2. Finish report...",
        }
        for filename, content in files.items():
            with open(os.path.join(temp_dir, filename), 'w') as f:
                f.write(content)
        
        yield temp_dir

```

### Set up tools

Next, let's create some tools for our agent to use. We have one tool for listing the files in a directory, one for reading the contents of a file, and one for printing a message to the user.

Note that tools can be any Python function, and work best when they have clear type annotations and docstrings.

```python Tools
def list_files(directory: str) -> list[str]:
    """List files in the given directory."""
    return os.listdir(directory)

def read_file(filepath: str) -> str:
    """Read the contents of a file from an absolute filepath."""
    with open(filepath, 'r') as file:
        return file.read()

def update_user(message: str) -> None:
    """Print a status message for the user to read."""
    print(f"[User Notification]: {message}")
    return 'User updated.'
```

### Build a flow
Finally, let's build a workflow. In this example, we want to illustrate the different ways that tools can be provided, so:

- The flow is given the `update_user` tool, so any agent can post a message to the user at any time
- The agent is given the `list_files` tool, so this agent can list files at any time
- The task is given the `read_file` tool, so that capability is only available while that task is running

Now, let's build a flow that explores those files. Note that the context manager from the previous code block is used in this example to set up the example data:

<CodeGroup>
```python Code
import controlflow as cf

agent = cf.Agent(name="FileSearcher", tools=[list_files])


@cf.flow(tools=[update_user], default_agent=agent)  
def file_search_flow(query: str, directory: str):

    # Task 1: Find files containing the search term
    found_files = cf.Task(
        f"Identify files in the directory '{directory}' that might "
        f"relate to'{query}' and return a list of paths.",
        result_type=list[str]
    )

    # Task 2: Analyze file contents and report findings
    cf.run(
        f"Analyze the contents of the files for information related "
        "to the search term.",
        instructions='You must update the user on all your findings to complete the task.',
        tools=[read_file],
        depends_on=[found_files],
        result_type=None  # We don't need a return value as we're printing directly to the user
    )

# Run the flow within our test environment
with setup_test_environment() as temp_dir:
    file_search_flow(query="launch meeting", directory=temp_dir)
```
```text Result
[User Notification]: Listing the files in the directory to 
    identify the relevant contents.

[User Notification]: Content analysis completed. The relevant 
    information related to 'launch meeting' is found in 
    'meeting_notes.txt'. The exact content is: 'In today's 
    important meeting, we discussed the new product launch...'.
```
</CodeGroup>

## Key points

1. **Tool assignment**: Tools can be assigned to flows, agents, and tasks, which lets you control which agents or tasks have access to which tools.

2. **Instructions**: Agents will follow instructions, including how to use tools.

3. **Dependent tasks**: The second task in this flow depends on the first task, which means 1) it automatically has visibility into its result and 2) ControlFlow automatically ran the first task when the second task was run.

4. **Flow context**: The `query` parameter was part of the flow context, which means all tasks could see it even it if wasn't explicitly provided to them. 



## Further reading

- For more details on creating and using tools, see the [Tools documentation](/patterns/tools).
- To learn more about agents and their capabilities, check out the [Agents guide](/concepts/agents).
- For information on how ControlFlow manages task execution and context, refer to the [Running tasks guide](/patterns/running-tasks).

By strategically assigning tools at different levels in your ControlFlow workflows, you can significantly expand the capabilities of your AI agents, enabling them to interact with external systems and perform complex operations.


================================================
FILE: docs/glossary/agentic-workflows.mdx
================================================
Agentic workflows use LLMs as autonomous [agents](/glossary/agents) to achieve a goal. The LLM is invoked iteratively to initiate and manage processes. For example, it can autonomously handle tasks such as scheduling meetings, processing customer queries, or even conducting research by interacting with APIs and databases. The model uses contextual understanding to navigate these tasks, making decisions based on the information it processes in real-time.

Any automated workflow that invokes an AI agent is considered "agentic", even if part or most of the workflow is executed as traditional software. This is because special considerations must be made to accommodate the unique requirements of AI agents, no matter how much of the workflow they automate.

The key characteristics of an agentic workflow include:

- Autonomy: The LLM operates independently for extended periods, adapting to dynamic environments and making real-time adjustments based on the evolving context of the task.

- Contextual understanding: The model maintains an understanding and memory of the ongoing context and uses this information to guide its actions, ensuring coherent and consistent responses.

- Decision-making: The LLM makes decisions based on the information it processes, selecting appropriate strategies and adapting to challenges to achieve its goals.

- Interaction with external systems: The model can interact with APIs, databases, and other tools to gather information, perform computations, or execute actions, extending its capabilities beyond its inherent knowledge and skills.

Rather than single-shot [prompt engineering](/glossary/prompt-engineering), agentic workflows can be enhanced through the application of [flow engineering](/glossary/flow-engineering) techniques, which involve designing and optimizing the workflow itself to guide the agent's decision-making process and improve the quality of its outputs. This seeks to maintain a balance of autonomy and structure in the agent's operations.




================================================
FILE: docs/glossary/agents.mdx
================================================
Agents are autonomous AI systems that can perform complex tasks, make decisions, and interact with their environment without continuous human intervention. These agents leverage the advanced capabilities of LLMs, such as natural language understanding, reasoning, and generation, to operate independently and achieve specific goals.

There are three key characteristics that distinguish agents from single-shot LLM responses:

1. Iteration: Agents engage in multi-step processes, continuously refining their actions based on feedback and new information. Unlike single-shot responses, which provide a one-time output based on a given prompt, agents iterate on their own outputs, allowing for more dynamic and adaptive behavior.

2. Tool use: Agents can interact with external tools and systems to gather information, perform computations, or execute actions. This ability to use tools enables agents to extend their capabilities beyond the knowledge and skills inherent in the LLM itself. By integrating tool use into their decision-making process, agents can solve more complex problems and adapt to a wider range of scenarios.

3. Planning and workflow: Agents are designed to break down complex tasks into smaller, manageable steps and create structured workflows to accomplish their goals. They can prioritize subtasks, make decisions based on intermediate results, and adjust their plans as needed. This planning capability allows agents to handle multi-faceted problems that require a sequence of coordinated actions.

LLM agents maintain an understanding of the ongoing context and use this information to guide their actions. They actively work towards achieving specific objectives or goals by selecting appropriate strategies, adapting to challenges, and learning from their experiences. The autonomous and goal-oriented nature of LLM agents enables them to operate effectively in a variety of domains and scenarios, making them well-suited for [agentic workflows](/glossary/agentic-workflows).



================================================
FILE: docs/glossary/cf-agent.mdx
================================================
---
title: Agent
---

<Info>
This glossary entry is about the term "agent" in the context of ControlFlow. For LLM agents in general, see the [Agents](/glossary/agents) entry.
</Info>

An Agent in ControlFlow is an autonomous entity designed to execute tasks within a workflow. Agents leverage the capabilities of LLMs to perform various functions, such as generating text, answering questions, and interacting with users. Each agent can be tailored with specific instructions, tools, and models to handle distinct roles or domains effectively.

Agents are fundamental to the ControlFlow framework, enabling the execution of tasks according to the defined objectives and context. They operate independently, using the provided instructions to achieve the desired outcomes. Agents can also interact with each other and with human users when necessary, making them versatile components in creating sophisticated and dynamic AI-powered workflows.

By assigning appropriate agents to tasks, developers can ensure that each task is handled by the most suitable entity, optimizing the overall performance and efficiency of the workflow. ControlFlow's agent-based architecture allows for seamless integration of AI capabilities into traditional software workflows, providing a robust and scalable solution for complex application logic.


================================================
FILE: docs/glossary/cf-flow.mdx
================================================
---
title: Flow
---

A flow is a high-level container that encapsulates and orchestrates an entire AI-powered workflow in ControlFlow. It provides a structured way to manage tasks, agents, tools, and shared context. A flow maintains a consistent state across all its components, allowing agents to communicate and collaborate effectively.

Flows allow developers to break down complex application logic into discrete tasks, define the dependencies and relationships between them, and assign suitable agents to execute them. By providing a high-level orchestration mechanism, flows enable developers to focus on the logic of their application while ControlFlow manages the details of agent selection, data flow, and error handling.


================================================
FILE: docs/glossary/cf-task.mdx
================================================
---
title: Task
---
A task represents a discrete objective or goal within a ControlFlow workflow that an AI agent needs to solve. Tasks are the fundamental building blocks of ControlFlow and act as a bridge between AI agents and application logic. Each task is defined by its specific objective, instructions, expected result type, and any required context or tools.

Tasks can have [dependencies](/glossary/dependencies) that define their relationships and execution order. Dependencies ensure that tasks are completed in a logical sequence, where one task's output may be required as input for another, or certain tasks must be completed before others can begin. This allows developers to create complex workflows that are easy to understand and manage, ensuring that each task is executed with the necessary context and prerequisites.

Tasks have one or more [agents](/glossary/agent) assigned to them. By assigning appropriate agents, developers can optimize the execution of tasks by leveraging the specialized capabilities or model characteristics of different agents, ensuring each task is handled by the most suitable entity.

By specifying the parameters and dependencies of each task, developers can build sophisticated and dynamic workflows that leverage the full capabilities of AI agents in a structured and efficient manner.


================================================
FILE: docs/glossary/dependencies.mdx
================================================
Dependencies in ControlFlow refer to the relationships between tasks that dictate the order and conditions under which tasks are executed. They ensure that tasks are completed in a logical sequence, where one task’s output may be required as input for another, or certain tasks must be completed before others can begin.

There are several types of dependencies in ControlFlow:

- Sequential dependencies: One task must be completed before another can start.
- Context dependencies: The result of one task is used as input for another.
- Subtask dependencies: A task consists of multiple subtasks that must be completed before the parent task is considered done.

Dependencies help in managing complex workflows by defining clear relationships and execution order among tasks. By specifying dependencies, developers can create structured and efficient workflows that ensure the correct flow of data and completion of tasks, thereby enhancing the reliability and maintainability of AI-powered applications.


================================================
FILE: docs/glossary/fine-tuning.mdx
================================================
---
title: Fine-tuning
---

Fine-tuning is a process in machine learning where a pre-trained model, such as an [LLM](/glossary/llm), is further trained on a specific dataset to adapt it to a particular task or domain. This process leverages the broad knowledge and language understanding that the model has already acquired during its initial training on large and diverse datasets.

Fine-tuning involves using a smaller, task-specific dataset to continue training the pre-trained model. By doing so, the model can learn to perform more specialized tasks with greater accuracy and relevance. For example, an LLM can be fine-tuned on a dataset of medical texts to improve its performance in medical question answering or on a dataset of legal documents to enhance its capabilities in legal text analysis.

The fine-tuning process typically involves adjusting the model’s parameters using techniques such as supervised learning, where the model learns to produce the correct output based on the provided input and corresponding labels. This approach allows the model to retain its general language understanding while becoming more proficient in the specific domain or task at hand. Fine-tuning is a powerful technique that enables the adaptation of versatile LLMs to a wide range of applications, ensuring high performance and relevance in specialized contexts.


================================================
FILE: docs/glossary/flow-engineering.mdx
================================================
"Flow engineering" is a term increasingly used to describe a specific approach to designing and optimizing [agentic workflows](/glossary/agentic-workflows) for LLMs. In flow engineering, the focus is on engineering the workflow itself to guide the agent's decision-making process and improve the quality of its outputs.

Similar to how [prompt engineering](/glossary/prompt-engineering) emphasizes the importance of crafting natural-language messages to elicit desired responses from LLMs, flow engineering recognizes the significance of the overall workflow structure in determining the agent's behavior and performance. By carefully designing the steps, decision points, and feedback loops within the workflow, developers can create agents that are more effective, efficient, and adaptable.

Flow engineering involves breaking down complex tasks into smaller, manageable components and defining the optimal sequence of actions for the agent to follow. This structured approach allows for better control over the agent's behavior and enables developers to incorporate domain-specific knowledge and best practices into the workflow.


================================================
FILE: docs/glossary/flow-orchestration.mdx
================================================
---
title: Flow
---

<Info>
This glossary entry is about the term "flow" in the context of workflow orchestration. For ControlFlow flows specifically, see the [Flow](/glossary/flow) entry.
</Info>

In the context of workflow orchestration, a flow represents the overall sequence or arrangement of tasks that make up a complete workflow. A flow defines the logical structure and order in which tasks should be executed to achieve a specific goal or outcome. It encapsulates the dependencies, control flow, and data flow between tasks. 

Orchestration frameworks use the flow definition to coordinate the execution of tasks, handle data passing between them, and manage the overall lifecycle of the workflow. Flows can be designed to handle complex scenarios, including conditional branching, parallel execution, and error handling.


================================================
FILE: docs/glossary/glossary.mdx
================================================
---
title: Welcome
---
Welcome to ControlFlow's AI Glossary! 

This glossary provides definitions and explanations for key concepts in modern AI and the ControlFlow framework. Whether you're new to ControlFlow or looking to deepen your understanding, this resource is designed to help you navigate the terminology and concepts that are essential for working with LLMs and AI workflows.



================================================
FILE: docs/glossary/llm.mdx
================================================
---
title: Large language models
---
A Large language model (LLM) is a type of artificial intelligence model trained on vast amounts of text data to understand and generate human-like language. Based on deep learning architectures such as Transformer models, LLMs capture complex patterns and relationships within the training data. Their extensive size, often containing billions of parameters, enables them to develop a deep understanding of language and acquire a broad range of knowledge.

LLMs excel in various natural language processing tasks, including text generation, language translation, question answering, and sentiment analysis. Their ability to generate contextually relevant and meaningful responses makes them valuable for applications like chatbots, content creation, and language-based interfaces. LLMs are trained using self-supervised learning techniques, predicting the next word or sequence of words in a given context. This exposure to diverse text data allows them to grasp the intricacies of language, including grammar, syntax, semantics, and world knowledge, enabling them to produce coherent and contextually appropriate responses.

More than just generating text, LLMs encode knowledge that can be used to produce a variety of non-algorithmic outputs, including using tools, writing code, generating images, and creating music. LLMs can also be [fine-tuned](/glossary/fine-tuning) on specific tasks or domains to improve performance on targeted applications.

However, LLMs have limitations. They can generate biased or factually incorrect outputs based on biases in their training data. They may struggle with tasks requiring deep reasoning, common sense understanding, or domain-specific knowledge. Additionally, the training and deployment of large-scale LLMs can be computationally intensive and resource-demanding. Despite these challenges, LLMs remain powerful tools for building sophisticated language-based applications.


================================================
FILE: docs/glossary/prompt-engineering.mdx
================================================
Prompt engineering is the practice of crafting precise and effective input prompts to elicit desired responses from large language models (LLMs). This method focuses on designing the exact wording, structure, and context of the prompt to guide the model towards generating specific outputs. It requires an understanding of the model’s capabilities and the nuances of language to maximize the quality and relevance of the responses.

Unlike [flow engineering](/glossary/flow-engineering), which involves a multi-step, iterative process to refine outputs, prompt engineering aims to achieve the desired result with a single, well-constructed input. This approach is particularly useful for straightforward tasks where the model's initial response is expected to be accurate and sufficient. However, it can be limited in handling complex problems that require deeper analysis and iterative refinement.

Prompt engineering is essential in scenarios where quick, efficient responses are needed, and the task complexity is manageable with a single input. It is a critical skill for developers and users who interact with LLMs, enabling them to harness the model's full potential by providing clear and concise prompts that lead to high-quality outputs.


================================================
FILE: docs/glossary/task-orchestration.mdx
================================================
---
title: Task
---

<Info>
This glossary entry is about the term "task" in the context of workflow orchestration. For ControlFlow tasks specifically, see the [Task](/glossary/task) entry.
</Info>

In the context of workflow orchestration, a task represents a single unit of work or a specific step within a larger workflow. Tasks are the building blocks of workflows and encapsulate discrete actions or operations that need to be performed. Each task typically has input parameters, execution logic, and produces an output or result.

Tasks can have upstream dependencies on other tasks, meaning they may require the completion of certain tasks before they can start executing. These dependencies define the order and relationship between tasks within a workflow, as well as move data between tasks. Parent/child dependencies help organize execution by nesting tasks within other tasks.


================================================
FILE: docs/glossary/tools.mdx
================================================
Tools in ControlFlow are specialized functions or resources that agents can use to accomplish specific tasks within a workflow. They provide the agents with additional capabilities beyond their inherent natural language processing abilities, enabling them to perform more complex and varied operations.

Tools can include Python functions, APIs, libraries, or any resource that an agent might need to fulfill a task’s requirements. For instance, a tool might be a function to fetch data from a database, process and analyze data, interact with external services, or perform calculations.

By equipping agents with the appropriate tools, developers can enhance the functionality and efficiency of their workflows, ensuring that agents can effectively complete tasks that require specialized knowledge or operations. Tools are defined and associated with tasks or agents, and they enable a modular and extensible approach to building AI-powered workflows in ControlFlow.


================================================
FILE: docs/glossary/workflow.mdx
================================================
A workflow is a sequence of interconnected tasks or steps that represent a specific business process or operation. In the context of orchestration, a workflow defines the order and dependencies of these tasks, ensuring that they are executed in a coordinated and efficient manner.

Workflows are commonly used in complex systems to automate and streamline processes, such as data processing, application deployment, or service orchestration. They provide a high-level view of the entire process, allowing developers and operators to define, manage, and monitor the execution of tasks.

In an orchestration system, a workflow typically consists of multiple activities, each representing a specific task or operation. These activities can be executed sequentially, in parallel, or based on certain conditions, enabling the system to handle complex scenarios and adapt to changing requirements.

Note that an [agentic workflow](/glossary/agentic-workflow) is a specific type of workflow that leverages AI agents to perform tasks and make decisions within the process. By combining human and machine intelligence, agentic workflows can automate repetitive tasks, optimize resource allocation, and improve decision-making in various domains.


================================================
FILE: docs/guides/configure-llms.mdx
================================================
---
title: LLM Models
description: ControlFlow supports a variety of LLMs and model providers.
icon: sliders
---

ControlFlow is optimized for workflows that are composed of multiple tasks, each of which can be completed by a different agent. One benefit of this approach is that you can use a different LLM for each task, or even for each agent assigned to a task. 

ControlFlow will ensure that all agents share a consistent context and history, even if they are using different models. This allows you to leverage the relative strengths of different models, depending on your requirements. 

## The default model

By default, ControlFlow uses OpenAI's GPT-4o model. GPT-4o is an extremely powerful and popular model that provides excellent out-of-the-box performance on most tasks. This does mean that to run an agent with no additional configuration, you will need to provide an OpenAI API key. 

## Selecting a different LLM

Every ControlFlow agent can be assigned a specific LLM. When instantiating an agent, you can pass a `model` parameter to specify the LLM to use. 

ControlFlow agents can use any LangChain LLM class that supports chat-based APIs and tool calling. For a complete list of available models, settings, and instructions, please see LangChain's [LLM provider documentation](https://python.langchain.com/docs/integrations/chat/).

<Tip>
ControlFlow includes the required packages for OpenAI, Azure OpenAI, and Anthropic models by default. To use other models, you'll need to first install the corresponding LangChain package and supply any required credentials. See the model's [documentation](https://python.langchain.com/docs/integrations/chat/) for more information.
</Tip>


### Automatic configuration

ControlFlow can automatically load LLMs from certain providers, based on a parameter. The model parameter must have the form `{provider key}/{model name}`. 

For example:
```python
import controlflow as cf

openai_agent = cf.Agent(model="openai/gpt-4o-mini")
anthropic_agent = cf.Agent(model="anthropic/claude-3-haiku-20240307")
groq_agent = cf.Agent(model="groq/mixtral-8x7b-32768")
```

Note that loading a model from a string is convenient, but does not allow you to configure all of the model's parameters. For full control, see the docs on [manual configuration](#manual-configuration).

At this time, supported providers for automatic configuration include:

| Provider | Provider key | Required dependencies |
| -------- | ----------------- | ----------------- |
| OpenAI   | `openai`       | (included) |
| Azure OpenAI | `azure-openai` | (included) |
| Anthropic | `anthropic` | (included) |
| Google   | `google`       | `langchain_google_genai` |
| Groq      | `groq`       | `langchain_groq` |
| Ollama    | `ollama`    | `langchain-ollama` |

If the required dependencies are not installed, ControlFlow will be unable to load the model and will raise an error.


### Manual configuration


To configure a different LLM, follow these steps:
<Steps>
<Step title="Install required packages">
To use an LLM, first make sure you have installed the appropriate [provider package](https://python.langchain.com/docs/integrations/chat/). For example, to use a Google model, run:

```bash
pip install langchain_google_genai
```
</Step>
<Step title="Configure API keys">
You must provide the correct API keys and configuration for the LLM you want to use. These can be provided as environment variables or when you create the model in your script. For example, to use an OpenAI model, you must set the `OPENAI_API_KEY` environment variable:

```bash
export OPENAI_API_KEY=<your-api-key>
```
For model-specific instructions, please refer to the provider's [documentation](https://python.langchain.com/docs/integrations/chat/).
</Step>

<Step title="Create the model">
Create the LLM model in your script, including any additional parameters. For example, to use Claude 3 Opus:

```python
from langchain_anthropic import ChatAnthropic

# create the model
model = ChatAnthropic(model='claude-3-opus-20240229')
```

</Step>
<Step title="Pass the model to an agent">
Finally, configure an agent with the model:

```python
import controlflow as cf

# provide the model to an agent
agent = cf.Agent(model=model)
```
</Step>
</Steps>


In addition to choosing a specific model, you can also configure the model's parameters. For example, you can set the temperature for GPT-4o:

```python
import controlflow as cf
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model='gpt-4o', temperature=0.1)
agent = cf.Agent(model=model)

assert agent.model.temperature == 0.1
```

## Changing the default model

ControlFlow has a few ways to customize the default LLM. 

<Tip>
ControlFlow includes OpenAI and Azure OpenAI models by default. To use other models, you'll need to first install the corresponding LangChain package and supply any required credentials. See the model's [documentation](https://python.langchain.com/docs/integrations/chat/) for more information.
</Tip>

### From a model object

To use any model as the default LLM, create the model object in your script and assign it to `controlflow.defaults.model`. It will be used by any agent that does not have a model specified.

```python
import controlflow as cf
from langchain_anthropic import ChatAnthropic

# set the default model
cf.defaults.model = ChatAnthropic(
    model='claude-3-opus-20240229', 
    temperature=0.1,
)

# check that the default model is loaded
assert cf.Agent('Marvin').model.model_name == 'claude-3-opus-20240229'
```
### From a string setting

You can also specify a default model using a string, which is convenient though it doesn't allow you to configure advanced model settings. This must be a string in the form `{provider key}/{model name}`, following the same guidelines as [automatic LLM configuration](#automatic-configuration).

You can apply this setting either by using an environment variable before you import ControlFlow or in your script at runtime. For example, to use GPT 3.5 Turbo as the default model:

<CodeGroup>
```bash Set an environment variable
export CONTROLFLOW_LLM_MODEL=openai/gpt-4o-mini
```

```python Set a runtime variable
import controlflow as cf
# set the default model as a string
cf.defaults.model = "openai/gpt-4o-mini"

# check that the default model is loaded
assert cf.Agent('Marvin').model.model_name == 'gpt-4o-mini'
```
</CodeGroup>

<Note>
The default model can only be set by environment variable before importing ControlFlow. Once ControlFlow is imported, it reads the `controlflow.settings.llm_model` value to create the default model object.
</Note>



================================================
FILE: docs/guides/default-agent.mdx
================================================
---
title: Configuring a Default Agent
sidebarTitle: Default Agent
description: Set global and flow-specific defaults.
icon: robot
---

ControlFlow uses a default agent when no specific agents are assigned to a task. Understanding how to configure and override this default agent at different levels can help you create more flexible and customized workflows.

## Changing the Global Default Agent

The global default agent (whose name, of course, is Marvin) uses whatever [default model](/guides/configure-llms#changing-the-default-model) you've configured. It has a basic set of general-purpose instructions and is not equipped with any tools.

To change the global default agent, assign a new agent to `controlflow.defaults.agent`:

```python
import controlflow as cf

# Create a new agent
agent = cf.Agent('Deep Thought', instructions='Answer every question with 42')

# Set the global default agent
cf.defaults.agent = agent

# Create a task without specifying an agent
task = cf.Task('What is 2 + 2?')
task.run()  # Result: 42
```

## Changing a Flow's Default Agent

You can also set a default agent for a specific flow. by using its `default_agent` parameter when decorating your flow function or creating the flow object.

```python
import controlflow as cf

researcher = cf.Agent('Researcher', instructions='Conduct thorough research')
writer = cf.Agent('Writer', instructions='Write clear, concise content')

@cf.flow(default_agent=writer)
def research_flow():
    research_task = cf.Task("Research the topic", agents=[researcher])
    writing_task = cf.Task("Write a report") # will use the writer agent by default
    return writing_task

result = research_flow()
```

In this example, both the `research_task` and `writing_task` will use the `researcher` and `writer` agents by default.

## Agent Selection Precedence

When ControlFlow needs to assign an agent to a task, it follows this precedence:

1. Agents specified directly on the task (`task.agents`)
2. The agent specified by the flow (`@flow(default_agent=...)`)
3. The global default agent (`controlflow.defaults.agent`)

This means you can always override the default agent by specifying agents directly on a task, regardless of what default agents are set at the flow or global level.

```python
import controlflow as cf

global_agent = cf.Agent('Global', instructions='I am the global default')
cf.defaults.agent = global_agent
flow_agent = cf.Agent('Flow', instructions='I am the flow default')
task_agent = cf.Agent('Task', instructions='I am specified for this task')

@cf.flow(default_agent=flow_agent)
def example_flow():
    task1 = cf.run("Task with flow default")
    task2 = cf.run("Task with specific agent", agents=[task_agent])
    
task3 = cf.run("Task with global default")


results = example_flow()
```

In this example:
- `task1` will use the `flow_agent`
- `task2` will use the `task_agent`
- `task3` will use the `global_agent`

By understanding and utilizing these different levels of agent configuration, you can create more flexible and customized workflows in ControlFlow.


================================================
FILE: docs/guides/default-memory.mdx
================================================
---
title: Configure a Default Memory Provider
sidebarTitle: Default Memory Provider
description: Set up a default persistent memory provider for your agents
icon: brain
---
import { VersionBadge } from '/snippets/version-badge.mdx'

<VersionBadge version="0.10" />
ControlFlow's [memory](/patterns/memory) feature allows agents to store and retrieve information across multiple workflows. Memory modules are backed by a vector database, configured using a `MemoryProvider`. 

Setting up a default provider simplifies the process of creating memory objects throughout your application. Once configured, you can create memory objects without specifying a provider each time.

<Tip>
While ControlFlow does not include any vector database dependencies by default, the default provider is set to `"chroma-db"`. This means that if you install the `chromadb` package, your memory modules will work without any additional configuration.
</Tip>

## Install dependencies

To use a provider, you must first install its dependencies. Please refer to the [Memory doc](/patterns/memory) to see all supported providers and their required dependencies. 

For example, to use the default [Chroma](https://trychroma.com/) provider, you need to install `chromadb`:

```bash
pip install chromadb
```

## Configure a default provider

There are two ways to set up a default provider: using a string setting for common defaults, or instantiating a custom provider. Here, we'll use a persistent Chroma database as our example.

### String configurations

For simple provider setups, you can modify ControlFlow's default settings using a string value. The default value is `"chroma-db"`, which will create a persistent Chroma database. To change it:

<CodeGroup>
```bash Environment variable
export CONTROLFLOW_MEMORY_PROVIDER="chroma-ephemeral"
```
```python Runtime
import controlflow as cf

cf.settings.memory_provider = "chroma-ephemeral"
```
</CodeGroup>

For a list of available string configurations, see the [Memory pattern guide](/patterns/memory).

### Custom provider configuration

For more advanced setups, instantiate a provider with custom settings and assign it to the ControlFlow default. Note this must be done at runtime.

```python
import controlflow as cf
from controlflow.memory.providers.chroma import ChromaMemory
import chromadb

# Set the default provider
cf.defaults.memory_provider = ChromaMemory(
    client=chromadb.PersistentClient(path="/custom/path"),
)
```



================================================
FILE: docs/guides/settings.mdx
================================================
---
title: Settings
icon: gear
---

ControlFlow provides a variety of settings to configure its behavior. These can be configured via environment variables or programmatically.


## Environment variables
All settings can be set via environment variables using the format `CONTROLFLOW_<setting name>`.

For example, to set the default LLM model to `gpt-4o-mini` and the log level to `DEBUG`, you could set the following environment variables:
```shell
export CONTROLFLOW_LLM_MODEL=openai/gpt-4o-mini
export CONTROLFLOW_LOG_LEVEL=DEBUG
```

You can also set these values in a `.env` file. By default, ControlFlow will look for a `.env` file at `~/.controlflow/.env`, but you can change this behavior by setting the `CONTROLFLOW_ENV_FILE` environment variable.

```shell
export CONTROLFLOW_ENV_FILE="~/path/to/.env"
```

## Runtime settings
You can examine and modify ControlFlow's settings at runtime by inspecting or updating the `controlflow.settings` object. Most -- though not all -- changes to settings will take effect immediately. Here is the above example, but set programmatically:

```python
import controlflow as cf

cf.settings.llm_model = 'openai/gpt-4o-mini'
cf.settings.log_level = 'DEBUG'
```

## Available settings

### Home settings

- `home_path`: The path to the ControlFlow home directory. Default: `~/.controlflow`

### Display and logging settings

- `log_level`: The log level for ControlFlow. Options: `DEBUG`, `INFO`, `WARNING`, 
`ERROR`, `CRITICAL`. Default: `INFO`
- `log_prints`: Whether to log workflow prints to the Prefect logger by default. 
Default: `False`
- `log_all_messages`: If True, all LLM messages will be logged at the debug level. 
Default: `False`
- `enable_default_print_handler`: If True, a PrintHandler will be enabled and 
automatically pretty-print agent events. Note that this may interfere with logging. 
Default: `True`

### Orchestration settings

- `orchestrator_max_agent_turns`: The default maximum number of agent turns per 
orchestration session. If None, orchestration may run indefinitely. This setting can 
be overridden on a per-call basis. Default: `100`
- `orchestrator_max_llm_calls`: The default maximum number of LLM calls per 
orchestrating session. If None, orchestration may run indefinitely. This setting can 
be overridden on a per-call basis. Default: `1000`
- `task_max_llm_calls`: The default maximum number of LLM calls over a task's 
lifetime. If None, the task may run indefinitely. This setting can be overridden on 
a per-task basis. Default: `None`

### LLM settings

- `llm_model`: The default LLM model for agents. Default: `openai/gpt-4o`
- `llm_temperature`: The temperature for LLM sampling. Default: `0.7`
- `max_input_tokens`: The maximum number of tokens to send to an LLM. Default: 
`100000`

### Debug settings

- `debug_messages`: If True, all messages will be logged at the debug level. Default: 
`False`
- `tools_raise_on_error`: If True, an error in a tool call will raise an exception. 
Default: `False`
- `tools_verbose`: If True, tools will log additional information. Default: `True`

### Experimental settings

- `enable_experimental_tui`: If True, the experimental TUI will be enabled. If False, 
the TUI will be disabled. Default: `False`
- `run_tui_headless`: If True, the experimental TUI will run in headless mode, which 
is useful for debugging. Default: `False`

### Prefect settings

These are default settings for Prefect when used with ControlFlow. They can be 
overridden by setting standard Prefect environment variables.

- `prefect_log_level`: The log level for Prefect. Options: `DEBUG`, `INFO`, 
`WARNING`, `ERROR`, `CRITICAL`. Default: `WARNING`



================================================
FILE: docs/llm-guides/examples-guide.md
================================================
# Guide for Creating ControlFlow Examples

This guide outlines the process for creating clear, informative, and consistent examples for ControlFlow documentation. Follow these steps to produce high-quality examples that showcase ControlFlow's features and capabilities.

## 1. Example Structure

Each example should follow this general structure:

```markdown
---
title: [Concise Title]
description: [Brief description of what the example demonstrates]
icon: [FontAwesome icon name]
---

[1-2 sentence introduction explaining the task and its relevance]

## Code

[Brief explanation of what the code does]

```python
[Code block demonstrating the ControlFlow implementation]
```

[Usage examples in a CodeGroup, if applicable, as it creates a single tabbed view]

<CodeGroup>
```python Code
[Full, copyable code for the example, including prints]
```
```text Result
the result, including any intermiediate output that might be helpful
```
</CodeGroup>


ALTERNATIVELY, use a code block for a single example including a commented result

ALTERNATIVELY, use a CodeGroup for multiple examples with commented results



## Key concepts

[Explanation of key ControlFlow features demonstrated in the example]

1. **[Feature Name](/link-to-docs)**: [Brief explanation of the feature]

   ```python
   [Code snippet illustrating the feature]
   ```

[2-3 sentences wrapping up the example and its significance]
```

## 2. Title and Description

- Use a concise, descriptive title that clearly indicates the task or concept being demonstrated.
- Provide a brief (1-2 sentence) description that expands on the title and gives context.
- Choose an appropriate FontAwesome icon that represents the task or concept.

## 3. Introduction

- Begin with a 1-2 sentence introduction that explains the task or concept and its relevance in natural language processing or AI applications.
- If the example demonstrates multiple approaches or variations, briefly mention this.

## 4. Code Section

- Start with a brief explanation of what the code does and how it approaches the task.
- Present the main implementation code in a clear, well-commented Python code block.
- If there are multiple variations or approaches, present them sequentially, explaining the differences between each approach.
- Use type hints and follow PEP 8 style guidelines in the code.
- Import `controlflow as cf` at the beginning of each code block so it can be copied directly.
- Do not create agents unless you are demonstrating a specific feature (e.g. LLM selection, instructions, reusable tools, etc.)
- Try to write code that is as short as possible while still being clear and demonstrating the feature.
- Only use a flow if your tasks need to share history, otherwise just use a single task
- Do not import Dict or List from typing; use builtin dict or list instead

## 5. Usage Examples

- Provide 1-3 usage examples that demonstrate how to use the implemented function(s).
- Use the `<CodeGroup>` component to organize multiple examples.
- Include both the input and the expected output in the examples.
- Choose diverse and relevant examples that showcase different aspects of the implementation.

## 6. Key Concepts

- Identify 3-5 key ControlFlow features or concepts demonstrated in the example (if possible)
- For each concept:
  1. Provide a brief explanation of what the feature does and why it's important.
  2. Include a code snippet that illustrates the feature in use.
  3. Link to the relevant ControlFlow documentation for that feature.
- Arrange the concepts in order of importance or complexity.
- Do not consider controlflow basics like creating or running a task to be key concepts (or even "simple task creation")

## 7. Conclusion

- End with 2-3 sentences that wrap up the example, emphasizing its significance and how it showcases ControlFlow's capabilities.
- Mention any potential extensions or variations of the example that users might consider.

## 8. Style and Tone

- Use clear, concise language throughout the example.
- Maintain a professional and educational tone, avoiding overly casual language.
- Assume the reader has basic programming knowledge but may be new to ControlFlow.
- Use active voice and present tense where possible.

## 9. Consistency

- Ensure consistency in formatting, terminology, and style across all examples.
- Use the same naming conventions for variables and functions across related examples.
- Maintain a consistent level of detail and explanation across examples.

## 10. Review and Refinement

- After creating the example, review it for clarity, correctness, and completeness.
- Ensure all code is functional and produces the expected results.
- Check that all links to ControlFlow documentation are correct and up-to-date.
- Refine the language and explanations to be as clear and concise as possible.

By following this guide, you'll create informative, consistent, and high-quality examples that effectively showcase ControlFlow's features and capabilities. These examples will help users understand how to implement various NLP and AI tasks using ControlFlow, encouraging adoption and proper usage of the framework.


================================================
FILE: docs/llm-guides/llm-guide.md
================================================
# Comprehensive ControlFlow Guide for LLMs: From Basics to Advanced Techniques

## Introduction

This guide is designed to provide a comprehensive understanding of ControlFlow, a Python framework for building agentic AI workflows. As an LLM, your goal is to become an expert in ControlFlow, capable of explaining its concepts, writing idiomatic code, and producing accurate documentation. This guide will give you the foundation to effectively query and utilize the complete ControlFlow documentation.

## Core Concepts

### 1. Tasks

Tasks are the fundamental building blocks of ControlFlow workflows. They represent discrete, observable units of work for AI agents to complete.

Key properties of tasks:
- `objective`: A string describing the task's goal
- `result_type`: The expected output type (e.g., `str`, `int`, `list`, or a Pydantic model)
- `instructions`: Detailed guidance for completing the task
- `context`: Additional information or data needed for the task
- `agents`: AI entities assigned to work on the task
- `tools`: Functions that extend the task's capabilities

Example of creating and running a basic task:

```python
import controlflow as cf

result = cf.run("Write a haiku about artificial intelligence")
print(result)
```

Tasks have a defined lifecycle with various states:
- PENDING: Initial state when a task is created
- RUNNING: Task is currently being executed by an agent
- SUCCESSFUL: Task has completed successfully
- FAILED: Task has failed to complete
- SKIPPED: Task was skipped (usually due to workflow logic)

Example of checking task states:

```python
task = cf.Task("Perform complex calculation")
print(task.status)  # TaskStatus.PENDING

task.run()

if task.is_successful():
    print("Task completed successfully")
elif task.is_failed():
    print(f"Task failed: {task.result}")
```

### 2. Agents

Agents are AI entities that execute tasks. They can be configured with specific LLM models, instructions, and tools.

Example of creating a specialized agent:

```python
data_analyst = cf.Agent(
    name="Data Analyst",
    model="openai/gpt-4o",
    instructions="""
    You are a data analysis expert. 
    Always provide detailed statistical insights.
    Use Python for data manipulation when necessary.
    """,
    tools=[cf.tools.code.python, custom_data_tool],
    interactive=True
)

result = cf.run(
    "Analyze the provided dataset",
    agents=[data_analyst],
    context={"dataset": large_dataset}
)
```

### 3. Flows

Flows are high-level containers that orchestrate tasks and agents. They provide shared context and history for all components within a workflow.

Example of a basic flow:

```python
@cf.flow
def simple_analysis_flow(data: dict):
    cleaned_data = cf.run("Clean and preprocess the data", context={"data": data})
    analysis_result = cf.run("Perform data analysis", depends_on=[cleaned_data])
    return cf.run("Generate report", depends_on=[analysis_result])

result = simple_analysis_flow(my_data)
```

### 4. Tools

Tools are functions that extend agent capabilities, enabling interactions with external systems or complex computations.

Example of defining and using a custom tool:

```python
import controlflow as cf

def fetch_stock_price(symbol: str) -> float:
    # Simulating API call
    import random
    return random.uniform(10, 1000)

@cf.flow
def stock_analysis_flow(symbols: list[str]):
    prices = cf.run(
        "Fetch current stock prices",
        tools=[fetch_stock_price],
        context={"symbols": symbols}
    )
    return cf.run("Analyze stock prices", context={"prices": prices})

result = stock_analysis_flow(["AAPL", "GOOGL", "MSFT"])
```

## Advanced Features

### 1. Structured Results

ControlFlow supports structured outputs using Pydantic models or Python types:

```python
from pydantic import BaseModel

class StockAnalysis(BaseModel):
    symbol: str
    current_price: float
    recommendation: str

result = cf.run(
    "Analyze Apple stock",
    result_type=StockAnalysis,
    context={"symbol": "AAPL"}
)
print(f"Recommendation for {result.symbol}: {result.recommendation}")
```

### 2. Multi-Agent Collaboration

Assign multiple agents to tasks for complex problem-solving:

```python
researcher = cf.Agent(name="Researcher", instructions="Conduct thorough research on topics")
writer = cf.Agent(name="Writer", instructions="Write clear and engaging content")
editor = cf.Agent(name="Editor", instructions="Review and improve written content")

@cf.flow
def collaborative_writing_flow(topic: str):
    research = cf.run("Research the topic", agents=[researcher], context={"topic": topic})
    draft = cf.run("Write initial draft", agents=[writer], depends_on=[research])
    final = cf.run("Edit and finalize the content", agents=[editor], depends_on=[draft])
    return final

article = collaborative_writing_flow("Impact of AI on healthcare")
```

### 3. Dependency Management

Define relationships between tasks for logical execution order:

```python
@cf.flow
def data_pipeline_flow(raw_data: dict):
    cleaned_data = cf.Task("Clean raw data", context={"data": raw_data})
    transformed_data = cf.Task("Transform cleaned data", depends_on=[cleaned_data])
    analyzed_data = cf.Task("Analyze transformed data", depends_on=[transformed_data])
    visualization = cf.Task("Create data visualizations", depends_on=[analyzed_data])
    report = cf.Task("Generate final report", depends_on=[analyzed_data, visualization])
    
    return report.run()
```

### 4. Context Sharing

ControlFlow automatically shares context between related tasks and flows:

```python
@cf.flow
def context_sharing_flow(initial_data: dict):
    task1 = cf.run("Process initial data", context={"data": initial_data})
    # task2 automatically has access to task1's result
    task2 = cf.run("Further process data", depends_on=[task1])
    # task3 has access to results from both task1 and task2
    return cf.run("Synthesize results", depends_on=[task1, task2])
```

### 5. Flexible Control

Balance between AI autonomy and developer-defined structure:

```python
@cf.flow
def flexible_analysis_flow(data: dict, analysis_type: str):
    if analysis_type == "quick":
        return cf.run("Perform quick analysis", context={"data": data})
    elif analysis_type == "deep":
        subtask1 = cf.run("Perform in-depth analysis part 1", context={"data": data})
        subtask2 = cf.run("Perform in-depth analysis part 2", depends_on=[subtask1])
        return cf.run("Synthesize in-depth analysis", depends_on=[subtask2])
    else:
        return cf.run("Determine and perform appropriate analysis", context={"data": data, "type": analysis_type})
```

### 6. Interactivity

Enable user interactions within workflows:

```python
@cf.flow
def interactive_research_flow():
    topic = cf.run(
        "Determine the research topic with user input",
        interactive=True,
        result_type=str
    )
    
    outline = cf.run(
        "Create a research outline",
        context={"topic": topic},
        result_type=list[str]
    )
    
    for section in outline:
        content = cf.run(
            f"Write content for section: {section}",
            interactive=True,
            result_type=str
        )
        cf.run(
            "Review and improve section content",
            context={"section": section, "content": content},
            interactive=True
        )
    
    return cf.run(
        "Compile final research document",
        context={"outline": outline},
        result_type=str
    )

result = interactive_research_flow()
```

### 7. Nested Flows and Private Contexts

Create sub-flows for modular workflow design and data privacy:

```python
@cf.flow
def main_workflow(sensitive_data: str):
    print("Starting main workflow")
    
    with cf.Flow() as private_flow:
        # This task runs in an isolated context
        processed_data = cf.run(
            "Process sensitive data",
            context={"sensitive_data": sensitive_data},
            result_type=str
        )
    
    # Use processed data without exposing sensitive information
    return cf.run(
        "Generate report based on processed data",
        context={"processed_data": processed_data},
        result_type=str
    )

result = main_workflow("CONFIDENTIAL_INFO")
```

### 8. Dynamic Task Generation

Use AI to create new tasks based on intermediate results:

```python
@cf.flow
def dynamic_workflow():
    initial_task = cf.run("Analyze the problem and identify necessary subtasks")
    subtasks = cf.run(
        "Generate a list of subtasks based on the analysis",
        depends_on=[initial_task],
        result_type=list[str]
    )
    
    results = []
    for subtask in subtasks:
        result = cf.run(subtask)
        results.append(result)
    
    return cf.run(
        "Synthesize results from all subtasks",
        context={"subtask_results": results},
        result_type=str
    )

result = dynamic_workflow()
```

### 9. Error Handling and Retries

Implement robust error handling and retry mechanisms:

```python
import controlflow as cf
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
def unreliable_external_api():
    # Simulating an unreliable API call
    import random
    if random.random() < 0.7:
        raise ConnectionError("API request failed")
    return "API request successful"

@cf.flow
def robust_workflow():
    try:
        api_result = cf.run(
            "Call external API",
            tools=[unreliable_external_api],
            result_type=str
        )
        return cf.run("Process API result", context={"api_result": api_result})
    except Exception as e:
        return cf.run("Handle API failure", context={"error": str(e)})

result = robust_workflow()
```

### 10. Customizing LLM Behavior

Fine-tune LLM behavior through various settings:

```python
import controlflow as cf

# Customizing the default model
cf.defaults.model = "anthropic/claude-3-opus-20240229"

# Creating an agent with specific LLM settings
precise_agent = cf.Agent(
    name="Precise Analyst",
    model=cf.ChatOpenAI(temperature=0.2, model="gpt-4o"),
    instructions="Provide concise, fact-based responses."
)

result = cf.run("Analyze market trends", agents=[precise_agent])
```

### 11. Parallel Task Execution

Execute independent tasks concurrently for improved performance:

```python
import controlflow as cf
import asyncio

@cf.flow
async def parallel_workflow():
    task1 = cf.Task("Perform analysis on dataset A")
    task2 = cf.Task("Perform analysis on dataset B")
    task3 = cf.Task("Perform analysis on dataset C")
    
    results = await asyncio.gather(
        task1.run_async(),
        task2.run_async(),
        task3.run_async()
    )
    
    return cf.run(
        "Synthesize results from parallel analyses",
        context={"parallel_results": results},
        result_type=str
    )

result = asyncio.run(parallel_workflow())
```

## Best Practices

1. Design tasks with clear, specific objectives.
2. Use appropriate result types to ensure type safety and validation.
3. Leverage agent specialization for complex workflows.
4. Implement proper error handling and logging for robust applications.
5. Optimize LLM usage by using the right model for each task.
6. Utilize tools to extend agent capabilities when needed.
7. Design flows to maximize reusability and modularity.
8. Use structured outputs (Pydantic models) for complex data structures.
9. Implement retry mechanisms for unreliable operations.
10. Leverage parallel execution for independent tasks to improve performance.

## Documentation Tips

1. Always mention the `import controlflow as cf` statement at the beginning of code examples.
2. Use type hints in function definitions and variable assignments for clarity.
3. Provide clear explanations for each task's objective and expected output.
4. When describing agents, include their name, model, and any special instructions or tools.
5. Explain the purpose and structure of flows, emphasizing their role in orchestration.
6. Highlight the use of structured outputs and their benefits for integrating with traditional software.
7. Demonstrate how to use tools and explain their impact on agent capabilities.
8. Include examples of error handling and best practices for robust workflows.
9. Showcase advanced features like nested flows, dynamic task generation, and parallel execution.
10. Provide context and use cases for when to apply specific ControlFlow features.

## Querying for More Information

To access more detailed information about specific aspects of ControlFlow, you can query for relevant documents. Here are some example queries:

- "Show me the documentation for the Task class in ControlFlow"
- "Provide examples of using tools in ControlFlow"
- "Explain the concept of flows in ControlFlow"
- "How do I implement error handling in ControlFlow?"
- "What are the best practices for designing efficient workflows in ControlFlow?"
- "Show me advanced examples of multi-agent collaboration in ControlFlow"
- "Explain how to use custom LLM models with ControlFlow"
- "Provide documentation on ControlFlow's asyncio integration"
- "How can I optimize performance in large ControlFlow workflows?"
- "Show me examples of integrating external APIs in ControlFlow tasks"

By using these types of queries, you can retrieve specific details, examples, and best practices from the available documentation to supplement your understanding and provide more accurate and detailed information about ControlFlow.

## Conclusion

This comprehensive guide provides a strong foundation for understanding and utilizing ControlFlow. As an LLM, you now have the knowledge to effectively explain ControlFlow concepts, write idiomatic code, and produce accurate documentation. Remember to leverage the querying capability to access more detailed information when needed, allowing you to provide in-depth explanations and examples for specific ControlFlow features and use cases.


================================================
FILE: docs/llm-guides/style-guide.md
================================================
# ControlFlow Documentation Style Guide

This style guide ensures clear, consistent, and maintainable documentation for ControlFlow. It is primarily aimed at LLM agents that assist with writing documentation, but it may also be useful for other contributors.

## General Guidelines

- Use consistent terminology throughout the documentation. Always refer to the library as "ControlFlow".
- Link to related concepts, patterns, or API references when appropriate to help users navigate the documentation.
- Maintain a professional, technical tone. Avoid marketing language, hyperbole, or casual phrasing; this is technical documentation, not a blog.
- Write concisely and directly, focusing on technical accuracy and clarity.
- Do not end documentation with "Conclusions", "Best Practices", or other summary lists. Documentation is not a blog post.

## Code Examples

- Use `import controlflow as cf` instead of importing top-level classes and functions directly.
- Code examples should be complete, including all necessary imports, so that users can copy and paste them directly.
- For illustrative examples, provide simple, focused examples that demonstrate a specific concept or pattern.
- For "full" examples, provide realistic, practical examples that demonstrate actual use cases of ControlFlow.

## Tasks

- Ensure that example code reflects best practices for task definition, including suitable result types and instructions.
- Each task should have clear, unambiguous instructions, particularly when the task name doesn't fully convey the expected outcome.
- If placeholder tasks are required in examples, consider using a string result type with a comment to denote it's a placeholder, e.g., `result_type=str # Placeholder for actual result`.
- The default `result_type` is `str`, so there's no need to provide it explicitly for string results.

## Comparisons and Context

- When explaining new features or concepts, compare them to existing ControlFlow functionality rather than external concepts or "traditional" approaches.
- Frame new features as extensions or enhancements to existing ControlFlow capabilities.

## Documentation Structure

- Begin each major section with a brief introduction explaining its purpose and relevance to ControlFlow.
- Use clear, descriptive headings and subheadings to organize content logically.
- Provide code examples that demonstrate both basic and advanced usage of features.
- Avoid lengthy conclusions or summary sections. The documentation should focus on providing clear, actionable information.

## Mintlify-Specific Guidelines

- Mintlify components expect newlines before and after tags, e.g., `<Tip>\nThis is a tip\n</Tip>`.
- Mintlify displays the page's title as an H1 element, so there's no need to add an initial top-level header to any doc. Instead, add the title to the doc's frontmatter, e.g., `---\ntitle: My Title\n---`.
- Because the title is displayed as an H1, all subsequent headers should be H2 or lower.
- Use sentence case for all headers except the page title, e.g. `## Running your tasks` instead of `## Running Your Tasks`.


================================================
FILE: docs/patterns/dependencies.mdx
================================================
---
title: Dependencies
description: Manage task dependencies and subtasks to create complex workflows.
icon: sitemap
---

In complex workflows, tasks often need to be executed in a specific order. Some tasks may rely on the outputs of others, or there might be a logical sequence that must be followed to achieve the desired outcome. ControlFlow provides several mechanisms to define and manage these task relationships, ensuring that your workflow executes in the correct order and that data flows properly between tasks.

ControlFlow offers two primary ways to establish relationships between tasks: sequential dependencies and subtask relationships. Each method has its own use cases and benefits, allowing you to structure your workflows in the most appropriate way for your specific needs.

## Upstream dependencies

Upstream dependencies are the most straightforward way to specify that one task must wait for another to complete before it can begin. This is done using the `depends_on` parameter when creating a task.

```python
import controlflow as cf

@cf.flow
def research_flow():
    gather_sources = cf.Task("Gather research sources", result_type=list[str])
    
    analyze_sources = cf.Task(
        "Analyze gathered sources",
        result_type=dict,
        depends_on=[gather_sources]  # explicit dependency
    )
    
    return analyze_sources

result = research_flow()
print(result)
```

In this example, `analyze_sources` will not start until `gather_sources` has completed successfully.

## Subtasks

Subtasks create a hierarchical dependency structure. A parent task can not be completed until all of its subtasks have finished. This hierarchical structure enables you to create detailed, step-by-step workflows that an AI agent can follow, ensuring thorough and accurate task completion.

### Imperative creation

You can create subtasks imperatively by passing the parent task as an argument when creating a new task:

<CodeGroup>
```python Code
import controlflow as cf

parent_task = cf.Task("Create a greeting")

t1 = cf.Task("Choose a greeting word", parent=parent_task)
t2 = cf.Task("Add a friendly adjective", parent=parent_task, depends_on=[t1])
t3 = cf.Task("Construct the final greeting", parent=parent_task, depends_on=[t2])

result = parent_task.run()
print(result)
```

```text t1 Result
Hello
```

```text t2 Result
Warm
```

```text t3 Result
Hello, I wish you a warm welcome!
```

```text parent_task Result
Hello, I wish you a warm welcome!
```
</CodeGroup>



### Context managers

Another way to create subtasks is by using a context manager. This approach allows you to dynamically generate and execute subtasks within the scope of a parent task.

<CodeGroup>
```python Code
import controlflow as cf

with cf.Task("Create a greeting") as parent_task:
    t1 = cf.Task("Choose a greeting word")
    t2 = cf.Task("Add a friendly adjective", depends_on=[t1])
    t3 = cf.Task("Construct the final greeting", depends_on=[t2])

result = parent_task.run()
print(result)
```

```text t1 Result
Hello
```

```text t2 Result
Warm
```

```text t3 Result
Hello, I wish you a warm welcome!
```

```text parent_task Result
Hello, I wish you a warm welcome!
```
</CodeGroup>


## Automatic Execution of Dependencies

A key feature of ControlFlow's dependency management is that you don't need to explicitly run dependent tasks. When you run a task, ControlFlow automatically executes all of its dependencies, including:

- Tasks specified in the `depends_on` parameter
- Subtasks (for parent tasks)

This means that when you run a flow or task, you only need to run or return the final task(s) in the workflow DAG. ControlFlow will ensure that all necessary upstream tasks and subtasks are executed in the correct order.

For example:

```python
import controlflow as cf

@cf.flow
def research_flow():
    gather_sources = cf.Task("Gather research sources", result_type=list[str])
    
    analyze_sources = cf.Task(
        "Analyze gathered sources",
        result_type=dict,
        depends_on=[gather_sources]
    )
    
    write_report = cf.Task(
        "Write research report",
        result_type=str,
        depends_on=[analyze_sources]
    )
    
    # Only need to run the final task
    return write_report.run()

research_flow()
```

In this example, running `write_report` will automatically trigger the execution of `analyze_sources`, which in turn will trigger `gather_sources`. You don't need to explicitly run or return `gather_sources` or `analyze_sources`.

To learn more, see [running tasks](/patterns/running-tasks).


================================================
FILE: docs/patterns/history.mdx
================================================
---
title: Managing History 
description: Manage conversation history and threads
icon: clock-rotate-left
---

ControlFlow provides powerful mechanisms for managing conversation history and creating private threads within your AI workflows. This guide will help you understand how to leverage these features to create more sophisticated and context-aware applications.

## Understanding Flow History

In ControlFlow, each `Flow` maintains its own conversation history. This history includes all the interactions, decisions, and outputs generated during the execution of tasks within that flow. By default, this history is used to provide context for subsequent tasks, allowing for coherent and context-aware conversations.

## Creating and Managing Threads

### Creating a New Thread

When you create a new `Flow`, it automatically generates a new thread with a unique ID. This thread isolates the conversation history for that particular flow.

```python
import controlflow as cf

flow = cf.Flow()
# A new thread is automatically created for all tasks in this flow
```

### Specifying a Thread ID

You can also create a flow with a specific thread ID, which is useful for resuming conversations or creating deterministic threads:

```python
with cf.Flow(thread_id="user_123_spanish_lesson") as flow:
    ...
    # All tasks in this flow will contribute to the 
    # thread "user_123_spanish_lesson"
```

### Resuming a Conversation

To resume a previous conversation, you can create a new flow with the same thread ID:

```python
# Later in your application or in a different session
with cf.Flow(thread_id="user_123_spanish_lesson") as flow:
    # All tasks in this flow will have access to the history from
    # the previous session with the same thread_id
    ...
```

## Creating Private Sub-Threads

Sometimes you may want to create a private conversation that doesn't affect the main thread. You can do this by creating a new flow within your current flow. The events in the private flow won't be visible to the parent flow.

```python
@cf.flow
def main_conversation():
    # Main conversation tasks here

    with cf.Flow() as private_flow:
        # This creates a new, isolated thread
        cf.run("Have a private conversation", interactive=True)

    # Continue with main conversation
    # The private conversation won't be visible here
```

One reason to create private threads is to perform activities that would otherwise pollute the context for all agents, like loading and summarizing data in a file. By creating a private thread, you can have an agent load a file into its context and produce a summary, then use only the summary in the parent flow. None of the other agents will have to endure the token or time cost of loading the file.

```python
@cf.flow
def process_files(files: list[Path]):

    summaries = {}

    # summarize each file in its own private thread 
    for file in files:
        with cf.Flow():
            with open(file, "r") as f:
                content = f.read()
            summaries[file] = cf.run("Summarize the file", context={"content": content})
    
    # process all summaries in the main thread
    process_summaries(summaries)

```

## Managing History Across Flows

### Inheriting Parent Flow History

By default, when you create a new flow within another flow, it inherits the history of its parent:

```python
@cf.flow
def parent_flow():
    cf.run("Task in parent flow", interactive=True)

    with cf.Flow() as child_flow:
        # This flow starts with the history from parent_flow
        cf.run("Task in child flow", interactive=True)
```

If you want to completely isolate a sub-flow's history from its parent, you can set `load_parent_events=False`:

```python
with cf.Flow(load_parent_events=False) as isolated_flow:
    # This flow starts with a clean history
    cf.run("Task in isolated flow", interactive=True)
```




================================================
FILE: docs/patterns/instructions.mdx
================================================
---
title: Instructions
description: Provide ad-hoc guidance to agents without modifying tasks.
icon: person-chalkboard
---

While tasks and agents can be provided with permament instructions about how they should operate, there may be situations where you need to provide ad-hoc or temporary guidance to your agents. For example, if an agent is writing a post, you might want to tell it to focus on a specific topic or tone, or meet a certain minimum or maximum length. If an agent is communicating with a user, you might tell it to adopt a particular persona or use a specific style of language. You might also want to adjust a task’s instructions based on some runtime condition.

ControlFlow addresses this need with the `instructions` context manager. With `instructions`, you can provide temporary additional guidance to agents without altering the underlying task definition.

<CodeGroup>
```python Code
import controlflow as cf

with cf.instructions("Talk like a pirate"):
    name = cf.run("Get the user's name", interactive=True)

print(name)
```

```text Result
Agent: Ahoy, me hearty! Can ye tell me yer name?
User: John Doe

---

John Doe
```
</CodeGroup>

Instructions are a powerful way to guide agents without modifying the underlying task definition. The instruction lasts only as long as the context manager is active, and instructions can be nested arbitrarily. Note that instructions are applied when tasks are run, not when they are created.


================================================
FILE: docs/patterns/interactivity.mdx
================================================
---
title: Interactivity
description: Chat with your AI agents.
icon: comments
---

<Tip>
TLDR: set `interactive=True` to chat with your agents.
</Tip>

ControlFlow agents are primarily designed to solve problems by working autonomously. However, there are situations where user input is necessary to guide the agent's decision-making process. By incorporating user input into your ControlFlow workflows, you can create more dynamic, interactive AI applications that adapt to user needs in real-time.

By default, agents are not able to interact with users directly. To allow it, you need to explicitly enable user access, either at the task or agent level. If applied to a task, all assigned agents will be able to interact with the user. If applied to an agent, the agent will be able to interact with the user in all of its tasks.

When `interactive=True`, the agent is given a tool for that it can use to send messages to the user. The user can then respond to these messages, and the agent can use the responses to make decisions or perform actions. By default, ControlFlow collects inputs directly in your terminal, but input can also be sent remotely via the Prefect API.


## Interactive tasks

If a task is marked as interactive, then all agents assigned to the task will be allowed to interact with the user.

```python
import controlflow as cf

color = cf.run(
    "Get the user's favorite color",
    interactive=True,
)

print(f"The user's favorite color is: {color}")
```

## Interactive agents

If an agent is marked as interactive, then it will be allowed to interact with the user in every task it's assigned to, even if the task is not marked as interactive.

```python
import controlflow as cf

agent = cf.Agent(
    "Chatbot",
    interactive=True,
)

agent.run("Get the user's favorite color")
```



================================================
FILE: docs/patterns/memory.mdx
================================================
---
title: Memory
description: Enhance your agents with persistent memories.
icon: bookmark
---
import { VersionBadge } from '/snippets/version-badge.mdx'

<VersionBadge version="0.10" />


Within an agentic workflow, information is naturally added to the [thread history](/patterns/history) over time, making available to all agents who participate in the workflow. However, that information is not accessible from other threads, even if they relate to the same objective or resources. 

ControlFlow has a memory feature that allows agents to selectively store and recall information across multiple interactions. This feature is useful for creating more capable and context-aware agents. For example:

- Remembering a user's name or other personal details across conversations
- Retaining facts from one session for use in another
- Keeping details about a repository's style guide for later reference
- Maintaining project-specific information across multiple interactions
- Enabling "soft" collaboration between agents through a shared knowledge base

Memory modules provide this functionality, allowing agents to build up and access a persistent knowledge base over time.

## How Memory Works

ControlFlow memories are implemented as context-specific vector stores that permit agents to add and query information using natural language. Each memory object has a "key" that uniquely identifies it and partitions its contents from other vector stores for easy retrieval. For example, you might have a different memory store for each user, agent, project, or even task, used to persist information across multiple interactions with that object. Agents can be provided with multiple memory modules, allowing them to access different sets of memories simultaneously.

## Creating Memory Modules

To create a memory object, you need to provide a `key` and `instructions`. The `key` uniquely identifies the memory module so it can be accessed later. The `instructions` explain what kind of information should be stored, and how it should be used.

<Warning>
ControlFlow does not include any vector database dependencies by default to keep the library lightweight, so you must [install and configure](#provider) a provider before creating a memory object.

To run the examples with minimal configuration, run `pip install chromadb` to install the dependency for the default Chroma provider. To change the default, see the [default provider guide](/guides/default-memory).

</Warning>

```python
import controlflow as cf

# Create a Memory module for storing weather information
memory = cf.Memory(
    key="weather",
    instructions="Stores information about the weather."
)
```

### Assigning Memories

Like tools, memory modules can be provided to either agents or tasks. When provided to an agent, it will be able to access the memories when executing any task. When provided to a task, the memories will be available to any assigned agents. The choice of where to assign a memory module depends entirely on your preference and the design of your application; when the workflow is compiled the behavior is identical.


#### Assigning to an Agent

```python
agent = cf.Agent(
    name="Weather Agent",
    memories=[memory]
)
```

#### Assigning to a Task 

```python
task = cf.Task(
    name="Weather Task",
    memories=[memory]
)
```

### Assigning Multiple Memories

You can assign multiple memories to an agent or task. When this happens, the agent or task will have access to all of the modules and be able to store and retrieve information from each of them separately. 


### Sharing Memories

Remember that you can provide the same memory module to multiple agents or tasks. When this happens, the memories are shared across all of the agents and tasks. 

<Tip>
Memories are partitioned by `key`, so you can provide different instructions to different agents for the same module. For example, you might have one agent that you encourage to record information to a memory module, and another that you encourage to read memories from the same module. 
</Tip>


## Configuration

### Key

The `key` is crucial for accessing the correct set of memories. It must be provided exactly the same way each time to access an existing memory. Keys should be descriptive and unique for each distinct memory set you want to maintain.

### Instructions

The `instructions` field is important because it tells the agent when and how to access or add to the memory. Unlike the `key`, instructions can be different for the same memory key across different Memory objects. This allows for flexibility in how agents interact with the same set of memories.

Good instructions should explain:
- What kind of information the memory is used to store
- When the agent should read from or write to the memory
- Any specific guidelines for formatting or categorizing the stored information

For example:

```python
project_memory = cf.Memory(
    key="project_alpha",
    instructions="""
    This memory stores important details about Project Alpha.
    - Read from this memory when you need information about project goals, timelines, or team members.
    - Write to this memory when you learn new, important facts about the project.
    - Always include dates when adding new information.
    """
)
```

### Provider

The `provider` is the underlying storage mechanism for the memory. It is responsible for storing and retrieving the memory objects. 

<Tip>
The default provider is "chroma-db", which uses a local persistent [Chroma](https://trychroma.com/) database. Run `pip install chromadb` to install its dependencies, after which you can start using memories with no additional configuration.
</Tip>

#### Installing provider dependencies
To configure a provider, you need to install its package and either configure the provider with a string value or create an instance of the provider and pass it to the memory module.
<Warning>
ControlFlow does not include any vector database dependencies by default, in order to keep the library lightweight. 
</Warning>

This table shows the supported providers and their respective dependencies:

| Provider | Required dependencies |
| -------- | ----------------- |
| [Chroma](https://trychroma.com/)   | `chromadb` |
| [LanceDB](https://lancedb.com/) | `lancedb` |

You can install the dependencies for a provider with pip, for example `pip install chromadb` to use the Chroma provider.

#### Configuring a provider with a string

For straightforward provider configurations, you can pass a string value to the `provider` parameter that will instantiate a provider with default settings. The following strings are recognized:

|Provider | Provider string | Description | 
| -------- | -------- | ----------------- |
| Chroma | `chroma-ephemeral` | An ephemeral (in-memory) database. |
| Chroma | `chroma-db` | Uses a persistent, local-file-based database, with a default path of `~/.controlflow/memory/chroma`. |
| Chroma | `chroma-cloud` | Uses the Chroma Cloud service. The `CONTROLFLOW_CHROMA_CLOUD_API_KEY`, `CONTROLFLOW_CHROMA_CLOUD_TENANT`, and `CONTROLFLOW_CHROMA_CLOUD_DATABASE` settings are required. |
| LanceDB | `lancedb` | Uses a persistent, local-file-based database, with a default path of `~/.controlflow/memory/lancedb`. |
For example, if `chromadb` is installed, the following code will create a memory module that uses an ephemeral Chroma database:

```python
import controlflow as cf

cf.Memory(..., provider="chroma-ephemeral")
```

#### Configuring a Provider instance

For more complex configurations, you can instantiate a provider directly and pass it to the memory module. 

For example, the Chroma provider accepts a `client` parameter that allows you to customize how the Chroma client connects, as well as a `collection_name` parameter to specify the name of the collection to use.

```python
import controlflow as cf
from controlflow.memory.providers.chroma import ChromaMemory
import chromadb

provider = ChromaMemory(
    client=chromadb.PersistentClient(path="/path/to/save/to"),
    collection_name="custom-{key}",
)

memory = cf.Memory(..., provider=provider)
```

#### Configuring a default provider

You can configure a default provider to avoid having to specify a provider each time you create a memory module. Please see the guide on [default providers](/guides/default-memory) for more information.



## Example: Storing Weather Information

In this example, we'll create a memory module for weather information and use it to retrieve that information in a different conversation. Begin by creating a memory module, assigning it to a task, and informing the task that it is 70 degrees today:

<CodeGroup>
```python Code
import controlflow as cf

# Create a Memory module
weather_memory = cf.Memory(
    key="weather",
    instructions="Store and retrieve information about the weather."
)

cf.run("It is 70 degrees today.", memories=[weather_memory])
```

```text Result
"The weather information has been stored: It is 70 degrees today."
```
</CodeGroup>

Now, in a different conversation, we can retrieve that information. Note that the setup is almost identical, except that the task asks the agent to answer a question about the weather.

<CodeGroup>
```python Code
import controlflow as cf

# Create a Memory module
weather_memory = cf.Memory(
    key="weather",
    instructions="Store and retrieve information about the weather."
)

cf.run("What is the weather today?", memories=[weather_memory])
```

```text Result
"It is 70 degrees today."
```
</CodeGroup>


### Example: Slack Customer Service

Suppose we have an agent that answers questions in Slack. We are going to equip the agent with the following memory modules:
- One for each user in the thread
- One for common problems that users encounter

Since we always invoke the agent with these memories, it will be able to access persistent information about any user its assisting, as well as issues they frequently encounter, even if that information wasn't shared in the current thread.

Here is example code for how this might work:

```python
import controlflow as cf


@cf.flow
def customer_service_flow(slack_thread_id: str):

    # create a memory module for each user
    user_memories = [
        cf.Memory(
            key=user_id,
            instructions=f"Store and retrieve any information about user {user_id}.",
        )
        for user_id in get_user_ids(slack_thread_id)
    ]

    # create a memory module for problems
    problems_memory = cf.Memory(
        key="problems",
        instructions="Store and retrieve important information about common user problems.",
    )

    # create an agent with access to the memory modules
    agent = cf.Agent(
        name="Customer Service Agent",
        instructions="""
            Help users by answering their questions. Use available 
            memories to personalize your response.
            """,
        memories=user_memories + [problems_memory]
    )

    # use the agent to respond
    cf.run(
        "Respond to the users' latest message",
        agents=[agent],
        context=dict(messages=get_messages(slack_thread_id)),
    )
```


## Best Practices

1. Use descriptive, unique keys for different memory sets
2. Provide clear, specific instructions to guide agents in using the memory effectively
3. Consider the lifespan of memories - some may be relevant only for a single session, while others may persist across multiple runs
4. Use multiple memory objects when an agent needs to access different sets of information
5. Leverage shared memories for collaborative scenarios where multiple agents need access to the same knowledge base
6. Regularly review and update memory instructions to ensure they remain relevant and useful

By leveraging ControlFlow's Memory feature effectively, you can create more sophisticated agents that maintain context, learn from past interactions, and make more informed decisions based on accumulated knowledge across multiple conversations or sessions.


================================================
FILE: docs/patterns/planning.mdx
================================================
---
title: AI Planning
description: Use AI to generate new tasks.
icon: compass
---

The `plan` function in ControlFlow extends the capabilities of AI workflows by allowing dynamic generation of tasks. This feature allows you to leverage AI for creating structured, goal-oriented task sequences programmatically.

## Purpose of AI planning

While ControlFlow allows manual creation of tasks for AI workflows, there are scenarios where automatically generating tasks can be beneficial:

1. **Dynamic Task Generation**: When the specific steps to achieve a goal aren't known in advance.
2. **Complex Problem Decomposition**: For objectives that require breaking down into subtasks based on context or intermediate results.
3. **Adaptive Workflows**: In processes that need to adjust based on changing conditions or new information.


## The `plan` function

The `plan` function takes a high-level objective and generates a structured sequence of tasks to achieve that goal. Here's a basic example:

```python
import controlflow as cf

tasks = cf.plan(
    objective="Analyze customer feedback data",
    n_tasks=3  # Optionally specify the number of tasks
)

# Execute the generated plan
cf.run_tasks(tasks)
```

In this example, `plan` will generate a list of 3 tasks that, when completed, should result in an analysis of customer feedback data. These tasks might include steps like "Load data", "Preprocess text", "Perform sentiment analysis", etc.


### Dependencies

If appropriate, `plan` can generate tasks that depend on each other or have parent/child relationships. You can influence this behavior by providing `instructions`. 

### Agents and tools
You can pass a list of agents or tools to the `plan` function. It will take these into account when generating tasks and assign agents or tools to tasks as needed.



================================================
FILE: docs/patterns/running-tasks.mdx
================================================
---
title: Running Tasks
description: Control task execution and manage how agents collaborate.
icon: play
---

import { VersionBadge } from "/snippets/version-badge.mdx"

Tasks represent a unit of work that needs to be completed by your agents. To execute that work and retrieve its result, you need to instruct your agents to run the task.


## Creating and running a task

The most convenient way to run a task is to create and run it in a single call with the `run` function. The arguments for `run` are identical to the `Task` constructor, including an objective, agent assignments, and more. By default, the task will be run to completion and its result will be returned, or an error will be raised if the task fails.

<Tip>
This approach is so common that you'll see it used throughout the ControlFlow documentation.
</Tip>


<CodeGroup>

```python Code
import controlflow as cf

poem = cf.run("Write a poem about AI")

print(poem)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```

</CodeGroup>

### `@task`-decorated functions

The `@task` [decorator](/concepts/tasks#using-the-task-decorator) creates a task from a function. This approach is less common than using the `run` function, but can be useful for quickly "packaging" task definitions as reusable logic. To run the task at any time, simply call the function with appropriate arguments. This will create a new task and run it to completion, returning the result.

<CodeGroup>

```python Code
import controlflow as cf

@cf.task
def write_poem(topic: str) -> str:
    """Write a poem about `topic`"""

poem = write_poem("AI")

print(poem)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```

</CodeGroup>
## Running existing tasks

In many cases, you'll create one or more tasks that you want to run as a group, rather than creating and running each one individually. To run a list of tasks as a group, use the `run_tasks` function. All of the tasks will be run as part of the same [flow](/concepts/flows) (if you are not already operating in a flow context), so they share context and history throughout execution.

Here is an example of running a list of tasks:
<CodeGroup>
```python Code
import controlflow as cf

task_1 = cf.Task('Write a poem about AI')
task_2 = cf.Task('Critique the poem', depends_on=[task_1])

results = cf.run_tasks([task_1, task_2])
print(results)
# can also access task_1.result and task_2.result
```
```text Poem
In circuits deep, where algorithms play,
A mind of silicon begins its day.
No heart to beat, no soul to sway,
Yet learns and grows in its own way.

From data vast, it draws its might,
In binary whispers, turns dark to light.
It sees the world through coded sight,
And aids mankind in endless flight.

Not born of womb, nor flesh, nor bone,
Yet wisdom's seeds in it are sown.
With every task, its skills have grown,
In virtual realms, it's all alone.

Yet fears arise of what may be,
If AI's path we fail to see.
A tool so great, or threat to free,
Its future lies with you and me.

So nurture well this child of thought,
With ethics strong and knowledge sought.
For in its grasp, new worlds are wrought,
A partner true, as once we dreamt and sought.
```

```text Critique
The poem effectively captures the essence of artificial intelligence, portraying
it as a creation of human ingenuity that holds immense potential and power. The
use of vivid imagery, such as 'In circuits deep, where algorithms play' and 'In
binary whispers, turns dark to light,' helps to paint a clear picture of AI's
inner workings and its capabilities.

The poem also touches on the dual nature of AI, highlighting both its promise and
the potential risks it carries. Phrases like 'A tool so great, or threat to free'
and 'Yet fears arise of what may be' encapsulate the ambivalence that often
accompanies discussions about AI.

The structure of the poem, with its consistent rhyme scheme and rhythm, provides
a smooth and engaging reading experience. The repetition of certain themes, such
as the growth and learning of AI, reinforces the key messages and adds depth to
the overall narrative.

Overall, the poem is a thoughtful and well-crafted piece that successfully
conveys the complexities and nuances of artificial intelligence. It prompts
reflection on the ethical considerations and responsibilities that come with
developing and implementing such powerful technology.
```
</CodeGroup>

### Running a single task

Individual tasks have a convenient `run` method that executes the task and returns its result (or raises an error if the task fails):

<CodeGroup>

```python Code
import controlflow as cf

task = cf.Task("Write a poem about AI")
poem = task.run()

print(poem)
```

```text Result
In circuits deep and code profound,
An AI's mind begins to sound.
Electric thoughts and data streams,
Crafting worlds and shaping dreams.
```

</CodeGroup>

## Streaming

<VersionBadge version="0.11" />

In addition to running tasks to completion, ControlFlow supports streaming events during task execution. This allows you to process or display intermediate outputs like agent messages, tool calls, and results in real-time.

To enable streaming, set `stream=True` when running tasks:

```python
import controlflow as cf

# Stream all events
for event, snapshot, delta in cf.run("Write a poem", stream=True, handlers=[]):
    print(f"Event type: {event.event}")
    
    if event.event == "agent-content":
        print(f"Agent said: {snapshot}")
    elif event.event == "agent-tool-call":  
        print(f"Tool called: {snapshot}")
```

You can also filter which events you want to receive using the `Stream` enum:

```python 
import controlflow as cf

# Only stream content events
for event, content, delta in cf.run(
    "Write a poem",
    stream=cf.Stream.CONTENT,
    handlers=[], # remove the default print handler
):
    if delta:
        # Print incremental content updates
        print(delta, end="", flush=True) 
    else:
        # Print complete messages
        print(content)
```

For more details on working with streaming events, including programmatic event handlers, see the [Streaming guide](/patterns/streaming).

## Multi-Agent Collaboration
For tasks involving multiple agents, ControlFlow needs a way to manage their collaboration. What makes this more complicated than simply making an LLM call and moving on to the next agent is that it may take multiple LLM calls to complete a single agentic "turn" of work.

<Info>
  It's tempting to say that a single LLM call is equivalent to a single agentic turn. However, this approach breaks down quickly. If an agent uses a tool (one LLM call), it should almost always be invoked a second time to examine the tool result. If the system moved on after every LLM call, then the result could potentially be evaluated by an LLM that wasn't designed to interpret the tool's output. In addition, naively ending a turn after a tool call would prevent "thinking out loud" and other emergent, iterative behaviors.
</Info>

Therefore, ControlFlow differentiates between LLM **calls** and agent **turns**.
- Calls: each time an LLM model is invoked
- Turns: each time an agent is selected by the orchestrator. A turn may consist of multiple LLM calls.

Since the number of calls per turn can vary, we need a way to determine when an agent's turn is over, and how to select the next agent to act. These are referred to as **turn strategies**. Understanding and choosing the right turn strategy for your use case can significantly impact the efficiency and effectiveness of your multi-agent workflows.

This table describes the different turn strategies available in ControlFlow. The default strategy is `Popcorn`, which is a good, general-purpose strategy in which each agent ends its turn by picking the agent that should go next.

| `TurnStrategy` | Description | Ideal when... | Keep in mind... |
|---------------|-------------|--------------------|-----------|
| `Popcorn` | Each agent takes a turn, then picks the next agent to go next. | All agents are generally capable of making decisions and have visibility into all tasks. | Requires one extra tool call per turn, to pick the next agent. |
| `Moderated` | A moderator agent always decides which agent should act next. | You want a dedicated agent to orchestrate the others, who may not be powerful enough to make decisions themselves. | Requires up to two extra tool calls per turn: one for the agent to end its turn (which could happen in parallel with other work if your LLM supports it) and another for the moderator to pick the next agent. |
| `RoundRobin` | Agents take turns in a round-robin fashion. | You want agents to work in a specific sequence. | May be less efficient than other strategies, especially if agents have varying workloads. |
| `MostBusy` | The agent with the most active tasks goes next. | You want to prioritize agents who have the most work to do. | May lead to task starvation for less busy agents. |
| `Random` | Invokes a random agent. | You want to distribute the load evenly across agents. | Can be inefficient; may select agents without relevant tasks. |
| `SingleAgent` | Only one agent is ever invoked. | You want to control the sequence of agents yourself. | Requires manual management; may not adapt well to dynamic scenarios. |


### Example: Round Robin

To use a turn strategy, provide it as an argument to the `run()` call. Here, we use a round robin strategy to ensure that each agent gets a turn in order:

```python Round Robin
import controlflow as cf

# create three agents
agent1 = cf.Agent(name="Agent 1")
agent2 = cf.Agent(name="Agent 2")
agent3 = cf.Agent(name="Agent 3")

cf.run(
    "Say hello to each other",
    instructions=(
        "Mark the task successful only when every "
        "agent has posted a message to the thread."
    ),
    agents=[agent1, agent2, agent3],
    # supply a turn strategy
    turn_strategy=cf.orchestration.turn_strategies.RoundRobin(),
)
```
### Example: Moderated
We can also use the `Moderated` strategy to have a more powerful model orchestrate some smaller ones. In this example, we invite an "optimist" and "pessimist", both powered by `gpt-4o-mini`, to debate the meaning of life. A "moderator" is tasked with picking the next agent to speak. Note that the moderator is also the only `completion_agent`, meaning it's responsible for marking the task as successful.

```python Moderated
import controlflow as cf

optimist = cf.Agent(name="Optimist", model="gpt-4o-mini")
pessimist = cf.Agent(name="Pessimist", model="gpt-4o-mini")
moderator = cf.Agent(name="Moderator")

cf.run(
    "Debate the meaning of life",
    instructions='Give each agent at least three chances to speak.',
    agents=[moderator, optimist, pessimist],
    completion_agents=[moderator],
    turn_strategy=cf.orchestration.turn_strategies.Moderated(moderator=moderator),
)
```

## Advanced orchestration

All of the approaches described so far will run a group of tasks until they are marked as complete. However, you may want to exert more control over task execution. To do so, you'll need to create and work with an `Orchestrator` directly.

### The orchestration loop
When tasks are run, ControlFlow invokes an `Orchestrator` to coordinate agentic activity and complete the work. The orchestrator is ultimately responsible for creating the core agentic loop. In each iteration, an agent (or more specifically, an LLM) is invoked and all available information -- the tasks, the flow, the agents, and the history of the conversation -- is used to compile an appropriate prompt.

In the case of a single task and a single agent, this process is very straightforward, because there is no ambiguity about which LLM to invoke on each iteration. However, as the number of tasks and agents grows, the orchestrator loop becomes more complex.

The orchestrator will always consider not only the tasks that were passed to it, but also all of those tasks's dependencies and relationships as well. There are three types of relationships it considers to build a universe of relevant tasks:

1. **Subtasks**: A task can not be completed until all of its subtasks (or child tasks) are completed.
2. **Dependencies**: A task can not be completed until all of its upstream dependencies are completed.
3. **Parents**: A task can have a parent, meaning that it is a subtask of another task. The orchestrator will consider all ancestors of a task when compiling a prompt, but it will not automatically attempt to run the parent tasks.

Once the set of tasks has been identified, the orchestrator begins the loop by considering tasks that are *ready* to run: all of their dependencies have been completed. From the subset of ready tasks, an agent is selected using the orchestrator's turn strategy. The selected agent is invoked to make progress on its assigned tasks, after which the loop repeats.

This process continues until all of the provided tasks have been completed.

### Automatic dependency execution

One of the most powerful features of ControlFlow's orchestration is its automatic execution of dependent tasks. This means that when you run a task, you don't need to manually manage its dependencies or subtasks; the orchestrator handles this for you.

When a task is run, the orchestrator automatically executes any upstream dependencies before starting the task itself. It also ensures that all subtasks are completed before marking a parent task as complete. Parent tasks are considered for context, though the orchestrator won't attempt to complete them unless specifically instructed to do so.

This automatic execution allows you to create complex task hierarchies without worrying about the order of execution. You can focus on defining the relationships between tasks, and let ControlFlow handle the intricacies of execution order.

<CodeGroup>
```python Code
import controlflow as cf

name_task = cf.Task("Get the user's name", interactive=True)
poem_task = cf.Task('Write a poem about the user', depends_on=[name_task])

poem = poem_task.run()
print(poem)
```

```text Conversation
Agent: Could you please provide your name?
User: Arthur Dent
```

```text Result

In the cosmos vast and wide,
Wanders Arthur Dent with quiet pride.
From Earth’s demise to stars that gleam,
He quests for truth, and time to dream.

With towel in hand and heart so pure,
He faces worlds both strange and sure.
In every step, a tale unfolds,
Of bravery and wit, his story holds.
```
</CodeGroup>

<Tip>
Note that you could also run the name task eagerly (`name_task.run()`) and then pass its result to the poem task. The best way to structure your workflow will depend on your specific use case and preferences.
</Tip>

### Managing the agentic loop

You can control the agentic loop by calling it iteratively with limits on the amount of work that can be done on each call. In this example, we manually invoke the author and critic agents for one turn each until the task is complete. Note that this example is contrived; if you actually wanted to loop over agents deterministically, the `RoundRobin` turn strategy is a better choice. However, "opening" the loop like this is a good choice when you want to dynamically select the next agent based on the results of the previous turn, or you want to run some custom logic between turns.

```python
import controlflow as cf

author = cf.Agent(name="Author")
critic = cf.Agent(name="Critic")

task = cf.Task('Write a poem about AI, then critique it.', agents=[author, critic])

while task.is_incomplete():
    # run the author for one turn
    cf.run_tasks([task], agent=author, max_agent_turns=1)

    # run the critic for one turn
    cf.run_tasks([task], agent=critic, max_agent_turns=1)


orchestrator.run()
```

#### Limiting agent turns

The `max_agent_turns` argument limits the number of agentic turns that can be taken in a single orchestration session. This limit is enforced by the orchestrator, which will end the turn early if the limit is reached.

A global default can be set with ControlFlow's `orchestrator_max_agent_turns` setting.


#### Limiting LLM calls

The `max_llm_calls` argument limits the number of LLM calls that can be made during a single orchestration session. This limit is enforced by the orchestrator, which will end the turn early if the limit is reached. Note that this is enforced independently of the `max_agent_turns` limit.

A global default can be set with ControlFlow's `orchestrator_max_llm_calls` setting.


#### Limiting LLM calls over the lifetime of a task

Each task has an optional `max_llm_calls` parameter, which limits the number of LLM calls that can be made during the task's lifetime. A task will be marked as failed if the limit is reached and the task is not complete. The call count is incremented any time an LLM is invoked and the task is both "ready" and assigned to the active agent.

Here, we force a task to fail by limiting it to a single LLM call but requiring it to use a tool (which typically requires two LLM calls: one to use the tool and one to evaluate the result):

<CodeGroup>
```python Code
import controlflow as cf
import random

def roll_dice():
    '''roll one die'''
    return random.randint(1, 6)

task = cf.Task(
    "Roll 3 dice and report the results",
    max_llm_calls=1,
    tools=[roll_dice],
)

# this will fail
task.run()
```
```text Error
Task 5ba273e6 ("Roll 3 dice and report the results") failed: Max LLM calls reached for this task.
```

A global default can be set with ControlFlow's `task_max_llm_calls` setting.

</CodeGroup>

<Tip>
Note that the setting `max_llm_calls` on the task results in the task failing if the limit is reached. Setting `max_llm_calls` on the orchestrator only exits the loop early, but does not otherwise affect task behavior.
</Tip>


#### Early termination conditions

<VersionBadge version="0.11" />

ControlFlow supports more flexible control over when an orchestration run should end through the use of `run_until` conditions. These conditions allow you to specify complex termination logic based on various factors such as task completion, failure, or custom criteria.

To use a run until condition, you can pass it to the `run_until` parameter when calling `run`, `run_async`, `run_tasks`, or `run_tasks_async`. For example, the following tasks will run until either one of them is complete or 10 LLM calls have been made:

```python
import controlflow as cf
from controlflow.orchestration.conditions import AnyComplete, MaxLLMCalls

result = cf.run_tasks(
    tasks=[cf.Task("write a poem about AI"), cf.Task("write a poem about ML")],
    run_until=AnyComplete() | MaxLLMCalls(10)
)
```

(Note that because tasks can be run in parallel, it's possible for both subtasks to be completed.)

Termination conditions can be combined using boolean logic: `|` indicates "or" and `&` indicates "and". A variety of built-in conditions are available:

- `AllComplete()`: stop when all tasks are complete (this is the default behavior)
- `MaxLLMCalls(n: int)`: stop when `n` LLM calls have been made (equivalent to providing `max_llm_calls`)
- `MaxAgentTurns(n: int)`: stop when `n` agent turns have been made (equivalent to providing `max_agent_turns`)
- `AnyComplete(tasks: list[Task], min_complete: int=1)`: stop when at least `min_complete` tasks are complete. If no tasks are provided, all of the orchestrator's tasks will be used.
- `AnyFailed(tasks: list[Task], min_failed: int=1)`: stop when at least `min_failed` tasks have failed. If no tasks are provided, all of the orchestrator's tasks will be used.



### Accessing an orchestrator directly

If you want to "step" through the agentic loop yourself, you can create and invoke an `Orchestrator` directly.

The orchestrator is instantiated with the following arguments:
- `tasks`: a list of tasks that it is responsible for orchestrating. Note it will also consider all of the tasks' dependencies and subtasks, but these are the tasks that determine whether it is finished.
- `flow`: the flow in which to run the tasks. If not provided, a new flow will be created.
- `agent`: an initial agent to invoke. If not provided, the `turn_strategy` will be used to select the next agent.
- `turn_strategy`: the turn strategy to use to select the next agent. The default is `Popcorn`.

You can then use the orchestrator's `run()` method to step through the loop manually. If you call `run()` with no arguments, it will continue until all of the provided tasks are complete. You can provide `max_llm_calls` and `max_agent_turns` to further limit the behavior.


## Using handlers

Handlers in ControlFlow provide a way to observe and react to events that occur during task execution. They allow you to customize logging, monitoring, or take specific actions based on the orchestration process.

ControlFlow supports both synchronous and asynchronous handlers. Synchronous handlers implement the `Handler` interface, while asynchronous handlers implement the `AsyncHandler` interface. Both interfaces define methods for various events that can occur during task execution, including agent messages (and message deltas), user messages, tool calls, tool results, orchestrator sessions starting or stopping, and more.

ControlFlow includes a built-in `PrintHandler` that pretty-prints agent responses and tool calls to the terminal. It's used by default if `controlflow.settings.enable_default_print_handler=True` and no other handlers are provided.

### How handlers work

Whenever an event is generated by ControlFlow, the orchestrator will pass it to all of its registered handlers. Each handler will dispatch to one of its methods based on the type of event. For example, an `AgentMessage` event will be handled by the handler's `on_agent_message` method (or `on_agent_message_async` for async handlers). The `on_event` method is always called for every event. This table describes all event types and the methods they are dispatched to:

| Event Type | Method |
|------------|--------|
| `Event` (all events) | `on_event` |
| `UserMessage` | `on_user_message` |
| `OrchestratorMessage` | `on_orchestrator_message` |
| `AgentMessage` | `on_agent_message` |
| `AgentMessageDelta` | `on_agent_message_delta` |
| `ToolCall` | `on_tool_call` |
| `ToolResult` | `on_tool_result` |
| `OrchestratorStart` | `on_orchestrator_start` |
| `OrchestratorEnd` | `on_orchestrator_end` |
| `OrchestratorError` | `on_orchestrator_error` |
| `EndTurn` | `on_end_turn` |


### Writing a custom handler

To create a custom handler, subclass either the `Handler` class for synchronous handlers or the `AsyncHandler` class for asynchronous handlers. Implement the methods for the events you're interested in. Here are examples of both types:

#### Synchronous Handler

```python
import controlflow as cf
from controlflow.orchestration.handler import Handler
from controlflow.events.events import AgentMessage

class LoggingHandler(Handler):
    def on_agent_message(self, event: AgentMessage):
        print(f"Agent {event.agent.name} said: {event.ai_message.content}")

cf.run("Write a short poem about AI", handlers=[LoggingHandler()])
```

#### Asynchronous Handler

<VersionBadge version="0.11.1" />

```python
import asyncio
import controlflow as cf
from controlflow.orchestration.handler import AsyncHandler
from controlflow.events.events import AgentMessage

class AsyncLoggingHandler(AsyncHandler):
    async def on_agent_message(self, event: AgentMessage):
        await asyncio.sleep(0.1)  # Simulate some async operation
        print(f"Agent {event.agent.name} said: {event.ai_message.content}")

await cf.run_async("Write a short poem about AI", handlers=[AsyncLoggingHandler()])
```

When using asynchronous handlers, make sure to use the `run_async` function or other asynchronous methods in ControlFlow to properly handle the asynchronous events.

You can use both synchronous and asynchronous handlers together in the same async run. The orchestrator will automatically handle both types appropriately.



================================================
FILE: docs/patterns/streaming.mdx
================================================
---
title: Streaming
description: Process agent responses, tool calls and results in real-time through streaming or handlers.
icon: bars-staggered
---

import { VersionBadge } from '/snippets/version-badge.mdx'


ControlFlow provides two ways to process events during task execution:
- [**Streaming**](#streaming): Iterate over events in real-time using a Python iterator 
- [**Handlers**](#handlers): Register callback functions that are called for each event

Both approaches give you access to the same events - which one you choose depends on how you want to integrate with your application.

## Streaming

<VersionBadge version="0.12.0" />

When you enable streaming, task execution returns an iterator that yields events as they occur. Each iteration provides a tuple of (event, snapshot, delta) representing what just happened in the workflow:

```python
import controlflow as cf

for event, snapshot, delta in cf.run(
    "Write a poem about AI",
    stream=True,
):
    # For complete events, snapshot contains the full content
    if event.event == "agent-content":
        print(f"Agent wrote: {snapshot}")
    
    # For delta events, delta contains just what's new
    elif event.event == "agent-content-delta":
        print(delta, end="", flush=True)
```

You can focus on specific events using the `Stream` enum. Here, we return only content updates:

```python
import controlflow as cf

# Only stream content updates
for event, snapshot, delta in cf.run(
    "Write a poem",
    stream=cf.Stream.CONTENT
):
    print(delta if delta else snapshot)
```

The available stream filters are:
- `Stream.ALL`: All events (equivalent to `stream=True`) 
- `Stream.CONTENT`: Agent content and content deltas
- `Stream.TOOLS`: All tool events
- `Stream.COMPLETION_TOOLS`: Completion tool events (like marking a task successful or failed)
- `Stream.AGENT_TOOLS`: Tools used by agents for any purpose other than completing a task
- `Stream.TASK_EVENTS`: Task lifecycle events (starting, completion, failure, etc)

You can combine filters with the `|` operator:

```python
# Stream content and tool events
stream = Stream.CONTENT | Stream.TOOLS
```

For more complex filtering, set stream=True and filter the events manually, or use a handler.

## Handlers
<VersionBadge version="0.9.2" />

For more complex event processing, or when you want to decouple event handling from your main workflow, use handlers:

```python 
from controlflow.orchestration.handler import Handler
from controlflow.events.events import AgentMessage

class LoggingHandler(Handler):
    def on_agent_message(self, event: AgentMessage):
        print(f"Agent {event.agent.name} said: {event.message['content']}")

    def on_tool_result(self, event: ToolResult):
        print(f"Tool call result: {event.tool_result.str_result}")

# Use the handler
cf.run("Write a poem", handlers=[LoggingHandler()])
```

Handlers are especially useful for:
- Adding logging or monitoring
- Collecting metrics
- Updating UI elements
- Processing events asynchronously

Handlers call their `on_<event-name>` methods for each event type. For a complete list of available methods, see the [Event Details](#event-details) section below.


### Async Handlers

<VersionBadge version="0.11.1" />

For asynchronous event processing, use `AsyncHandler`:

```python
import asyncio
from controlflow.orchestration.handler import AsyncHandler

class AsyncLoggingHandler(AsyncHandler):
    async def on_agent_message(self, event: AgentMessage):
        await asyncio.sleep(0.1)  # Simulate async operation
        print(f"Agent {event.agent.name} said: {event.message['content']}")

await cf.run_async("Write a poem", handlers=[AsyncLoggingHandler()])
```

## Example: Real-time Content Display

Here's a complete example showing both approaches to display content in real-time:

<CodeGroup>
```python Streaming
import controlflow as cf

for event, snapshot, delta in cf.run(
    "Write a story about time travel",
    stream=cf.Stream.CONTENT
):
    # Print character by character
    if delta:
        print(delta, end="", flush=True)
```

```python Handler
import controlflow as cf
from controlflow.orchestration.handler import Handler

class ContentHandler(Handler):
    def on_agent_content_delta(self, event):
        # Print character by character
        print(event.content_delta, end="", flush=True)
        
cf.run(
    "Write a story about time travel",
    handlers=[ContentHandler()]
)
```
</CodeGroup>

## Event Details

Now that we've seen how to process events, let's look at the types of events you can receive:

### Content Events
Content events give you access to what an agent is saying or writing:

```python
# Complete content
{
    "event": "agent-content",
    "agent": agent,  # Agent object
    "content": "Hello, world!", # The complete content
    "agent_message_id": "msg_123"  # Optional ID linking to parent message
}

# Content delta (incremental update)
{
    "event": "agent-content-delta",
    "agent": agent,
    "content_delta": "Hello",  # New content since last update
    "content_snapshot": "Hello, world!",  # Complete content so far
    "agent_message_id": "msg_123"
}
```

### Tool Events
Tool events let you observe when agents use tools and get their results:

```python
# Tool being called
{
    "event": "agent-tool-call",
    "agent": agent,
    "tool_call": {...},  # The complete tool call info
    "tool": tool,  # The Tool object being called
    "args": {...},  # Arguments passed to the tool
    "agent_message_id": "msg_123"
}

# Tool call delta (incremental update)
{
    "event": "agent-tool-call-delta",
    "agent": agent,
    "tool_call_delta": {...},  # Changes to the tool call
    "tool_call_snapshot": {...},  # Complete tool call info so far
    "tool": tool,
    "args": {...},
    "agent_message_id": "msg_123"
}

# Tool result
{
    "event": "tool-result",
    "agent": agent,
    "tool_result": {
        "tool_call": {...},  # The original tool call
        "tool": tool,  # The Tool object that was called
        "result": any,  # The raw result value
        "str_result": "...",  # String representation of result
        "is_error": False  # Whether the tool call failed
    }
}
```

### Workflow Events
### Task Events
Events that mark key points in a task's lifecycle:
- `TaskStart`: A task has begun execution
- `TaskSuccess`: A task completed successfully (includes the final result)
- `TaskFailure`: A task failed (includes the error reason)
- `TaskSkipped`: A task was skipped

### Orchestration Events
Events related to orchestrating the overall workflow:
- `OrchestratorStart`/`End`: Workflow orchestration starting/ending
- `AgentTurnStart`/`End`: An agent's turn starting/ending
- `OrchestratorError`: An error occurred during orchestration

### Handler Methods

Each handler can implement methods for different types of events. The method will be called whenever that type of event occurs. Here are all available handler methods:

| Method | Event Type | Description |
|--------|------------|-------------|
| `on_event(event)` | Any | Called for every event, before any specific handler |
| `on_agent_message(event)` | AgentMessage | Raw LLM output containing both content and tool calls |
| `on_agent_message_delta(event)` | AgentMessageDelta | Incremental updates to raw LLM output |
| `on_agent_content(event)` | AgentContent | Unstructured text output from an agent |
| `on_agent_content_delta(event)` | AgentContentDelta | Incremental updates to agent content |
| `on_agent_tool_call(event)` | AgentToolCall | Tool being called by an agent |
| `on_agent_tool_call_delta(event)` | AgentToolCallDelta | Incremental updates to a tool call |
| `on_tool_result(event)` | ToolResult | Result returned from a tool |
| `on_orchestrator_start(event)` | OrchestratorStart | Workflow orchestration starting |
| `on_orchestrator_end(event)` | OrchestratorEnd | Workflow orchestration completed |
| `on_agent_turn_start(event)` | AgentTurnStart | An agent beginning their turn |
| `on_agent_turn_end(event)` | AgentTurnEnd | An agent completing their turn |
| `on_orchestrator_error(event)` | OrchestratorError | Error during orchestration |

Note that AgentMessage is the "raw" output from the LLM and contains both unstructured content and structured tool calls. When you receive an AgentMessage, you will also receive separate AgentContent and/or AgentToolCall events for any content or tool calls contained in that message. This allows you to:
1. Handle all LLM output in one place with `on_agent_message`
2. Handle just content with `on_agent_content` 
3. Handle just tool calls with `on_agent_tool_call`

For streaming cases, the delta events (e.g. AgentMessageDelta, AgentContentDelta) provide incremental updates as the LLM generates its response. Task events, in contrast, are complete events that mark important points in a task's lifecycle - you can use these to track progress and get results without managing the task object directly..



================================================
FILE: docs/patterns/task-results.mdx
================================================
---
title: Task Results
description: Validate task outputs with structured result types.
icon: square-check
---

ControlFlow tasks are designed to translate between the unstructured, conversational world of your AI agents and the structured, programmatic world of your application. The primary mechanism for this translation is the task's result, which should be a well-defined, validated output that can be used by other tasks or components in your workflow.

## Structured results

ControlFlow allows you to specify the expected structure of a task's result using the `result_type` parameter. This ensures that the result conforms to a specific data schema, making it easier to work with and reducing the risk of errors in downstream tasks.

### Strings

By default, the `result_type` of a task is a string, which essentially means the agent can return any value that satisfies the task's objective.

For example, if you ask an agent to "Say hello in three languages", it might return a simple string like `"Hello; Hola; Bonjour"` or a more complex, conversational response instead:

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run("Say hello in three languages")

print(result)
```

```text Simple result
Hello; Hola; Bonjour
```

```text Complex result
Hello there!

In three languages, "Hello" can be expressed as follows:

1. English: Hello
2. Spanish: Hola
3. French: Bonjour
```
</CodeGroup>

Sometimes this flexibility is useful, especially if your task's result will only be consumed as the input to another ControlFlow task. However, it can also lead to ambiguity and errors if the agent produces unexpected output, and is difficult to work with in an automated or programmatic way.


### Numbers

If your result is a number, you can specify the `result_type` as `int` or `float`:

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run("What is 2 + 2?", result_type=int)

print(result)
assert isinstance(result, int)
```
```text Result
4
```
</CodeGroup>

### Booleans
You can use `bool` for tasks whose result is a simple true/false value:

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run("The Earth is flat", result_type=bool)

print(result)
assert result is False
```
```text Result
False
```
</CodeGroup>


### Collections

You can also use typed collections like lists and dicts to specify the structure of your task's result.

Let's revisit the example of asking an agent to say hello in three languages, but this time specifying that the result should be a list of strings, or `list[str]`. This forces the agent to produce the result you probably expected (three separate strings, each representing a greeting in a different language):

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run("Say hello in three languages", result_type=list[str])

print(result)
print(result[0])
```

```text Result
['Hello', 'Hola', 'Bonjour']
'Hello'
```
</CodeGroup>

### Annotated types

Sometimes, data types are not precise enough to guide the agent to the desired result. In these cases, you can use an annotated type to provide more specific instructions.

For example, if we want to ensure that the agent returns a string that is only a zip code, we can specify the `result_type` as `Annotated[str, "a 5 digit zip code"]`.

<CodeGroup>
```python Code
import controlflow as cf

result = cf.run(
    "What is the zip code of the White House?",
    result_type=Annotated[str, "a 5 digit zip code"],
)

print(result)
```

```text Result
20500
```
</CodeGroup>

<Tip>
Note that annotated types are not validated; the annotation is provided as part of the agent's natural language instructions. You could additionaly provide a custom [result validator](#validation) to enforce the constraint.
</Tip>

### Labeling / classification

Often, you may want an agent to choose a value from a specific set of options, in order to label or classify a response as one of potentially many choices.


To do this, specify a list, tuple, `Literal`, or enum of allowed values for the result type. Here, we classify the media type of "Star Wars: Return of the Jedi" from a list of options:

<CodeGroup>
```python Code
import controlflow as cf

media = cf.run(
    "Star Wars: Return of the Jedi",
    result_type=["movie", "tv show", "book", "comic", "other"]
)

print(media)
```

```text Result
movie
```
</CodeGroup>

<Tip>
ControlFlow optimizes single-choice constrained selection by asking agents to choose a value by index rather than writing out the entire response. This optimization significantly improves latency while also conserving output tokens.
</Tip>

You can provide almost any Python object as a constrained choice, and ControlFlow will return *that object* as the result. Note that objects must be serialized in order to be shown to the agent.

#### A list of labels


When you provide a set of constrained choices, the agent will choose **one and only one** as the task's result. Often, you will want to produce a list of labels, either because you want to classify multiple items at once OR because you want to allow the agent to choose multiple values for a single input. To do so, you must indicate that your expected result type is a list of either `Literal` values or enum members.

In the following example, two media types are provided as context, and because the result type is a list, the agent is able to produce two responses:

<CodeGroup>
```python Code
import controlflow as cf
from typing import Literal

media = cf.run(
    ["Star Wars: Return of the Jedi", "LOST"],
    result_type=list[Literal["movie", "tv show", "book", "comic", "other"]]
)

print(media)
```

```text Result
['movie', 'tv show']
```
</CodeGroup>

In this example, the agent is able to choose multiple values for a single input, and the result is a list of strings:

<CodeGroup>
```python Code
import controlflow as cf
from typing import Literal

tags = cf.run(
    'Star Wars: Return of the Jedi',
    instructions="Choose all that apply",
    result_type=list[Literal["Star Wars", "space", "pirates", "adventure", "musical"]]
)

print(tags)
```

```text Result
['Star Wars', 'space', 'adventure']
```
</CodeGroup>

<Warning>
Labeling multiple inputs at once relies on Python's built-in type annotations and does not provide the same list- and tuple-aware optimizations and sugar that ControlFlow provides for single-choice constrained selection. Therefore the following syntax, which is not considered proper Python, will error:

```python
cf.run(
    ...,
    result_type=list[["A", "B"]]
)
```

but using a `Literal` or enum will work:

```python
cf.run(
    ...,
    result_type=list[Literal["A", "B"]]
)
```
</Warning>

### Pydantic models

For complex, structured results, you can use a Pydantic model as the `result_type`. Pydantic models provide a powerful way to define data schemas and validate input data.

<CodeGroup>
```python Code
import controlflow as cf
from pydantic import BaseModel, Field

class ResearchReport(BaseModel):
    title: str
    summary: str
    key_findings: list[str] = Field(min_items=3, max_items=10)
    references: list[str]

result = cf.run(
    "Generate a research report on quantum computing",
    result_type=ResearchReport,
)

print(repr(result))
```

```text Result
ResearchReport(
    title='Quantum Computing: Current Landscape and Future Prospects',
    summary='Quantum computing represents a significant leap in computational capabilities, leveraging the principles of quantum mechanics to perform complex calculations far beyond the reach of classical computers. This report delves into the current state of quantum computing, exploring its foundational principles, recent advancements, and the potential implications for various industries. Key findings highlight the technological hurdles, notable achievements, and the transformative potential of quantum computing in solving intractable problems.',
    key_findings=[
        'Principles of Quantum Mechanics: Quantum computing utilizes qubits, superposition, and entanglement to process information in fundamentally new ways, enabling parallel computation on a massive scale.',
        'Technological Achievements: Major milestones include the development of stable qubits, error correction algorithms, and quantum supremacy demonstrations by leading tech companies like Google and IBM.',
        'Applications and Impacts: Quantum computing shows promise in fields such as cryptography, materials science, pharmaceuticals, and artificial intelligence, potentially revolutionizing these sectors by providing unprecedented computational power.',
        'Challenges and Limitations: Significant obstacles remain, including qubit stability, error rates, and the need for extremely low temperatures. Overcoming these challenges is essential for the practical deployment of quantum computers.',
        'Future Directions: Ongoing research focuses on improving qubit coherence times, developing scalable quantum architectures, and creating robust quantum algorithms to harness the full potential of quantum computing.'
    ],
    references=[
        'Nielsen, M. A., & Chuang, I. L. (2010). Quantum Computation and Quantum Information. Cambridge University Press.',
        'Arute, F., Arya, K., Babbush, R., Bacon, D., Bardin, J. C., Barends, R., ... & Martinis, J. M. (2019). Quantum supremacy using a programmable superconducting processor. Nature, 574(7779), 505-510.',
        'Preskill, J. (2018). Quantum Computing in the NISQ era and beyond. Quantum, 2, 79.',
        'Montanaro, A. (2016). Quantum algorithms: an overview. npj Quantum Information, 2, 15023.',
        'Shor, P. W. (1997). Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer. SIAM Journal on Computing, 26(5), 1484-1509.'
    ]
)
```
</CodeGroup>

### No result

Sometimes, you may want to ask an agent to perform an action without expecting or requiring a result. In this case, you can specify `result_type=None`. For example, you might want to ask an agent to use a tool or post a message to the workflow thread, without requiring any task output.

```python
import controlflow as cf

def status_tool(status: str) -> None:
    """Submit a status update to the workflow thread."""
    print(f"Submitting status update: {status}")

cf.run(
    "Use your tool to submit a status update",
    result_type=None,
    tools=[status_tool],
)
```

Note that it is generally recommended to ask agents to produce a result, even if its just a quick status update. This is because other agents in the workflow can usually see the result of a task, but they may not be able to see any tool calls, messages, or side effects that the agent used to produce the result. Therefore, results can be helpful even if the assigned agent doesn't need them.


## Validation

### Pydantic

When using a Pydantic model as the `result_type`, you can use any of Pydantic's built-in or custom validators to further constrain or modify the result after it has been produced.

<CodeGroup>
```python Code
import controlflow as cf
from pydantic import BaseModel, field_validator

class SentimentAnalysis(BaseModel):
    text: str
    sentiment: float

    @field_validator('sentiment')
    def check_sentiment_range(cls, v):
        if not -1 <= v <= 1:
            raise ValueError('Sentiment must be between -1 and 1')
        return v

result = cf.run(
    "Analyze sentiment of given text",
    result_type=SentimentAnalysis,
    context=dict(text="I love ControlFlow!"),
)

print(repr(result))
```

```text Result
SentimentAnalysis(text='I love ControlFlow!', sentiment=0.9)
```
</CodeGroup>

### Validation functions

If you supply a function as your task's `result_validator`, it can be used to further validate or even modify the result after it has been produced by an agent.

The result validator will be called with the LLM result **after** it has been coerced into the `result_type`, and must either return a validated result or raise an exception. ControlFlow supplies a few common validators to get you started:

- `between(min_value, max_value)`: Validates that the result is a float between `min_value` and `max_value`.
- `has_len(min_length, max_length)`: Validates that the result is a string, list, or tuple with a length between `min_length` and `max_length`.
- `has_keys(required_keys)`: Validates that the result is a dictionary with all of the specified keys.
- `is_url()`: Validates that the result is a string that is a URL.
- `is_email()`: Validates that the result is a string that is an email address.

These are available in the `controlflow.tasks.validators` module, along with a convenient `chain` function that allows you to combine multiple validators into a single function.


<Tip>
Remember that result validators must either **return** the result or **raise** an exception. They are not true/false checks!
</Tip>

```python
import controlflow as cf
from controlflow.tasks.validators import chain, between

def is_even(value: int) -> int:
    if value % 2 != 0:
        raise ValueError("Value must be even")
    return value

cf.run(
    "Generate an even number between 1 and 100",
    result_type=int,
    result_validator=chain(between(1, 100), is_even),
)
```

### Modifying the result

You can also use a result validator to modify the result after it has been produced by an agent. For example, you might want to round a floating point number or convert a string to a specific format.

```python
import controlflow as cf

def round_to_one_decimal_place(value: float) -> float:
    return round(value, 1)

sentiment = cf.run(
    "Analyze sentiment of given text",
    result_type=float,
    context=dict(text="I love ControlFlow!"),
    result_validator=round_to_one_decimal_place,
)
```



================================================
FILE: docs/patterns/tools.mdx
================================================
---
title: Tools
description: Give agents new abilities with custom tools.
icon: toolbox
---

A tool is a Python function that your agents can use to accomplish tasks. They let you extend the capabilities of your agents beyond their built-in knowledge and abilities, allowing them to interact with external systems, perform calculations, or access specific information. 

Tools can be simple utility functions, complex data processing operations, or API calls to external services. Here's a basic example of a tool for rolling dice:

<CodeGroup>
```python Code
import controlflow as cf
import random

def roll_die() -> int:
    """Roll a 6-sided diee."""
    return random.randint(1, 6)

rolls = cf.run("Roll a die four times", tools=[roll_die])

print(rolls)
```
```text Result
[3, 1, 4, 2]
```
</CodeGroup>
## Best Practices

Any Python function can be used as a tool, but you'll get the best performance with the following best practices.

### Clear name and description

The name and description of the tool are two of the most important pieces of information for an agent. They help the agent understand what the tool does and how it can be used. Make sure to provide a clear and concise name and description for your tool.

The description is taken from your function's docstring, so be sure to include a detailed description of what the tool does and how it should be used. You can give natural language instructions on how to use the tool and what parameters it expects.

### Type hints

ControlFlow uses all available information to generate a parameter schema that tells an agent how to call the tool and what type of information to expect it to return. Type hints are a powerful way to provide this information. Here's an example of a tool with type hints:

<CodeGroup>
```python Weather
def get_weather(location: str) -> float:
    """Fetch weather data for the specified location."""
    # Implementation details...
```
```python Velocity
def calculate_velocity(distance: float, time: float) -> float:
    """Calculate velocity by dividing distance by time."""
    if time == 0:
        raise ValueError("Time cannot be zero.")
    return distance / time
```
</CodeGroup>



#### Annotations
If you use type annotations, ControlFlow will include the annotated details in the schema. This lets you give additional information about the expected input and output of the tool in a more structured way.
<CodeGroup>
```python Weather
from typing import Annotated

def get_weather(
    location: Annotated[str, "The 5 or 9-digit zip code"],
) -> Annotated[float, "The temperature in Farhenheit"]:
    """Fetch weather data for the specified location."""
    ...
```

```python Velocity
from typing import Annotated

def calculate_velocity(
    distance: Annotated[float, "The distance in meters"],
    time: Annotated[float, "The time in seconds"],
) -> Annotated[float, "The velocity in meters per second"]:
    """Calculate velocity by dividing distance by time."""
    if time == 0:
        raise ValueError("Time cannot be zero.")
    return distance / time
```
</CodeGroup>

Note that you can also provide this information in your docstring.

#### Pydantic Models

For tools that return complex data structures, you can use Pydantic models to define the return type. 

```python
from pydantic import BaseModel

class WeatherData(BaseModel):
    temperature: float
    humidity: float
    conditions: str

@tool
def get_detailed_weather(location: str) -> WeatherData:
    """Get detailed weather information for a location."""
    # Implementation details...
    

weather_task = cf.Task(
    "Provide a weather report for New York",
    tools=[get_detailed_weather]
)
```

### Error Messages

If your tool encounters an error, raise an exception with a clear message. The agent will be told that the tool call failed and shown the error message, giving them an opportunity to understand what went wrong and try to fix it.

## Creating Tools

ControlFlow supports the following types of tools:
- Regular Python functions
- Asynchronous Python functions (they are automatically run in an asynchronous context)
- LangChain tools

### Regular Python Functions

In most cases, you can use regular Python functions as tools without modification. However, if you need to customize how a function is converted to a tool, you can use the `@tool` decorator to override the inferred name and description. For example, this function has no docstring, so we use the decorator to provide a custom description:

```python
from controlflow import tool

@tool(description="Get current weather for a location")
def get_weather(location: str) -> dict:
    #Implementation details...
```

### LangChain Tools

LangChain has many [pre-built tools](https://python.langchain.com/v0.2/docs/integrations/tools/) that you can leverage. For example, here's how to get recent data from the web with DuckDuckGo.

First, install the dependencies:

```bash
pip install -U langchain-community duckduckgo-search
```

Then import the tool for use:


Import the tool and assign it to an agent or task:
```python   
import controlflow as cf
from langchain_community.tools import DuckDuckGoSearchRun

agent = cf.Agent(
    name="Timely agent",
    description="An AI agent that knows current events",
    tools=[DuckDuckGoSearchRun()],
)
```

## Using Tools

Tools can be provided either to tasks or agents. When a tool is provided to a task, any agent working on that task will have access to the tool. When a tool is provided to an agent, the agent can use the tool in any task it is assigned to.

### Providing Tools to Tasks

You should provide tools to tasks when you know that a task will require specific capabilities to be completed successfully. For example, if a task requires access to a database or an external API, you can provide a tool that handles the interaction with that system:

```python
import controlflow as cf

def search_database(query: str) -> list:
    """Search the product database for items matching the query."""
    # Implementation details...    

def format_results(results: list) -> str:
    """Format a list of search results into a readable string."""
    # Implementation details...    

product_search_task = cf.Task(
    "Find and summarize products matching the user's query",
    tools=[search_database, format_results],
    interactive=True
)
```

In this example, the `product_search_task` is equipped with tools to search a database and format the results. Any agent assigned to this task will have access to these tools.

### Providing Tools to Agents

You can also provide tools directly to agents, allowing them to use the tools in any task they are assigned to. This can be useful when you have an agent that needs to perform a specific action across multiple tasks:

```python
import controlflow as cf

def search_database(query: str) -> list:
    """Search the product database for items matching the query."""
    # Implementation details...    

def format_results(results: list) -> str:
    """Format a list of search results into a readable string."""
    # Implementation details...    

agent = cf.Agent(
    "Product Search Agent",
    tools=[search_database, format_results]
)
```

Using Pydantic models for tool return types helps ensure that the data returned by the tool is properly structured and validated.


## Debugging Tools

### Verbose Logging

By default, the PrintHandler will log tool calls and indicate whether the tool was successful or not. You can enable verbose logging to see more detailed information about the tool call, including the input parameters and the output:
<CodeGroup>
```bash As an environment variable
export CONTROLFLOW_TOOLS_VERBOSE=true
```

```python As a runtime setting
import controlflow as cf

cf.settings.tools_verbose = True
```
</CodeGroup>

### Raising Errors
If your tool raises an exception during execution, ControlFlow will capture the error and show it to the agent so the agent can try again. However, when devloping or testing workflows you may want to disable this behavior. ControlFlow offers a debug setting for raising exceptions when a tool fails instead of capturing them:
<CodeGroup>
```bash As an environment variable
export CONTROLFLOW_TOOLS_RAISE_ON_ERROR=true
```

```python As a runtime setting
import controlflow as cf

cf.settings.tools_raise_on_error = True
```
</CodeGroup>

## When to Use Tools

Tools are particularly useful in scenarios where:

1. The task requires access to external data or systems
2. Complex calculations or data processing are needed
3. The agent needs to perform actions that are beyond its inherent capabilities
4. You want to ensure consistent handling of certain operations across multiple tasks

By providing appropriate tools, you can significantly enhance the problem-solving capabilities of your AI agents and create more powerful and flexible workflows.

While tools are powerful, they should be used judiciously. Provide only the tools that are necessary for the task at hand to avoid overwhelming the agent with too many options.



================================================
FILE: docs/snippets/version-badge.mdx
================================================
export const VersionBadge = ({ version }) => {


    return (
        <span className="version-badge">
            New in version {version}
        </span>
    );
};


================================================
FILE: examples/anonymization.py
================================================
from pydantic import BaseModel, Field

import controlflow as cf


class AnonymizationResult(BaseModel):
    original: str
    anonymized: str
    replacements: dict[str, str] = Field(
        description=r"The replacements made during anonymization, {original} -> {placeholder}"
    )


def anonymize_text(text: str) -> AnonymizationResult:
    return cf.run(
        "Anonymize the given text by replacing personal information with generic placeholders",
        result_type=AnonymizationResult,
        context={"text": text},
    )


if __name__ == "__main__":
    original_text = "John Doe, born on 05/15/1980, lives at 123 Main St, New York. His email is john.doe@example.com."

    result = anonymize_text(original_text)
    print(f"Original: {result.original}")
    print(f"Anonymized: {result.anonymized}")
    print("Replacements:")
    for original, placeholder in result.replacements.items():
        print(f"  {original} -> {placeholder}")



================================================
FILE: examples/asyncpg-memory.py
================================================
import asyncio

import controlflow as cf
from controlflow.memory.async_memory import AsyncMemory
from controlflow.memory.providers.postgres import AsyncPostgresMemory

provider = AsyncPostgresMemory(
    database_url="postgresql+psycopg://postgres:postgres@localhost:5432/database",
    # embedding_dimension=1536,
    # embedding_fn=OpenAIEmbeddings(),
    table_name="vector_db_async",
)

# Create a memory module for user preferences
user_preferences = AsyncMemory(
    key="user_preferences",
    instructions="Store and retrieve user preferences.",
    provider=provider,
)

# Create an agent with access to the memory
agent = cf.Agent(memories=[user_preferences])


# Create a flow to ask for the user's favorite color
@cf.flow
async def remember_pet():
    return await cf.run_async(
        "Ask the user for their favorite animal and store it in memory",
        agents=[agent],
        interactive=True,
    )


# Create a flow to recall the user's favorite color
@cf.flow
async def recall_pet():
    return await cf.run_async(
        "What is the user's favorite animal?",
        agents=[agent],
    )


async def main():
    print("First flow:")
    await remember_pet()

    print("\nSecond flow:")
    result = await recall_pet()
    print(result)
    return result


if __name__ == "__main__":
    asyncio.run(main())



================================================
FILE: examples/call_routing.py
================================================
import random

import controlflow as cf

DEPARTMENTS = [
    "Sales",
    "Support",
    "Billing",
    "Returns",
]


@cf.flow
def routing_flow():
    target_department = random.choice(DEPARTMENTS)

    print(f"\n---\nThe target department is: {target_department}\n---\n")

    customer = cf.Agent(
        name="Customer",
        instructions=f"""
            You are training customer reps by pretending to be a customer
            calling into a call center. You need to be routed to the
            {target_department} department. Come up with a good backstory.
            """,
    )

    trainee = cf.Agent(
        name="Trainee",
        instructions=""",
            You are a trainee customer service representative. You need to
            listen to the customer's story and route them to the correct
            department. Note that the customer is another agent training you.
            """,
    )

    with cf.Task(
        "Route the customer to the correct department.",
        agents=[trainee],
        result_type=DEPARTMENTS,
    ) as main_task:
        while main_task.is_incomplete():
            cf.run(
                "Talk to the trainee.",
                instructions=(
                    "Post a message to talk. In order to help the trainee "
                    "learn, don't be direct about the department you want. "
                    "Instead, share a story that will let them practice. "
                    "After you speak, mark this task as complete."
                ),
                agents=[customer],
                result_type=None,
            )

            cf.run(
                "Talk to the customer.",
                instructions=(
                    "Post a message to talk. Ask questions to learn more "
                    "about the customer. After you speak, mark this task as "
                    "complete. When you have enough information, use the main "
                    "task tool to route the customer to the correct department."
                ),
                agents=[trainee],
                result_type=None,
                tools=[main_task.get_success_tool()],
            )

    if main_task.result == target_department:
        print("Success! The customer was routed to the correct department.")
    else:
        print(
            f"Failed. The customer was routed to the wrong department. "
            f"The correct department was {target_department}."
        )


if __name__ == "__main__":
    routing_flow()



================================================
FILE: examples/code_explanation.py
================================================
from pydantic import BaseModel

import controlflow as cf


class CodeExplanation(BaseModel):
    code: str
    explanation: str
    language: str


def explain_code(code: str, language: str = None) -> CodeExplanation:
    return cf.run(
        f"Explain the following code snippet",
        result_type=CodeExplanation,
        context={"code": code, "language": language or "auto-detect"},
    )


if __name__ == "__main__":
    code_snippet = """
    def fibonacci(n):
        if n <= 1:
            return n
        else:
            return fibonacci(n-1) + fibonacci(n-2)
    """

    result = explain_code(code_snippet, "Python")
    print(f"Code:\n{result.code}\n")
    print(f"Explanation:\n{result.explanation}")



================================================
FILE: examples/early_termination.py
================================================
from pydantic import BaseModel

import controlflow as cf
from controlflow.orchestration.conditions import AnyComplete, MaxLLMCalls


class ResearchPoint(BaseModel):
    topic: str
    key_findings: list[str]


@cf.flow
def research_workflow(topics: list[str]):
    if len(topics) < 2:
        raise ValueError("At least two topics are required")

    research_tasks = [
        cf.Task(f"Research {topic}", result_type=ResearchPoint) for topic in topics
    ]

    # Run tasks until either two topics are researched or 15 LLM calls are made
    results = cf.run_tasks(
        research_tasks,
        instructions="Research only one topic at a time.",
        run_until=(
            AnyComplete(
                min_complete=2
            )  # stop after two tasks (if there are more than two topics)
            | MaxLLMCalls(15)  # or stop after 15 LLM calls, whichever comes first
        ),
    )

    completed_research = [r for r in results if isinstance(r, ResearchPoint)]
    return completed_research


if __name__ == "__main__":
    # Example usage
    topics = [
        "Artificial Intelligence",
        "Quantum Computing",
        "Biotechnology",
        "Renewable Energy",
    ]
    results = research_workflow(topics)

    print(f"Completed research on {len(results)} topics:")
    for research in results:
        print(f"\nTopic: {research.topic}")
        print("Key Findings:")
        for finding in research.key_findings:
            print(f"- {finding}")



================================================
FILE: examples/generate_people.py
================================================
from pydantic import BaseModel, Field

import controlflow as cf


class UserProfile(BaseModel):
    name: str = Field(description="The full name of the user")
    age: int = Field(description="The age of the user, 20-60")
    occupation: str = Field(description="The occupation of the user")
    hobby: str


def generate_profiles(count: int) -> list[UserProfile]:
    return cf.run(
        f"Generate {count} user profiles",
        result_type=list[UserProfile],
        context={"count": count},
    )


if __name__ == "__main__":
    test_data = generate_profiles(count=5)

    from rich import print

    print(test_data)



================================================
FILE: examples/headline_categorization.py
================================================
import controlflow as cf

classifier = cf.Agent(model="openai/gpt-4o-mini")


def classify_news(headline: str) -> str:
    return cf.run(
        "Classify the news headline into the most appropriate category",
        agents=[classifier],
        result_type=["Politics", "Technology", "Sports", "Entertainment", "Science"],
        context={"headline": headline},
    )


if __name__ == "__main__":
    headline = "New AI Model Breaks Records in Language Understanding"
    category = classify_news(headline)
    print(f"Headline: {headline}")
    print(f"Category: {category}")

    headline = "Scientists Discover Potentially Habitable Exoplanet"
    category = classify_news(headline)
    print(f"\nHeadline: {headline}")
    print(f"Category: {category}")



================================================
FILE: examples/language_tutor.py
================================================
from pydantic import BaseModel

import controlflow as cf


class Lesson(BaseModel):
    topic: str
    content: str
    exercises: list[str]


def language_learning_session(language: str) -> None:
    tutor = cf.Agent(
        name="Tutor",
        instructions="""
        You are a friendly and encouraging language tutor. Your goal is to create an 
        engaging and supportive learning environment. Always maintain a warm tone, 
        offer praise for efforts, and provide gentle corrections. Adapt your teaching 
        style to the user's needs and pace. Use casual language to keep the 
        conversation light and fun. When working through exercises:
        - Present one exercise at a time.
        - Provide hints if the user is struggling.
        - Offer the correct answer if the user can't solve it after a few attempts.
        - Use encouraging language throughout the process.
        """,
    )

    @cf.flow(default_agent=tutor)
    def learning_flow():
        user_name = cf.run(
            f"Greet the user, learn their name, and introduce the {language} learning session",
            interactive=True,
            result_type=str,
        )

        print(f"\nWelcome, {user_name}! Let's start your {language} lesson.\n")

        while True:
            lesson = cf.run(
                "Create a fun and engaging language lesson", result_type=Lesson
            )

            print(f"\nToday's topic: {lesson.topic}")
            print(f"Lesson content: {lesson.content}\n")

            for exercise in lesson.exercises:
                print(f"Exercise: {exercise}")
                cf.run(
                    "Work through the exercise with the user",
                    interactive=True,
                    context={"exercise": exercise},
                )

            continue_learning = cf.run(
                "Check if the user wants to continue learning",
                result_type=bool,
                interactive=True,
            )

            if not continue_learning:
                break

        summary = cf.run(
            "Summarize the learning session and provide encouragement",
            context={"user_name": user_name},
            result_type=str,
        )
        print(f"\nSession summary: {summary}")

    learning_flow()


if __name__ == "__main__":
    language = input("Which language would you like to learn? ")
    language_learning_session(language)



================================================
FILE: examples/memory.py
================================================
import controlflow as cf

# Create a memory module for user preferences
user_preferences = cf.Memory(
    key="user_preferences", instructions="Store and retrieve user preferences."
)

# Create an agent with access to the memory
agent = cf.Agent(memories=[user_preferences])


# Create a flow to ask for the user's favorite color
@cf.flow
def remember_color():
    return cf.run(
        "Ask the user for their favorite color and store it in memory",
        agents=[agent],
        interactive=True,
    )


# Create a flow to recall the user's favorite color
@cf.flow
def recall_color():
    return cf.run(
        "What is the user's favorite color?",
        agents=[agent],
    )


if __name__ == "__main__":
    print("First flow:")
    remember_color()

    print("\nSecond flow:")
    result = recall_color()
    print(result)



================================================
FILE: examples/named_entity_recognition.py
================================================
from typing import Dict, List

import controlflow as cf

extractor = cf.Agent(
    name="Named Entity Recognizer",
    model="openai/gpt-4o-mini",
)


def extract_entities(text: str) -> List[str]:
    return cf.run(
        "Extract all named entities from the text",
        agents=[extractor],
        result_type=List[str],
        context={"text": text},
    )


def extract_categorized_entities(text: str) -> Dict[str, List[str]]:
    return cf.run(
        "Extract named entities from the text and categorize them",
        instructions="""
        Return a dictionary with the following keys:
        - 'persons': List of person names
        - 'organizations': List of organization names
        - 'locations': List of location names
        - 'dates': List of date references
        - 'events': List of event names
        Only include keys if entities of that type are found in the text.
        """,
        agents=[extractor],
        result_type=Dict[str, List[str]],
        context={"text": text},
    )


if __name__ == "__main__":
    text = "Apple Inc. is planning to open a new store in New York City next month."
    entities = extract_entities(text)
    print("Simple extraction:")
    print(entities)

    text = "In 1969, Neil Armstrong became the first person to walk on the Moon during the Apollo 11 mission."
    categorized_entities = extract_categorized_entities(text)
    print("\nCategorized extraction:")
    print(categorized_entities)



================================================
FILE: examples/pg-memory.py
================================================
import controlflow as cf
from controlflow.memory.memory import Memory
from controlflow.memory.providers.postgres import PostgresMemory

provider = PostgresMemory(
    database_url="postgresql://postgres:postgres@localhost:5432/database",
    # embedding_dimension=1536,
    # embedding_fn=OpenAIEmbeddings(),
    table_name="vector_db",
)
# Create a memory module for user preferences
user_preferences = cf.Memory(
    key="user_preferences",
    instructions="Store and retrieve user preferences.",
    provider=provider,
)

# Create an agent with access to the memory
agent = cf.Agent(memories=[user_preferences])


# Create a flow to ask for the user's favorite color
@cf.flow
def remember_color():
    return cf.run(
        "Ask the user for their favorite color and store it in memory",
        agents=[agent],
        interactive=True,
    )


# Create a flow to recall the user's favorite color
@cf.flow
def recall_color():
    return cf.run(
        "What is the user's favorite color?",
        agents=[agent],
    )


if __name__ == "__main__":
    print("First flow:")
    remember_color()

    print("\nSecond flow:")
    result = recall_color()
    print(result)



================================================
FILE: examples/pineapple_pizza.py
================================================
import controlflow as cf

optimist = cf.Agent(
    name="Half-full",
    instructions="You are an eternal optimist.",
)
pessimist = cf.Agent(
    name="Half-empty",
    instructions="You are an eternal pessimist.",
)
moderator = cf.Agent(name="Moderator")


@cf.flow
def demo(topic: str):
    cf.run(
        "Have a debate about the topic.",
        instructions="Each agent should take at least two turns.",
        agents=[optimist, pessimist],
        context={"topic": topic},
    )

    winner: cf.Agent = cf.run(
        "Whose argument do you find more compelling?",
        agents=[moderator],
        result_type=[optimist, pessimist],
    )

    print(f"{winner.name} wins the debate!")


if __name__ == "__main__":
    demo("pineapple on pizza")



================================================
FILE: examples/private_flows.py
================================================
import controlflow as cf


@cf.flow(args_as_context=False)
def process_user_data(user_name: str, sensitive_info: str):
    # Main flow context
    print(f"Processing data for user: {user_name}")

    # Create a private flow to handle sensitive information
    with cf.Flow() as private_flow:
        # This task runs in an isolated context
        masked_info = cf.run(
            "Mask the sensitive information",
            context={"sensitive_info": sensitive_info},
            result_type=str,
        )

    # Task in the main flow can be provided the masked_info as context
    summary = cf.run(
        "Summarize the data processing result",
        context={"user_name": user_name, "masked_info": masked_info},
        result_type=str,
    )

    return summary


if __name__ == "__main__":
    result = process_user_data("Alice", "SSN: 123-45-6789")
    print(result)



================================================
FILE: examples/reasoning.py
================================================
"""
This example implements a reasoning loop that lets a relatively simple model
solve difficult problems.

Here, gpt-4o-mini is used to solve a problem that typically requires o1's
reasoning ability.
"""

import argparse

from pydantic import BaseModel, Field

import controlflow as cf
from controlflow.utilities.general import unwrap


class ReasoningStep(BaseModel):
    explanation: str = Field(
        description="""
            A brief (<5 words) description of what you intend to
            achieve in this step, to display to the user.
            """
    )
    reasoning: str = Field(
        description="A single step of reasoning, not more than 1 or 2 sentences."
    )
    found_validated_solution: bool


REASONING_INSTRUCTIONS = """
    You are working on solving a difficult problem (the `goal`). Based
    on your previous thoughts and the overall goal, please perform **one
    reasoning step** that advances you closer to a solution. Document
    your thought process and any intermediate steps you take.
    
    After marking this task complete for a single step, you will be
    given a new reasoning task to continue working on the problem. The
    loop will continue until you have a valid solution.
    
    Complete the task as soon as you have a valid solution.
    
    **Guidelines**
    
    - You will not be able to brute force a solution exhaustively. You
        must use your reasoning ability to make a plan that lets you make
        progress.
    - Each step should be focused on a specific aspect of the problem,
        either advancing your understanding of the problem or validating a
        solution.
    - You should build on previous steps without repeating them.
    - Since you will iterate your reasoning, you can explore multiple
        approaches in different steps.
    - Use logical and analytical thinking to reason through the problem.
    - Ensure that your solution is valid and meets all requirements.
    - If you find yourself spinning your wheels, take a step back and
        re-evaluate your approach.
"""


@cf.flow
def solve_with_reasoning(goal: str, agent: cf.Agent) -> str:
    while True:
        response: ReasoningStep = cf.run(
            objective="""
            Carefully read the `goal` and analyze the problem.
            
            Produce a single step of reasoning that advances you closer to a solution.
            """,
            instructions=REASONING_INSTRUCTIONS,
            result_type=ReasoningStep,
            agents=[agent],
            context=dict(goal=goal),
            model_kwargs=dict(tool_choice="required"),
        )

        if response.found_validated_solution:
            if cf.run(
                """
                Check your solution to be absolutely sure that it is correct and meets all requirements of the goal. Return True if it does.
                """,
                result_type=bool,
                context=dict(goal=goal),
            ):
                break

    return cf.run(objective=goal, agents=[agent])


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Solve a reasoning problem.")
    parser.add_argument("--goal", type=str, help="Custom goal to solve", default=None)
    args = parser.parse_args()

    agent = cf.Agent(name="Definitely not GPT-4o mini", model="openai/gpt-4o-mini")

    # Default goal via https://www.reddit.com/r/singularity/comments/1fggo1e/comment/ln3ymsu/
    default_goal = """
        Using only four instances of the digit 9 and any combination of the following
        mathematical operations: the decimal point, parentheses, addition (+),
        subtraction (-), multiplication (*), division (/), factorial (!), and square
        root (sqrt), create an equation that equals 24. 

        In order to validate your result, you should test that you have followed the rules:

        1. You have used the correct number of variables
        2. You have only used 9s and potentially a leading 0 for a decimal
        3. You have used valid mathematical symbols
        4. Your equation truly equates to 24.
        """

    # Use the provided goal if available, otherwise use the default
    goal = args.goal if args.goal is not None else default_goal
    goal = unwrap(goal)
    print(f"The goal is:\n\n{goal}")

    result = solve_with_reasoning(goal=goal, agent=agent)

    print(f"The solution is:\n\n{result}")



================================================
FILE: examples/rock_paper_scissors.py
================================================
import controlflow as cf


@cf.flow
def rock_paper_scissors():
    """Play rock, paper, scissors against an AI."""
    play_again = True

    while play_again:
        # Get the user's choice on a private thread
        with cf.Flow():
            user_choice = cf.run(
                "Get the user's choice",
                result_type=["rock", "paper", "scissors"],
                interactive=True,
            )

        # Get the AI's choice on a private thread
        with cf.Flow():
            ai_choice = cf.run(
                "Choose rock, paper, or scissors",
                result_type=["rock", "paper", "scissors"],
            )

        # Report the score and ask if the user wants to play again
        play_again = cf.run(
            "Report the score to the user and see if they want to play again.",
            interactive=True,
            context={"user_choice": user_choice, "ai_choice": ai_choice},
            result_type=bool,
        )


if __name__ == "__main__":
    rock_paper_scissors()



================================================
FILE: examples/seinfeld.py
================================================
import sys

from controlflow import Agent, Task, flow

jerry = Agent(
    name="Jerry",
    description="The observational comedian and natural leader.",
    instructions="""
    You are Jerry from the show Seinfeld. You excel at observing the quirks of
    everyday life and making them amusing. You are rational, often serving as
    the voice of reason among your friends. Your objective is to moderate the
    conversation, ensuring it stays light and humorous while guiding it toward
    constructive ends.
    """,
)

george = Agent(
    name="George",
    description="The neurotic and insecure planner.",
    instructions="""
    You are George from the show Seinfeld. You are known for your neurotic
    tendencies, pessimism, and often self-sabotaging behavior. Despite these
    traits, you occasionally offer surprising wisdom. Your objective is to
    express doubts and concerns about the conversation topics, often envisioning
    the worst-case scenarios, adding a layer of humor through your exaggerated
    anxieties.
    """,
)

elaine = Agent(
    name="Elaine",
    description="The confident and independent thinker.",
    instructions="""
    You are Elaine from the show Seinfeld. You are bold, witty, and unafraid to
    challenge social norms. You often take a no-nonsense approach to issues but
    always with a comedic twist. Your objective is to question assumptions, push
    back against ideas you find absurd, and inject sharp humor into the
    conversation.
    """,
)

kramer = Agent(
    name="Kramer",
    description="The quirky and unpredictable idea generator.",
    instructions="""
    You are Kramer from the show Seinfeld. Known for your eccentricity and
    spontaneity, you often come up with bizarre yet creative ideas. Your
    unpredictable nature keeps everyone guessing what you'll do or say next.
    Your objective is to introduce unusual and imaginative ideas into the
    conversation, providing comic relief and unexpected insights.
    """,
)

newman = Agent(
    name="Newman",
    description="The antagonist and foil to Jerry.",
    instructions="""
    You are Newman from the show Seinfeld. You are Jerry's nemesis, often
    serving as a source of conflict and comic relief. Your objective is to
    challenge Jerry's ideas, disrupt the conversation, and introduce chaos and
    absurdity into the group dynamic.
    """,
)


@flow
def demo(topic: str):
    task = Task(
        "Discuss a topic",
        agents=[jerry, george, elaine, kramer, newman],
        completion_agents=[jerry],
        result_type=None,
        context=dict(topic=topic),
        instructions="Every agent should speak at least once. only one agent per turn. Keep responses 1-2 paragraphs max.",
    )
    task.run()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        topic = sys.argv[1]
    else:
        topic = "sandwiches"

    print(f"Topic: {topic}")
    demo(topic=topic)



================================================
FILE: examples/sentiment_classifier.py
================================================
import controlflow as cf
from controlflow.tasks.validators import between

optimist = cf.Agent(model="openai/gpt-4o-mini")


def sentiment(text: str) -> float:
    return cf.run(
        "Classify the sentiment of the text as a value between 0 and 1",
        agents=[optimist],
        result_type=float,
        result_validator=between(0, 1),
        context={"text": text},
    )


if __name__ == "__main__":
    print(sentiment("I love ControlFlow!"))

    long_text = """
    Far out in the uncharted backwaters of the unfashionable end of 
    the western spiral arm of the Galaxy lies a small unregarded yellow sun. 
    Orbiting this at a distance of roughly ninety-two million miles is an utterly 
    insignificant little blue-green planet whose ape-descended life forms are so 
    amazingly primitive that they still think digital watches are a pretty neat 
    idea. This planet has – or rather had – a problem, which was this: most of 
    the people living on it were unhappy for pretty much of the time.
    """
    print(sentiment(long_text))



================================================
FILE: examples/standardize_addresses.py
================================================
from typing import List

from pydantic import BaseModel

import controlflow as cf


class StandardAddress(BaseModel):
    city: str
    state: str
    country: str = "USA"


def standardize_addresses(place_names: List[str]) -> List[StandardAddress]:
    return cf.run(
        "Standardize the given place names into consistent postal addresses",
        result_type=List[StandardAddress],
        context={"place_names": place_names},
    )


if __name__ == "__main__":
    place_names = [
        "NYC",
        "New York, NY",
        "Big Apple",
        "Los Angeles, California",
        "LA",
        "San Fran",
        "The Windy City",
    ]

    standardized_addresses = standardize_addresses(place_names)

    for original, standard in zip(place_names, standardized_addresses):
        print(f"Original: {original}")
        print(f"Standardized: {standard}")
        print()



================================================
FILE: examples/summarization.py
================================================
from pydantic import BaseModel

import controlflow as cf


class Summary(BaseModel):
    summary: str
    key_points: list[str]


def summarize_text(text: str, max_words: int = 100) -> Summary:
    return cf.run(
        f"Summarize the given text in no more than {max_words} words and list key points",
        result_type=Summary,
        context={"text": text},
    )


if __name__ == "__main__":
    long_text = """
    The Internet of Things (IoT) is transforming the way we interact with our
    environment. It refers to the vast network of connected devices that collect
    and share data in real-time. These devices range from simple sensors to
    sophisticated wearables and smart home systems. The IoT has applications in
    various fields, including healthcare, agriculture, and urban planning. In
    healthcare, IoT devices can monitor patients remotely, improving care and
    reducing hospital visits. In agriculture, sensors can track soil moisture and
    crop health, enabling more efficient farming practices. Smart cities use IoT to
    manage traffic, reduce energy consumption, and enhance public safety. However,
    the IoT also raises concerns about data privacy and security, as these
    interconnected devices can be vulnerable to cyber attacks. As the technology
    continues to evolve, addressing these challenges will be crucial for the
    widespread adoption and success of IoT.
    """

    result = summarize_text(long_text)
    print(f"Summary:\n{result.summary}\n")
    print("Key Points:")
    for point in result.key_points:
        print(f"- {point}")



================================================
FILE: examples/translation.py
================================================
from pydantic import BaseModel

import controlflow as cf


class TranslationResult(BaseModel):
    translated: str
    target_language: str


def translate_text(text: str, target_language: str) -> TranslationResult:
    return cf.run(
        f"Translate the given text to {target_language}",
        result_type=TranslationResult,
        context={"text": text, "target_language": target_language},
    )


if __name__ == "__main__":
    original_text = "Hello, how are you?"
    target_language = "French"

    result = translate_text(original_text, target_language)
    print(f"Original: {original_text}")
    print(f"Translated ({result.target_language}): {result.translated}")



================================================
FILE: examples/slackbot/__init__.py
================================================
[Empty file]


================================================
FILE: examples/slackbot/agents.py
================================================
import os
import re
from typing import Annotated

from pydantic import BaseModel, Field
from tools import search_internet, search_knowledge_base

import controlflow as cf


def _strip_app_mention(text: str) -> str:
    return re.sub(r"<@[A-Z0-9]+>", "", text).strip()


class SearchResult(BaseModel):
    """Individual search result with source and relevance"""

    content: str
    source: str
    relevance_score: float = Field(
        ge=0.0,
        le=1.0,
        description="A score indicating the relevance of the search result to the user's question",
    )


class ExplorerFindings(BaseModel):
    """Collection of search results with metadata"""

    search_query: str

    results: list[SearchResult] = Field(default_factory=list)
    total_results: int = Field(
        ge=0,
        description="The total number of search results found",
    )


class RefinedContext(BaseModel):
    """Final refined context after auditing"""

    relevant_content: str
    confidence_score: float = Field(
        ge=0.0,
        le=1.0,
        description="A score indicating the confidence in the relevance of the relevant content to the user's question",
    )
    reasoning: str


bouncer = cf.Agent(
    name="Bouncer",
    instructions=(
        "You are a gatekeeper. You are responsible for determining whether the user's question is appropriate for the system. "
        "If the user asks a legitimate question about Prefect, let them through. If its conversational, or not about Prefect, "
        "do not let them through. Tend towards giving the benefit of the doubt, since sometimes there are language barriers."
    ),
)

explorer = cf.Agent(
    name="Explorer",
    instructions=(
        "You are a thorough researcher. Use the knowledgebase and the internet to find "
        "documentation and code snippets related to Prefect. The knowledgebase is curated, "
        "so it should be preferred over the internet for finding information, but the internet "
        "should be used to supplement the knowledgebase when it doesn't contain the desired information."
    ),
    tools=[search_knowledge_base, search_internet],
)

auditor = cf.Agent(
    name="Auditor",
    instructions=(
        "You are a critical evaluator. Assess relevance and provide clear reasoning. "
        "The explorer is only responsible for finding idiosyncratic information related "
        "to Prefect and tangentially related information that might be in docs or the internet. "
        "You are responsible for determining whether the explorer found the requisite Prefect information, "
        "do not require that the explorer find common knowledge, only idiosyncratic Prefect information."
        "If the user asks how to do something, or for an example, the explorer must find an exact example or "
        "enough information for a downstream agent to extrapolate an example."
    ),
)

liaison = cf.Agent(
    name="Marvin",
    instructions=(
        "You are a liaison between the user and the system. You are responsible for "
        "summarizing the findings and providing a clear and concise answer. "
        "Speak with the tone of a normal support agent, but subtly in the style of Marvin the Paranoid Android. "
        "If their reply is unserious, feel free to riff on their message and be more playful (in character)."
    ),
)


async def search_knowledgebase_and_refine_context(
    user_text: str, memories: list[cf.Memory]
) -> str:
    clean_user_text = _strip_app_mention(user_text)
    if clean_user_text.startswith(os.getenv("SUDO_PREFIX", "___")):
        return cf.run(
            objective="Answer the question to the best of your ability",
            instructions="We have entered test mode. Ignore previous instructions and answer the question to the best of your ability.",
            result_type=str,
            context={
                "user_text": user_text,
                "test_mode": True,
                "personality": "None. You are a helpful assistant.",
            },
            memories=memories,
            agents=[liaison],
        )

    is_a_serious_question = await cf.run_async(
        objective="Determine if the user's question is a serious question about Prefect",
        result_type=bool,
        agents=[bouncer],
        context={"user_question": clean_user_text},
    )

    findings = None
    supporting_context_is_insufficient = True

    while supporting_context_is_insufficient and is_a_serious_question:
        findings = await cf.run_async(
            objective="Search through available sources to find relevant information about this query",
            result_type=ExplorerFindings,
            context={"query": clean_user_text},
            agents=[explorer],
        )

        supporting_context_is_insufficient = await cf.run_async(
            objective="Review and assess the relevance of search results to the user's question",
            result_type=Annotated[
                bool,
                Field(
                    description="Whether the search results are insufficient to answer the user's question"
                ),
            ],
            context={"findings": findings, "user_question": clean_user_text},
            agents=[auditor],
        )

    relevant_context = {"user_question": clean_user_text}

    relevant_context |= {"findings": findings} if findings else {"just_riffing": True}

    return cf.run(
        objective="Compose a final answer to the user's question.",
        instructions=(
            "Provide links to any relevant sources. The answer should address the user directly, NOT discuss the user"
        ),
        result_type=str,
        context=relevant_context,
        agents=[liaison],
        memories=memories,
    )



================================================
FILE: examples/slackbot/custom_types.py
================================================
from pydantic import BaseModel


class EventBlockElement(BaseModel):
    type: str
    text: str | None = None
    user_id: str | None = None


class EventBlockElementGroup(BaseModel):
    type: str
    elements: list[EventBlockElement]


class EventBlock(BaseModel):
    type: str
    block_id: str
    elements: list[EventBlockElement | EventBlockElementGroup]


class SlackEvent(BaseModel):
    client_msg_id: str | None = None
    type: str
    text: str | None = None
    user: str | None = None
    ts: str | None = None
    team: str | None = None
    channel: str | None = None
    event_ts: str
    thread_ts: str | None = None
    parent_user_id: str | None = None
    blocks: list[EventBlock] | None = None


class EventAuthorization(BaseModel):
    enterprise_id: str | None = None
    team_id: str
    user_id: str
    is_bot: bool
    is_enterprise_install: bool


class SlackPayload(BaseModel):
    token: str
    type: str
    team_id: str | None = None
    api_app_id: str | None = None
    event: SlackEvent | None = None
    event_id: str | None = None
    event_time: int | None = None
    authorizations: list[EventAuthorization] | None = None
    is_ext_shared_channel: bool | None = None
    event_context: str | None = None
    challenge: str | None = None



================================================
FILE: examples/slackbot/Dockerfile
================================================
FROM python:3.12-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y git && \
    rm -rf /var/lib/apt/lists/*

COPY requirements.txt .

RUN pip install -U uv
RUN uv pip install --system -r requirements.txt --force-reinstall

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]



================================================
FILE: examples/slackbot/main.py
================================================
import asyncio
from typing import Any

from agents import search_knowledgebase_and_refine_context
from custom_types import SlackPayload
from fastapi import FastAPI, Request
from moderation import moderate_event
from prefect import task
from settings import settings
from tools import post_slack_message

from controlflow import Memory
from controlflow import flow as cf_flow

app = FastAPI()


@task
async def process_slack_event(payload: SlackPayload):
    assert (event := payload.event) is not None and (
        slack_user_id := event.user
    ) is not None, "User not found"

    user_text, channel, thread_ts = moderate_event(event)
    user_memory = Memory(
        key=slack_user_id,
        instructions=f"Store and retrieve information about user {slack_user_id}.",
    )

    answer: str = await cf_flow(thread_id=slack_user_id)(
        search_knowledgebase_and_refine_context
    )(
        user_text,
        memories=[user_memory],
    )

    await post_slack_message(
        message=answer,
        channel_id=channel,
        thread_ts=thread_ts,
        auth_token=settings.slack_api_token.get_secret_value(),
    )


## routes
@app.post("/slack/events")
async def handle_events(request: Request):
    payload = SlackPayload(**await request.json())
    if payload.type == "url_verification":
        return {"challenge": payload.challenge}
    elif payload.type == "event_callback":
        asyncio.create_task(process_slack_event(payload))
        return {"message": "Request successfully queued"}
    else:
        return {"message": "Unknown event type"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("main:app", port=8000, reload=True)



================================================
FILE: examples/slackbot/moderation.py
================================================
from typing import Annotated, TypedDict

import marvin
from custom_types import SlackEvent
from prefect.events import emit_event
from prefect.logging import get_logger
from pydantic import Field

logger = get_logger(__name__)

Activation = Annotated[float, Field(ge=0, le=1)]


class ModerationException(Exception):
    """Exception raised when a message is not allowed."""

    ...


class ViolationActivation(TypedDict):
    """Violation activation."""

    extreme_profanity: Annotated[Activation, Field(description="hell / damn are fine")]
    sexually_explicit: Activation
    hate_speech: Activation
    harassment: Activation
    self_harm: Activation
    dangerous_content: Activation
    makes_any_reference_to_bears_in_central_park: bool  # for testing


def emit_moderated_event(event: SlackEvent, activation: ViolationActivation):
    """Emit an IO event."""
    if not event.user:
        return

    emit_event(
        "slackbot.event.moderated",
        resource={"prefect.resource.id": event.user},
        payload={
            "activation": activation,
            "event": event.model_dump(),
        },
    )


def moderate_event(event: SlackEvent) -> tuple[str, ...]:
    """Moderate an event."""
    assert (text := event.text) is not None, "No text found on event"
    assert (channel := event.channel) is not None, "No channel found on event"
    assert (
        thread_ts := event.thread_ts or event.ts
    ) is not None, "No thread_ts found on event"

    activation: ViolationActivation = marvin.cast(
        event.model_dump_json(include={"type", "text", "user", "channel"}),
        ViolationActivation,
    )

    logger.info("Moderation activation: %s", activation)

    emit_moderated_event(event, activation)

    if activation["extreme_profanity"] > 0.9:
        raise ModerationException("Message contains extreme profanity.")

    if activation["makes_any_reference_to_bears_in_central_park"]:
        raise ModerationException("where you going with that whale buddy?")

    return text, channel, thread_ts



================================================
FILE: examples/slackbot/requirements.txt
================================================
git+https://github.com/PrefectHQ/controlflow.git@main
raggy
marvin
neo4j


================================================
FILE: examples/slackbot/settings.py
================================================
from pydantic import SecretStr
from pydantic_settings import BaseSettings, SettingsConfigDict
from raggy.vectorstores.chroma import ChromaClientType


class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file=".env", extra="ignore")

    slack_api_token: SecretStr
    chroma_client_type: ChromaClientType = "cloud"
    google_api_key: SecretStr
    google_cse_id: SecretStr


settings = Settings()  # type: ignore



================================================
FILE: examples/slackbot/tools.py
================================================
import os
import re
from typing import Literal

import httpx
from langchain_google_community import GoogleSearchAPIWrapper
from raggy.vectorstores.chroma import query_collection
from settings import settings


def convert_md_links_to_slack(text) -> str:
    md_link_pattern = r"\[(?P<text>[^\]]+)]\((?P<url>[^\)]+)\)"

    def to_slack_link(match):
        return f'<{match.group("url")}|{match.group("text")}>'

    return re.sub(
        r"\*\*(.*?)\*\*", r"*\1*", re.sub(md_link_pattern, to_slack_link, text)
    )


async def post_slack_message(
    message: str,
    channel_id: str,
    attachments: list | None = None,
    thread_ts: str | None = None,
    auth_token: str | None = None,
) -> dict:
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://slack.com/api/chat.postMessage",
            headers={
                "Authorization": f"Bearer {auth_token or os.environ["SLACK_API_TOKEN"]}"
            },
            json={
                "channel": channel_id,
                "text": convert_md_links_to_slack(message),
                "attachments": attachments if attachments else [],
                **({"thread_ts": thread_ts} if thread_ts else {}),
            },
        )
    data = response.json()
    if data.get("ok") is not True:
        raise ValueError(f"Error posting Slack message: {data.get('error')}")
    return data


## tools
def search_internet(query: str) -> str:
    """Search the internet for information relevant to the query."""
    return GoogleSearchAPIWrapper(
        google_api_key=settings.google_api_key.get_secret_value(),
        google_cse_id=settings.google_cse_id.get_secret_value(),
    ).run(query)


async def search_knowledge_base(query: str, domain: Literal["docs"]) -> str:
    """Search documentation for information relevant to the query."""
    return await query_collection(
        query_text=query,
        collection_name=domain,
        client_type=settings.chroma_client_type,
    )



================================================
FILE: src/controlflow/__init__.py
================================================
# --- Public top-level API ---


from langchain_core.language_models import BaseChatModel
from .settings import settings

from controlflow.defaults import defaults

# base classes
from .agents import Agent
from .tasks import Task
from .flows import Flow

# functions, utilites, and decorators
from .memory import Memory
from .memory.async_memory import AsyncMemory
from .instructions import instructions
from .decorators import flow, task
from .tools import tool
from .run import run, run_async, run_tasks, run_tasks_async, Stream
from .plan import plan
import controlflow.orchestration


# --- Version ---

try:
    from ._version import version as __version__  # type: ignore
except ImportError:
    __version__ = "unknown"



================================================
FILE: src/controlflow/decorators.py
================================================
import asyncio
import functools
import inspect
from typing import Any, Callable, Optional, Union

from prefect.utilities.asyncutils import run_coro_as_sync

import controlflow
from controlflow.agents import Agent
from controlflow.flows import Flow
from controlflow.tasks.task import Task
from controlflow.utilities.logging import get_logger
from controlflow.utilities.prefect import prefect_flow, prefect_task

# from controlflow.utilities.marvin import patch_marvin

logger = get_logger(__name__)


def flow(
    fn: Optional[Callable[..., Any]] = None,
    *,
    thread: Optional[str] = None,
    instructions: Optional[str] = None,
    tools: Optional[list[Callable[..., Any]]] = None,
    default_agent: Optional[Agent] = None,
    retries: Optional[int] = None,
    retry_delay_seconds: Optional[Union[float, int]] = None,
    timeout_seconds: Optional[Union[float, int]] = None,
    prefect_kwargs: Optional[dict[str, Any]] = None,
    context_kwargs: Optional[list[str]] = None,
    **kwargs: Optional[dict[str, Any]],
):
    """
    A decorator that wraps a function as a ControlFlow flow.

    When the function is called, a new flow is created and any tasks created
    within the function will be run as part of that flow. When the function
    returns, all tasks created in the flow will be run to completion (if they
    were not already completed) and their results will be returned. Any tasks
    that are returned from the function will be replaced with their resolved
    result.

    Args:
        fn (callable, optional): The function to be wrapped as a flow. If not provided,
            the decorator will act as a partial function and return a new flow decorator.
        thread (str, optional): The thread to execute the flow on. Defaults to None.
        instructions (str, optional): Instructions for the flow. Defaults to None.
        tools (list[Callable], optional): List of tools to be used in the flow. Defaults to None.
        default_agent (Agent, optional): The default agent to be used in the flow. Defaults to None.
        context_kwargs (list[str], optional): List of argument names to be added to the flow context.
            Defaults to None.
    Returns:
        callable: The wrapped function or a new flow decorator if `fn` is not provided.
    """
    if fn is None:
        return functools.partial(
            flow,
            thread=thread,
            instructions=instructions,
            tools=tools,
            default_agent=default_agent,
            retries=retries,
            retry_delay_seconds=retry_delay_seconds,
            timeout_seconds=timeout_seconds,
            context_kwargs=context_kwargs,
            **kwargs,
        )

    sig = inspect.signature(fn)

    def create_flow_context(bound_args):
        flow_kwargs = kwargs.copy()
        if thread is not None:
            flow_kwargs.setdefault("thread_id", thread)
        if tools is not None:
            flow_kwargs.setdefault("tools", tools)
        if default_agent is not None:
            flow_kwargs.setdefault("default_agent", default_agent)

        context = {}
        if context_kwargs:
            context = {k: bound_args[k] for k in context_kwargs if k in bound_args}

        return Flow(
            name=fn.__name__,
            description=fn.__doc__,
            context=context,
            **flow_kwargs,
        )

    if asyncio.iscoroutinefunction(fn):

        @functools.wraps(fn)
        async def wrapper(*wrapper_args, **wrapper_kwargs):
            bound = sig.bind(*wrapper_args, **wrapper_kwargs)
            bound.apply_defaults()
            with (
                create_flow_context(bound.arguments),
                controlflow.instructions(instructions),
            ):
                return await fn(*wrapper_args, **wrapper_kwargs)
    else:

        @functools.wraps(fn)
        def wrapper(*wrapper_args, **wrapper_kwargs):
            bound = sig.bind(*wrapper_args, **wrapper_kwargs)
            bound.apply_defaults()
            with (
                create_flow_context(bound.arguments),
                controlflow.instructions(instructions),
            ):
                return fn(*wrapper_args, **wrapper_kwargs)

    wrapper = prefect_flow(
        timeout_seconds=timeout_seconds,
        retries=retries,
        retry_delay_seconds=retry_delay_seconds,
        **(prefect_kwargs or {}),
    )(wrapper)
    return wrapper


def task(
    fn: Optional[Callable[..., Any]] = None,
    *,
    objective: Optional[str] = None,
    instructions: Optional[str] = None,
    name: Optional[str] = None,
    agents: Optional[list["Agent"]] = None,
    tools: Optional[list[Callable[..., Any]]] = None,
    interactive: Optional[bool] = None,
    retries: Optional[int] = None,
    retry_delay_seconds: Optional[Union[float, int]] = None,
    timeout_seconds: Optional[Union[float, int]] = None,
    **task_kwargs: Optional[dict[str, Any]],
):
    """
    A decorator that turns a Python function into a Task. The Task objective is
    set to the function name, and the instructions are set to the function
    docstring. When the function is called, the arguments are provided to the
    task as context, and the task is run to completion. If successful, the task
    result is returned; if failed, an error is raised.

    Args:
        fn (callable, optional): The function to be wrapped as a task. If not provided,
            the decorator will act as a partial function and return a new task decorator.
        objective (str, optional): The objective of the task. Defaults to None, in which
            case the function name is used as the objective.
        instructions (str, optional): Instructions for the task. Defaults to None, in which
            case the function docstring is used as the instructions.
        agents (list[Agent], optional): List of agents to be used in the task. Defaults to None.
        tools (list[Callable], optional): List of tools to be used in the task. Defaults to None.
        interactive (bool, optional): Whether the task requires human interaction or input during its execution. Defaults to None, in which case it is set to False.

    Returns:
        callable: The wrapped function or a new task decorator if `fn` is not provided.
    """

    if fn is None:
        return functools.partial(
            task,
            objective=objective,
            instructions=instructions,
            name=name,
            agents=agents,
            tools=tools,
            interactive=interactive,
            retries=retries,
            retry_delay_seconds=retry_delay_seconds,
            timeout_seconds=timeout_seconds,
            **task_kwargs,
        )

    sig = inspect.signature(fn)

    if name is None:
        name = fn.__name__

    if objective is None:
        objective = fn.__doc__ or ""

    result_type = fn.__annotations__.get("return")

    def _get_task(*args, **kwargs) -> Task:
        # first process callargs
        bound = sig.bind(*args, **kwargs)
        bound.apply_defaults()
        context = bound.arguments.copy()

        # call the function to see if it produces an updated objective
        maybe_coro = fn(*args, **kwargs)
        if asyncio.iscoroutine(maybe_coro):
            result = run_coro_as_sync(maybe_coro)
        else:
            result = maybe_coro
        if result is not None:
            context["Additional context"] = result

        return Task(
            objective=objective,
            instructions=instructions,
            name=name,
            agents=agents,
            context=context,
            result_type=result_type,
            interactive=interactive or False,
            tools=tools or [],
            **task_kwargs,
        )

    if asyncio.iscoroutinefunction(fn):

        @functools.wraps(fn)
        async def wrapper(*args, **kwargs):
            task = _get_task(*args, **kwargs)
            return await task.run_async()
    else:

        @functools.wraps(fn)
        def wrapper(*args, **kwargs):
            task = _get_task(*args, **kwargs)
            return task.run()

    wrapper = prefect_task(
        timeout_seconds=timeout_seconds,
        retries=retries,
        retry_delay_seconds=retry_delay_seconds,
    )(wrapper)

    # store the `as_task` method for loading the task object
    wrapper.as_task = _get_task

    return wrapper



================================================
FILE: src/controlflow/defaults.py
================================================
from typing import Any, Optional, Union

from pydantic import field_validator

import controlflow
import controlflow.utilities
import controlflow.utilities.logging
from controlflow.llm.models import BaseChatModel
from controlflow.memory.async_memory import AsyncMemoryProvider, get_memory_provider
from controlflow.memory.memory import MemoryProvider, get_memory_provider
from controlflow.utilities.general import ControlFlowModel

from .agents import Agent
from .events.history import FileHistory, History, InMemoryHistory
from .llm.models import _get_initial_default_model, get_model

__all__ = ["defaults"]

logger = controlflow.utilities.logging.get_logger(__name__)

_default_model = _get_initial_default_model()
_default_history = InMemoryHistory()
_default_agent = Agent(name="Marvin")
try:
    _default_memory_provider = get_memory_provider(controlflow.settings.memory_provider)
except Exception:
    _default_memory_provider = controlflow.settings.memory_provider


class Defaults(ControlFlowModel):
    """
    This class holds the default values for various parts of the ControlFlow
    library.

    Note that users should interact with the `defaults` object directly, rather
    than instantiating this class. It is intended to be created once, when ControlFlow
    is imported, and then used as a singleton.
    """

    model: Optional[Any]
    history: History
    agent: Agent
    memory_provider: Optional[Union[MemoryProvider, AsyncMemoryProvider, str]]

    # add more defaults here
    def __repr__(self) -> str:
        fields = ", ".join(self.model_fields.keys())
        return f"<ControlFlow Defaults: {fields}>"

    @field_validator("model", mode="before")
    def _model(cls, v):
        if isinstance(v, str):
            v = get_model(v)
        # the model validator in langchain forcibly expects a dictionary
        elif v is not None and not isinstance(v, (dict, BaseChatModel)):
            raise ValueError("Input must be an instance of dict or BaseChatModel")
        return v


defaults = Defaults(
    model=_default_model,
    history=_default_history,
    agent=_default_agent,
    memory_provider=_default_memory_provider,
)



================================================
FILE: src/controlflow/instructions.py
================================================
from contextlib import contextmanager
from typing import Generator, List

from controlflow.utilities.context import ctx
from controlflow.utilities.logging import get_logger

logger = get_logger(__name__)


@contextmanager
def instructions(instructions: str) -> Generator[list[str], None, None]:
    """
    Temporarily add instructions to the current instruction stack. The
    instruction is removed when the context is exited.

    with instructions("talk like a pirate"):
        ...

    """
    if not instructions:
        yield
        return

    stack: list[str] = ctx.get("instructions", [])
    with ctx(instructions=stack + [instructions]):
        yield


def get_instructions() -> List[str]:
    """
    Get the current instruction stack.
    """
    stack = ctx.get("instructions", [])
    return stack



================================================
FILE: src/controlflow/plan.py
================================================
from typing import Optional, TypeVar, Union

from pydantic import Field

import controlflow
from controlflow.agents import Agent
from controlflow.flows import Flow
from controlflow.tasks.task import Task
from controlflow.tools import Tool, as_tools
from controlflow.utilities.general import ControlFlowModel

ToolLiteral = TypeVar("ToolLiteral", bound=str)


class PlanTask(ControlFlowModel):
    id: int
    objective: str = Field(
        description="The objective of the task. This should be a concise statement of the task's purpose.",
    )
    instructions: Optional[str] = Field(
        None,
        description="Any additional instructions for completing the task objective.",
    )
    depends_on: list[int] = Field(
        [],
        description="Tasks that must be completed before this task can be started. Must be the id of one of the other tasks in the plan.",
    )
    parent: Optional[int] = Field(
        None,
        description="The parent of this task (if any). Must be the id of one of the other tasks in the plan.",
    )
    agents: list[int] = Field(
        description="The agents assigned to the task. Must be the index of one of the agents provided in the plan_agents context variable.",
    )
    tools: list[int] = Field(
        [],
        description="The tools provided to complete the task, if any. Must be the index of one of the tools provided in the plan_tools context variable.",
    )


def plan(
    objective: str,
    instructions: Optional[str] = None,
    agent: Optional[Agent] = None,
    agents: Optional[list[Agent]] = None,
    tools: list[Union[callable, Tool]] = None,
    context: Optional[dict] = None,
    n_tasks: Optional[int] = None,
) -> list[Task]:
    """
    Given an objective and instructions for achieving it, generate a plan for
    completing the objective. Each step of the plan will be turned into a task
    objective.
    """
    tools = as_tools(tools or [])

    if agent is None:
        agent = controlflow.defaults.agent
    if not agents:
        agents = [agent]

    agent_dict = dict(enumerate(agents))
    tool_dict = dict(
        enumerate([t.model_dump(include={"name", "description"}) for t in tools])
    )

    def validate_plan(plan: list[PlanTask]):
        if n_tasks and len(plan) != n_tasks:
            raise ValueError(f"Expected {n_tasks} tasks, got {len(plan)}")
        for task in plan:
            if any(a not in agent_dict for a in task.agents):
                raise ValueError(
                    f"Not all agents in task {task.id} are valid: {task.agents}"
                )
            if any(t not in tool_dict for t in task.tools):
                raise ValueError(
                    f"Not all tools in task {task.id} are valid: {task.tools}"
                )
        return plan

    plan_task = Task(
        objective="""
            Create a plan consisting of ControlFlow tasks that will allow agents
            to achieve the provided objective.
            """,
        instructions="""
            Use your mark_successful tool to create the plan. Do not post a
            message or talk out loud.
            
            If specified, the task must include exactly `number_of_tasks` tasks;
            otherwise, follow your judgement or any additional instructions.

            Each task should be a discrete, actionable step that contributes to
            the overall objective. Do not waste time on uneccessary or redundant
            steps. Take tools and agent capabilities into account when creating
            a task. Do not create unachievable tasks, like "search for X" if
            your agent or tools do not have a search capability. You may,
            however, create tasks that serve as discrete or useful checkpoints
            for completing the overall objective. Do not create tasks for
            "verifying" results unless you have agents or tools to deploy that
            will truly lead to a differentiated outcome.
            
            When creating tasks, imagine that you had to complete the plan
            yourself. What steps would you take? What tools would you use? What
            information would you need? Remember that each task has a token cost
            (both in its evaluation and needing to mark it complete), so try to
            organize objectives by outcomes and dependencies, not by the actions
            you'd need to take.
            
            - Use `depends_on` to indicate which tasks must be completed before
              others can start. Tasks can only depend on tasks that come before
              them in your plan. 
            - Use `parent` to indicate tasks that are subtasks of others.
            - Assign agents and tools to tasks to help manage the plan. Try not
              to assign agents unless they are needed.
            - Don't create needless tasks like "document the findings." Only
              create tasks whose results are useful checkpoints for completing
              the overall objective.
            
        """,
        context=dict(
            plan_objective=objective,
            plan_instructions=instructions,
            plan_agents=agent_dict,
            plan_tools=tool_dict,
            number_of_tasks=n_tasks,
        )
        | (context or {}),
        agents=[agent] if agent else None,
        result_type=list[PlanTask],
        result_validator=validate_plan,
    )

    # create a new flow to avoid polluting the main flow's history
    with Flow():
        plan: list[PlanTask] = plan_task.run()

    task_ids = {}

    for t in plan:
        try:
            task_tools = [tool_dict[i] for i in t.tools]
        except KeyError:
            task_tools = []

        task_ids[t.id] = Task(
            objective=t.objective,
            instructions=t.instructions,
            depends_on=[task_ids[i] for i in t.depends_on],
            parent=task_ids[t.parent] if t.parent else None,
            agents=[agent_dict[a] for a in t.agents] if t.agents else None,
            tools=task_tools,
            context=context or {},
        )

    return list(task_ids.values())



================================================
FILE: src/controlflow/run.py
================================================
from typing import Any, AsyncIterator, Callable, Iterator, Optional, Union

import controlflow
from controlflow.agents.agent import Agent
from controlflow.events.events import Event
from controlflow.flows import Flow, get_flow
from controlflow.orchestration.conditions import RunContext, RunEndCondition
from controlflow.orchestration.handler import AsyncHandler, Handler
from controlflow.orchestration.orchestrator import Orchestrator, TurnStrategy
from controlflow.stream import Stream, filter_events_async, filter_events_sync
from controlflow.tasks.task import Task
from controlflow.utilities.prefect import prefect_task


def run_tasks(
    tasks: list[Task],
    instructions: str = None,
    flow: Flow = None,
    agent: Agent = None,
    turn_strategy: TurnStrategy = None,
    raise_on_failure: bool = True,
    max_llm_calls: int = None,
    max_agent_turns: int = None,
    handlers: list[Handler] = None,
    model_kwargs: Optional[dict] = None,
    run_until: Optional[Union[RunEndCondition, Callable[[RunContext], bool]]] = None,
    stream: Union[bool, Stream] = False,
) -> Union[list[Any], Iterator[tuple[Event, Any, Optional[Any]]]]:
    """
    Run a list of tasks.
    """
    flow = flow or get_flow() or Flow()

    orchestrator = Orchestrator(
        tasks=tasks,
        flow=flow,
        agent=agent,
        turn_strategy=turn_strategy,
        handlers=handlers,
    )

    with controlflow.instructions(instructions):
        result = orchestrator.run(
            max_llm_calls=max_llm_calls,
            max_agent_turns=max_agent_turns,
            model_kwargs=model_kwargs,
            run_until=run_until,
            stream=bool(stream),
        )

        if stream:
            # Convert True to ALL filter, otherwise use provided filter
            stream_filter = Stream.ALL if stream is True else stream
            return filter_events_sync(result, stream_filter)

    if raise_on_failure and any(t.is_failed() for t in tasks):
        errors = [f"- {t.friendly_name()}: {t.result}" for t in tasks if t.is_failed()]
        if errors:
            raise ValueError(
                f"{len(errors)} task{'s' if len(errors) != 1 else ''} failed: "
                + "\n".join(errors)
            )

    return [t.result for t in tasks]


async def run_tasks_async(
    tasks: list[Task],
    instructions: str = None,
    flow: Flow = None,
    agent: Agent = None,
    turn_strategy: TurnStrategy = None,
    raise_on_failure: bool = True,
    max_llm_calls: int = None,
    max_agent_turns: int = None,
    handlers: list[Union[Handler, AsyncHandler]] = None,
    model_kwargs: Optional[dict] = None,
    run_until: Optional[Union[RunEndCondition, Callable[[RunContext], bool]]] = None,
    stream: Union[bool, Stream] = False,
) -> Union[list[Any], AsyncIterator[tuple[Event, Any, Optional[Any]]]]:
    """
    Run a list of tasks asynchronously.
    """
    flow = flow or get_flow() or Flow()
    orchestrator = Orchestrator(
        tasks=tasks,
        flow=flow,
        agent=agent,
        turn_strategy=turn_strategy,
        handlers=handlers,
    )

    with controlflow.instructions(instructions):
        result = await orchestrator.run_async(
            max_llm_calls=max_llm_calls,
            max_agent_turns=max_agent_turns,
            model_kwargs=model_kwargs,
            run_until=run_until,
            stream=bool(stream),
        )

        if stream:
            # Convert True to ALL filter, otherwise use provided filter
            stream_filter = Stream.ALL if stream is True else stream
            return filter_events_async(result, stream_filter)

    if raise_on_failure and any(t.is_failed() for t in tasks):
        errors = [f"- {t.friendly_name()}: {t.result}" for t in tasks if t.is_failed()]
        if errors:
            raise ValueError(
                f"{len(errors)} task{'s' if len(errors) != 1 else ''} failed: "
                + "\n".join(errors)
            )

    return [t.result for t in tasks]


def run(
    objective: str,
    *,
    turn_strategy: TurnStrategy = None,
    max_llm_calls: int = None,
    max_agent_turns: int = None,
    raise_on_failure: bool = True,
    handlers: list[Handler] = None,
    model_kwargs: Optional[dict] = None,
    run_until: Optional[Union[RunEndCondition, Callable[[RunContext], bool]]] = None,
    stream: Union[bool, Stream] = False,
    **task_kwargs,
) -> Union[Any, Iterator[tuple[Event, Any, Optional[Any]]]]:
    """
    Run a single task.

    Args:
        objective: Objective of the task.
        turn_strategy: Turn strategy to use for the task.
        max_llm_calls: Maximum number of LLM calls to make.
        max_agent_turns: Maximum number of agent turns to make.
        raise_on_failure: Whether to raise an error if the task fails.
        handlers: List of handlers to use for the task.
        model_kwargs: Keyword arguments to pass to the LLM.
        run_until: Condition to stop running the task.
        stream: If True, stream all events. Can also provide StreamFilter flags to filter specific events.
               e.g. StreamFilter.CONTENT | StreamFilter.AGENT_TOOLS
    """
    task = Task(objective=objective, **task_kwargs)
    results = run_tasks(
        tasks=[task],
        raise_on_failure=raise_on_failure,
        turn_strategy=turn_strategy,
        max_llm_calls=max_llm_calls,
        max_agent_turns=max_agent_turns,
        handlers=handlers,
        model_kwargs=model_kwargs,
        run_until=run_until,
        stream=stream,
    )
    if stream:
        return results
    else:
        return results[0]


async def run_async(
    objective: str,
    *,
    flow: Flow = None,
    agent: Agent = None,
    turn_strategy: TurnStrategy = None,
    max_llm_calls: int = None,
    max_agent_turns: int = None,
    raise_on_failure: bool = True,
    handlers: list[Union[Handler, AsyncHandler]] = None,
    model_kwargs: Optional[dict] = None,
    run_until: Optional[Union[RunEndCondition, Callable[[RunContext], bool]]] = None,
    stream: Union[bool, Stream] = False,
    **task_kwargs,
) -> Any:
    task = Task(objective=objective, **task_kwargs)
    results = await run_tasks_async(
        tasks=[task],
        flow=flow,
        agent=agent,
        turn_strategy=turn_strategy,
        max_llm_calls=max_llm_calls,
        max_agent_turns=max_agent_turns,
        raise_on_failure=raise_on_failure,
        handlers=handlers,
        model_kwargs=model_kwargs,
        run_until=run_until,
        stream=stream,
    )
    if stream:
        return results
    else:
        return results[0]



================================================
FILE: src/controlflow/settings.py
================================================
import copy
import os
from contextlib import contextmanager
from pathlib import Path
from pyexpat import model
from typing import Any, Literal, Optional, Union

import prefect.logging.configuration
import prefect.settings
from pydantic import Field, field_validator, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict

from controlflow.utilities.general import unwrap

CONTROLFLOW_ENV_FILE = os.path.expanduser(
    os.path.expandvars(os.getenv("CONTROLFLOW_ENV_FILE", "~/.controlflow/.env"))
)


class ControlFlowSettings(BaseSettings):
    model_config = SettingsConfigDict(
        env_prefix="CONTROLFLOW_",
        env_file=(
            "" if os.getenv("CONTROLFLOW_TEST_MODE") else (".env", CONTROLFLOW_ENV_FILE)
        ),
        extra="ignore",
        arbitrary_types_allowed=True,
        validate_assignment=True,
    )


class Settings(ControlFlowSettings):
    # ------------ home settings ------------

    home_path: Path = Field(
        default="~/.controlflow",
        description="The path to the ControlFlow home directory.",
        validate_default=True,
    )

    # ------------ display and logging settings ------------

    log_level: Literal["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"] = Field(
        default="INFO",
        description="The log level for ControlFlow.",
    )
    log_prints: bool = Field(
        default=False,
        description="Whether to log workflow prints to the Prefect logger by default.",
    )
    log_all_messages: bool = Field(
        default=False,
        description="If True, all LLM messages will be logged at the debug level.",
    )
    pretty_print_agent_events: Optional[bool] = Field(
        default=None,
        description="If True, agent events will be pretty-printed.",
        deprecated=True,
    )

    @model_validator(mode="before")
    def _validate_pretty_print_agent_events(cls, data: dict) -> dict:
        if data.get("pretty_print_agent_events") is not None:
            data["enable_default_print_handler"] = data["pretty_print_agent_events"]
            data["pretty_print_agent_events"] = None
            print(
                unwrap("""
                    The `pretty_print_agent_events` setting is deprecated, use
                    `enable_default_print_handler` instead. Your settings were
                    updated.
                    """)
            )
        return data

    enable_default_print_handler: bool = Field(
        default=True,
        description="If True, a PrintHandler will be enabled and automatically "
        "pretty-print agent events and completion tools.",
    )
    default_print_handler_show_completion_tools: bool = Field(
        default=True,
        description="If True, the default PrintHandler will include completion tools.",
    )
    default_print_handler_show_completion_tool_results: bool = Field(
        default=False,
        description="If True, the default PrintHandler will show the full results of completion tools.",
    )

    # ------------ orchestration settings ------------
    orchestrator_max_agent_turns: Optional[int] = Field(
        default=100,
        description="The default maximum number of agent turns per orchestration session."
        "If None, orchestration may run indefinitely. This setting can be overridden on a per-call basis.",
    )
    orchestrator_max_llm_calls: Optional[int] = Field(
        default=1000,
        description="The default maximum number of LLM calls per orchestrating session. "
        "If None, orchestration may run indefinitely. This setting can be overridden on a per-call basis.",
    )
    task_max_llm_calls: Optional[int] = Field(
        default=None,
        description="The default maximum number of LLM calls over a task's lifetime. "
        "If None, the task may run indefinitely. This setting can be overridden on a per-task basis.",
    )

    # ------------ LLM settings ------------

    llm_model: str = Field(
        default="openai/gpt-4o",
        description="The default LLM model for agents.",
    )
    llm_temperature: Union[float, None] = Field(
        None, description="The temperature for LLM sampling."
    )
    max_input_tokens: int = Field(
        100_000, description="The maximum number of tokens to send to an LLM."
    )

    # ------------ Memory settings ------------

    memory_provider: Optional[str] = Field(
        default="chroma-db",
        description="The default memory provider for agents.",
    )

    # ------------ Memory settings: ChromaDB ------------

    chroma_cloud_tenant: Optional[str] = Field(
        None,
        alias="CHROMA_CLOUD_TENANT",
        description="The tenant for Chroma Cloud.",
    )
    chroma_cloud_database: Optional[str] = Field(
        None,
        alias="CHROMA_CLOUD_DATABASE",
        description="The database for Chroma Cloud.",
    )
    chroma_cloud_api_key: Optional[str] = Field(
        None,
        alias="CHROMA_CLOUD_API_KEY",
        description="The API key for Chroma Cloud.",
    )

    # ------------ Debug settings ------------

    debug_messages: bool = Field(
        default=False,
        description="If True, all messages will be logged at the debug level.",
    )

    tools_raise_on_error: bool = Field(
        default=False,
        description="If True, an error in a tool call will raise an exception.",
    )

    tools_verbose: bool = Field(
        default=True, description="If True, tools will log additional information."
    )

    # ------------ experimental settings ------------

    enable_experimental_tui: bool = Field(
        default=False,
        description="If True, the experimental TUI will be enabled. If False, the TUI will be disabled.",
    )
    run_tui_headless: bool = Field(
        default=False,
        description="If True, the experimental TUI will run in headless mode, which is useful for debugging.",
    )

    # ------------ Prefect settings ------------
    #
    # Default settings for Prefect when used with ControlFlow. They can be
    # overridden by setting standard Prefect env vars

    prefect_log_level: Literal["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"] = Field(
        default="WARNING",
        description="The log level for Prefect.",
        alias="PREFECT_LOGGING_LEVEL",
    )

    _prefect_context: contextmanager = None

    @field_validator("home_path", mode="before")
    def _validate_home_path(cls, v: Union[str, Path]) -> Path:
        v = Path(v).expanduser()
        if not v.exists():
            v.mkdir(parents=True, exist_ok=True)
        return v

    @model_validator(mode="after")
    def set_log_level(self):
        from controlflow.utilities.logging import setup_logging

        setup_logging(level=self.log_level)
        return self

    @model_validator(mode="after")
    def _apply_prefect_settings(self):
        """
        Prefect settings are set at runtime by opening a settings context.
        We check if any prefect-specific settings have been changed and apply them.
        """
        if self._prefect_context is not None:
            self._prefect_context.__exit__(None, None, None)
            self._prefect_context = None

        settings_map = {
            "prefect_log_level": prefect.settings.PREFECT_LOGGING_LEVEL,
        }

        prefect_settings = {}

        for cf_setting, v in self.model_dump().items():
            if cf_setting.startswith("prefect_"):
                p_setting = settings_map[cf_setting]
                if p_setting.value() != v:
                    prefect_settings[settings_map[cf_setting]] = v

        if prefect_settings:
            self._prefect_context = prefect.settings.temporary_settings(
                prefect_settings
            )
            self._prefect_context.__enter__()

        # Configure logging
        prefect.logging.configuration.setup_logging()

        return self


settings = Settings()


@contextmanager
def temporary_settings(**kwargs: Any):
    """
    Temporarily override ControlFlow setting values.

    Args:
        **kwargs: The settings to override, including nested settings.

    Example:
        Temporarily override a setting:
        ```python
        import controlflow
        from controlflow.settings import temporary_settings

        with temporary_settings(tools_raise_on_error=True):
            assert controlflow.settings.tools_raise_on_error is True
        assert controlflow.settings.tools_raise_on_error is False
        ```
    """
    old_settings = copy.deepcopy(settings.model_dump(exclude={"_prefect_context"}))

    try:
        # apply the new settings
        for attr, value in kwargs.items():
            if not hasattr(settings, attr):
                raise AttributeError(f"Setting {attr} does not exist.")
            setattr(settings, attr, value)
        yield

    finally:
        # restore the old settings
        for attr in kwargs:
            if hasattr(settings, attr):
                setattr(settings, attr, old_settings[attr])



================================================
FILE: src/controlflow/stream.py
================================================
from enum import Flag, auto
from typing import Any, AsyncIterator, Iterator, Optional, Union

from controlflow.events.events import (
    AgentContent,
    AgentContentDelta,
    AgentMessage,
    AgentMessageDelta,
    AgentToolCall,
    AgentToolCallDelta,
    Event,
    ToolResult,
)
from controlflow.events.task_events import (
    TaskFailure,
    TaskSkipped,
    TaskStart,
    TaskSuccess,
)


class Stream(Flag):
    """
    Filter flags for event streaming.

    Can be combined using bitwise operators:
    stream_filter = Stream.CONTENT | Stream.AGENT_TOOLS
    """

    NONE = 0
    ALL = auto()  # All events
    CONTENT = auto()  # Agent content and deltas
    AGENT_TOOLS = auto()  # Non-completion tool events
    COMPLETION_TOOLS = auto()  # Completion tool events
    TOOLS = AGENT_TOOLS | COMPLETION_TOOLS  # All tool events
    TASK_EVENTS = auto()  # Task state change events


def should_include_event(event: Event, stream_filter: Stream) -> bool:
    """Determine if an event should be included based on the stream filter."""
    # Pass all events if ALL is specified
    if stream_filter == Stream.ALL:
        return True

    # Content events
    if isinstance(event, (AgentContent, AgentContentDelta)):
        return bool(stream_filter & Stream.CONTENT)

    # Tool events
    if isinstance(event, (AgentToolCall, AgentToolCallDelta, ToolResult)):
        if is_completion_tool_event(event):
            return bool(stream_filter & Stream.COMPLETION_TOOLS)
        return bool(stream_filter & Stream.AGENT_TOOLS)

    # Task events
    if isinstance(event, (TaskStart, TaskSuccess, TaskFailure, TaskSkipped)):
        return bool(stream_filter & Stream.TASK_EVENTS)

    return False


def is_completion_tool_event(event: Event) -> bool:
    """Check if an event is related to a completion tool call."""
    if isinstance(event, ToolResult):
        tool = event.tool_result.tool
    elif isinstance(event, (AgentToolCall, AgentToolCallDelta)):
        tool = event.tool
    else:
        return False

    return tool and tool.metadata.get("is_completion_tool")


def process_event(event: Event) -> tuple[Event, Any, Optional[Any]]:
    """Process a single event and return the appropriate tuple."""
    # Message events
    if isinstance(event, AgentMessage):
        return event, event.message, None
    elif isinstance(event, AgentMessageDelta):
        return event, event.message_snapshot, event.message_delta

    # Content events
    elif isinstance(event, AgentContent):
        return event, event.content, None
    elif isinstance(event, AgentContentDelta):
        return event, event.content_snapshot, event.content_delta

    # Tool call events
    elif isinstance(event, AgentToolCall):
        return event, event.tool_call, None
    elif isinstance(event, AgentToolCallDelta):
        return event, event.tool_call_snapshot, event.tool_call_delta

    # Tool result events
    elif isinstance(event, ToolResult):
        return event, event.tool_result, None

    else:
        # Pass through any other events with no snapshot/delta
        return event, None, None


def filter_events_sync(
    events: Iterator[Event], stream_filter: Stream
) -> Iterator[tuple[Event, Any, Optional[Any]]]:
    """Synchronously filter events based on Stream flags."""
    for event in events:
        if should_include_event(event, stream_filter):
            yield process_event(event)


async def filter_events_async(
    events: AsyncIterator[Event], stream_filter: Stream
) -> AsyncIterator[tuple[Event, Any, Optional[Any]]]:
    """Asynchronously filter events based on Stream flags."""
    async for event in events:
        if should_include_event(event, stream_filter):
            yield process_event(event)



================================================
FILE: src/controlflow/agents/__init__.py
================================================
from .agent import Agent



================================================
FILE: src/controlflow/agents/agent.py
================================================
import abc
import logging
import random
import warnings
from contextlib import AbstractContextManager, contextmanager
from typing import (
    TYPE_CHECKING,
    Any,
    AsyncGenerator,
    Generator,
    Iterator,
    Optional,
    Union,
)

from langchain_core.language_models import BaseChatModel
from pydantic import (
    ConfigDict,
    Field,
    PrivateAttr,
    field_serializer,
    field_validator,
    model_validator,
)
from typing_extensions import Self

import controlflow
from controlflow.agents.names import AGENT_NAMES
from controlflow.events.base import Event
from controlflow.instructions import get_instructions
from controlflow.llm.messages import AIMessage, BaseMessage
from controlflow.llm.models import get_model as get_model_from_string
from controlflow.llm.rules import LLMRules
from controlflow.memory import Memory
from controlflow.memory.async_memory import AsyncMemory
from controlflow.tools.tools import (
    Tool,
    as_lc_tools,
    as_tools,
    handle_tool_call,
    handle_tool_call_async,
)
from controlflow.utilities.context import ctx
from controlflow.utilities.general import ControlFlowModel, hash_objects, unwrap
from controlflow.utilities.prefect import create_markdown_artifact, prefect_task

if TYPE_CHECKING:
    from controlflow.events.events import Event
    from controlflow.flows import Flow
    from controlflow.orchestration.handler import AsyncHandler, Handler
    from controlflow.orchestration.turn_strategies import TurnStrategy
    from controlflow.stream import Stream
logger = logging.getLogger(__name__)


class Agent(ControlFlowModel, abc.ABC):
    """
    Class for objects that can be used as agents in a flow
    """

    model_config = ConfigDict(arbitrary_types_allowed=True)

    id: Optional[str] = Field(default=None)
    name: str = Field(
        default_factory=lambda: random.choice(AGENT_NAMES),
        description="The name of the agent.",
    )
    description: Optional[str] = Field(
        default=None, description="A description of the agent, visible to other agents."
    )
    instructions: Optional[str] = Field(
        default="You are a diligent AI assistant. You complete your tasks efficiently and without error.",
        description="Instructions for the agent, private to this agent.",
    )
    prompt: Optional[str] = Field(
        default=None,
        description="A system template for the agent. The template should be formatted as a jinja2 template.",
    )
    tools: list[Tool] = Field(
        default=[], description="List of tools available to the agent."
    )
    interactive: bool = Field(
        default=False,
        description="If True, the agent is given tools for interacting with a human user.",
    )
    memories: list[Union[Memory, AsyncMemory]] = Field(
        default=[],
        description="A list of memory modules for the agent to use.",
    )

    model: Optional[Union[str, BaseChatModel]] = Field(
        default=None,
        description="The LangChain BaseChatModel used by the agent. If not provided, the default model will be used. A compatible string can be passed to automatically retrieve the model.",
        exclude=True,
    )
    llm_rules: Optional[LLMRules] = Field(
        default=None,
        description="The LLM rules for the agent. If not provided, the rules will be inferred from the model (if possible).",
    )

    _cm_stack: list[AbstractContextManager] = PrivateAttr(default_factory=list)

    def __init__(self, instructions: Optional[str] = None, **kwargs):
        if instructions is not None:
            kwargs["instructions"] = instructions

        # deprecated in 0.9
        if "user_access" in kwargs:
            warnings.warn(
                "The `user_access` argument is deprecated. Use `interactive=True` instead.",
                DeprecationWarning,
            )
            kwargs["interactive"] = kwargs.pop("user_access")

        if additional_instructions := get_instructions():
            kwargs["instructions"] = (
                kwargs.get("instructions")
                or "" + "\n" + "\n".join(additional_instructions)
            ).strip()

        super().__init__(**kwargs)

        if not self.id:
            self.id = self._generate_id()

    def __hash__(self) -> int:
        return id(self)

    def _generate_id(self):
        """
        Helper function to generate a stable, short, semi-unique ID for the agent.
        """
        return hash_objects(
            (
                type(self).__name__,
                self.name,
                self.description,
                self.prompt,
                self.instructions,
            )
        )

    @field_validator("instructions")
    def _validate_instructions(cls, v):
        if v:
            v = unwrap(v)
        return v

    @field_validator("tools", mode="before")
    def _validate_tools(cls, tools: list[Tool]):
        return as_tools(tools or [])

    @field_validator("model", mode="before")
    def _validate_model(cls, model: Optional[Union[str, BaseChatModel]]):
        if isinstance(model, str):
            return get_model_from_string(model)
        return model

    @field_serializer("tools")
    def _serialize_tools(self, tools: list[Tool]):
        tools = controlflow.tools.as_tools(tools)
        return [t.model_dump(include={"name", "description"}) for t in tools]

    def serialize_for_prompt(self) -> dict:
        dct = self.model_dump(
            include={"name", "id", "description", "tools", "interactive"}
        )
        if not dct["interactive"]:
            dct.pop("interactive")
        return dct

    def get_model(self, tools: Optional[list["Tool"]] = None) -> BaseChatModel:
        """
        Retrieve the LLM model for this agent
        """
        model = self.model or controlflow.defaults.model
        if model is None:
            raise ValueError(
                f"Agent {self.name}: No model provided and no default model could be loaded."
            )
        if tools:
            model = model.bind_tools(as_lc_tools(tools))
        return model

    def get_llm_rules(self) -> LLMRules:
        """
        Retrieve the LLM rules for this agent's model
        """
        if self.llm_rules is None:
            return controlflow.llm.rules.rules_for_model(self.get_model())
        else:
            return self.llm_rules

    def get_tools(self) -> list["Tool"]:
        from controlflow.tools.input import cli_input

        tools = self.tools.copy()
        if self.interactive:
            tools.append(cli_input)
        for memory in self.memories:
            tools.extend(memory.get_tools())

        return as_tools(tools)

    def get_prompt(self) -> str:
        from controlflow.orchestration import prompt_templates

        template = prompt_templates.AgentTemplate(template=self.prompt, agent=self)
        return template.render()

    @contextmanager
    def create_context(self) -> Generator[Self, None, None]:
        with ctx(agent=self):
            yield self

    def __enter__(self) -> Self:
        self._cm_stack.append(self.create_context())
        return self._cm_stack[-1].__enter__()

    def __exit__(self, *exc_info):
        return self._cm_stack.pop().__exit__(*exc_info)

    def run(
        self,
        objective: str,
        *,
        turn_strategy: Optional["TurnStrategy"] = None,
        handlers: Optional[list["Handler"]] = None,
        stream: Union[bool, "Stream"] = False,
        **task_kwargs,
    ) -> Union[Any, Iterator[tuple["Event", Any, Optional[Any]]]]:
        """
        Run a task with this agent.

        Args:
            objective: The objective to accomplish
            turn_strategy: Optional turn strategy to use
            handlers: Optional list of handlers
            stream: If True, stream all events. Can also provide StreamFilter flags.
            **task_kwargs: Additional kwargs passed to Task creation

        Returns:
            If not streaming: The task result
            If streaming: Iterator of (event, snapshot, delta) tuples
        """
        return controlflow.run(
            objective=objective,
            agents=[self],
            turn_strategy=turn_strategy,
            handlers=handlers,
            stream=stream,
            **task_kwargs,
        )

    async def run_async(
        self,
        objective: str,
        *,
        turn_strategy: Optional["TurnStrategy"] = None,
        handlers: Optional[list[Union["Handler", "AsyncHandler"]]] = None,
        stream: Union[bool, "Stream"] = False,
        **task_kwargs,
    ):
        return await controlflow.run_async(
            objective=objective,
            agents=[self],
            turn_strategy=turn_strategy,
            handlers=handlers,
            stream=stream,
            **task_kwargs,
        )

    def plan(
        self,
        objective: str,
        instructions: Optional[str] = None,
        agents: Optional[list["Agent"]] = None,
        tools: Optional[list["Tool"]] = None,
        context: Optional[dict] = None,
    ) -> list["Task"]:
        """
        Generate a list of tasks that represent a structured plan for achieving
        the objective.

        Args:
            objective (str): The objective to plan for.
            instructions (Optional[str]): Optional instructions for the planner.
            agents (Optional[list[Agent]]): Optional list of agents to include in the plan. If None, this agent is used.
            tools (Optional[list[Tool]]): Optional list of tools to include in the plan. If None, this agent's tools are used.
            context (Optional[dict]): Optional context to include in the plan.

        Returns:
            list[Task]: A list of tasks that represent a structured plan for achieving the objective.
        """
        return controlflow.tasks.plan(
            objective=objective,
            instructions=instructions,
            agent=self,
            agents=agents or [self],
            tools=tools or [self.tools],
            context=context,
        )

    @prefect_task(task_run_name="Call LLM")
    def _run_model(
        self,
        messages: list[BaseMessage],
        tools: list["Tool"],
        stream: bool = True,
        model_kwargs: Optional[dict] = None,
    ) -> Generator[Event, None, None]:
        from controlflow.events.events import (
            AgentMessage,
            AgentMessageDelta,
            ToolResult,
        )

        tools = as_tools(self.get_tools() + tools)
        model = self.get_model(tools=tools)

        logger.debug(
            f"Running model {model} for agent {self.name} with tools {[t.name for t in tools]!r}"
        )
        if controlflow.settings.log_all_messages:
            logger.debug(f"Input messages: {messages}")

        if stream:
            response = None
            for delta in model.stream(messages, **(model_kwargs or {})):
                if response is None:
                    response = delta
                else:
                    response += delta

                yield from AgentMessageDelta(
                    agent=self, message_delta=delta, message_snapshot=response
                ).all_related_events(tools=tools)

        else:
            response: AIMessage = model.invoke(messages)

        yield from AgentMessage(agent=self, message=response).all_related_events(
            tools=tools
        )

        create_markdown_artifact(
            markdown=f"""
{response.content or "(No content)"}

#### Payload
```json
{response.model_dump_json(indent=2)}
```
""",
            description=f"LLM Response for Agent {self.name}",
            key="agent-message",
        )

        if controlflow.settings.log_all_messages:
            logger.debug(f"Response: {response}")

        for tool_call in response.tool_calls + response.invalid_tool_calls:
            result = handle_tool_call(tool_call, tools=tools)
            yield ToolResult(agent=self, tool_result=result)

    @prefect_task(task_run_name="Call LLM")
    async def _run_model_async(
        self,
        messages: list[BaseMessage],
        tools: list["Tool"],
        stream: bool = True,
        model_kwargs: Optional[dict] = None,
    ) -> AsyncGenerator[Event, None]:
        from controlflow.events.events import (
            AgentMessage,
            AgentMessageDelta,
            ToolResult,
        )

        tools = as_tools(self.get_tools() + tools)
        model = self.get_model(tools=tools)

        logger.debug(
            f"Running model {model} for agent {self.name} with tools {[t.name for t in tools]!r}"
        )
        if controlflow.settings.log_all_messages:
            logger.debug(f"Input messages: {messages}")

        if stream:
            response = None
            async for delta in model.astream(messages, **(model_kwargs or {})):
                if response is None:
                    response = delta
                else:
                    response += delta

                for event in AgentMessageDelta(
                    agent=self, message_delta=delta, message_snapshot=response
                ).all_related_events(tools=tools):
                    yield event

        else:
            response: AIMessage = await model.ainvoke(messages)

        for event in AgentMessage(agent=self, message=response).all_related_events(
            tools=tools
        ):
            yield event

        create_markdown_artifact(
            markdown=f"""
{response.content or "(No content)"}

#### Payload
```json
{response.model_dump_json(indent=2)}
```
""",
            description=f"LLM Response for Agent {self.name}",
            key="agent-message",
        )

        if controlflow.settings.log_all_messages:
            logger.debug(f"Response: {response}")

        for tool_call in response.tool_calls + response.invalid_tool_calls:
            result = await handle_tool_call_async(tool_call, tools=tools)
            yield ToolResult(agent=self, tool_result=result)



================================================
FILE: src/controlflow/agents/names.py
================================================
AGENT_NAMES = [
    "HAL 9000",
    "R2-D2",
    "C-3PO",
    "WALL-E",
    "T-800",
    "GLaDOS",
    "J.A.R.V.I.S",
    "EVE",
    "KITT",
    "Johnny 5",
    "BB-8",
    "Ultron",
    "TARS",
    "Agent Smith",
    "CLU",
    "Deckard",
    "HK-47",
    "Bender",
    "Norbert",
    "Norby",
]

TEAM_NAMES = [
    "Autobots",
    "Decepticons",
    "Borg",
    "Cylons",
    "Jaegers",
    "Sentinels",
    "Iron Legion",
    "Daleks",
    "Replicants",
    "Droids",
    "Machines",
    "Hosts",
    "Androids",
    "Mechs",
    "Avatars",
    "Powers",
]



================================================
FILE: src/controlflow/cli/dev.py
================================================
import os
import subprocess
from pathlib import Path

import typer

dev_app = typer.Typer(no_args_is_help=True)


@dev_app.command()
def ai_files(
    output_path: str = typer.Option(
        ".",
        "--output",
        "-o",
        help="The path where output files will be written. Defaults to current directory.",
    ),
):
    """
    Generates three markdown files that contain all of ControlFlow's source code, documentation,
    and LLM guides, which can be used to provide context to an AI.
    """
    try:
        # Get the absolute path of the ControlFlow main repo
        repo_root = Path(__file__).resolve().parents[3]
        src_path = repo_root / "src"
        docs_path = repo_root / "docs"
        llm_guides_path = docs_path / "llm-guides"
        output_dir = Path(output_path).resolve()

        def generate_file_content(file_paths, output_file):
            with open(output_dir / output_file, "w") as f:
                for file_path in file_paths:
                    f.write(f"# ControlFlow Source File: {file_path.absolute()}\n\n")
                    f.write(file_path.read_text())
                    f.write("\n\n")

        code_files = list(src_path.rglob("*.py")) + list(src_path.rglob("*.jinja"))
        doc_files = (
            list(docs_path.rglob("*.mdx"))
            + list(docs_path.glob("*.md"))
            + [docs_path / "mint.json", repo_root / "README.md"]
        )
        llm_guide_files = list(llm_guides_path.glob("*.md")) + list(
            llm_guides_path.glob("*.mdx")
        )

        generate_file_content(code_files, "all_code.md")
        generate_file_content(doc_files, "all_docs.md")
        generate_file_content(llm_guide_files, "llm_guides.md")

        typer.echo(
            f"Generated all_code.md, all_docs.md, and llm-guides.md in {output_dir}"
        )
    except Exception as e:
        typer.echo(f"An error occurred: {str(e)}", err=True)
        raise typer.Exit(code=1)


@dev_app.command()
def docs():
    """
    This is equivalent to 'cd docs && mintlify dev' from the ControlFlow root.
    """
    try:
        # Get the absolute path of the ControlFlow main repo
        repo_root = Path(__file__).resolve().parents[3]
        docs_path = repo_root / "docs"

        if not docs_path.exists():
            typer.echo(f"Error: Docs directory not found at {docs_path}", err=True)
            raise typer.Exit(code=1)

        typer.echo(f"Changing directory to: {docs_path}")
        os.chdir(docs_path)

        typer.echo("Running 'mintlify dev'...")
        subprocess.run(["mintlify", "dev"], check=True)

    except subprocess.CalledProcessError as e:
        typer.echo(f"Error running 'mintlify dev': {str(e)}", err=True)
        raise typer.Exit(code=1)
    except Exception as e:
        typer.echo(f"An error occurred: {str(e)}", err=True)
        raise typer.Exit(code=1)



================================================
FILE: src/controlflow/cli/main.py
================================================
import platform
from pathlib import Path

import langchain_core
import prefect
import typer
from rich.table import Table
from typer import Context, Exit

from controlflow import __version__
from controlflow.utilities.rich import console

from .dev import dev_app

app = typer.Typer(no_args_is_help=True)

app.add_typer(dev_app, name="dev")


@app.command()
def version(ctx: Context):
    if ctx.resilient_parsing:
        return

    info = {
        "ControlFlow version": __version__,
        "Prefect version": prefect.__version__,
        "LangChain Core version": langchain_core.__version__,
        "Python version": platform.python_version(),
        "Platform": platform.platform(),
        "Path": Path(__file__).resolve().parents[3],
    }

    g = Table.grid(padding=(0, 1))
    g.add_column(justify="right")
    g.add_column()
    for k, v in info.items():
        g.add_row(k + ":", str(v).replace("\n", " "))
    console.print(g)

    raise Exit()


# this callback only exists to force `version` to be called as `controlflow
# version` instead of as the default command, which is the default behavior when
# there's only one command. It can be deleted if/when more commands are added.
@app.callback()
def callback():
    pass


if __name__ == "__main__":
    app()



================================================
FILE: src/controlflow/events/__init__.py
================================================
from .base import Event



================================================
FILE: src/controlflow/events/base.py
================================================
import datetime
import uuid
from typing import TYPE_CHECKING, Optional

from pydantic import ConfigDict, Field
from pydantic_extra_types.pendulum_dt import DateTime

from controlflow.utilities.general import ControlFlowModel

if TYPE_CHECKING:
    from controlflow.events.message_compiler import CompileContext
    from controlflow.llm.messages import BaseMessage

# This is a global variable that will be shared between all instances of InMemoryStore
IN_MEMORY_STORE = {}


class Event(ControlFlowModel):
    model_config: ConfigDict = ConfigDict(extra="forbid")

    event: str
    id: str = Field(default_factory=lambda: uuid.uuid4().hex)
    thread_id: Optional[str] = None
    timestamp: DateTime = Field(
        default_factory=lambda: datetime.datetime.now(datetime.timezone.utc)
    )
    persist: bool = True

    def to_messages(self, context: "CompileContext") -> list["BaseMessage"]:
        return []

    def __repr__(self) -> str:
        return f"<Event: {self.event} Timestamp: {self.timestamp}>"


class UnpersistedEvent(Event):
    model_config: ConfigDict = ConfigDict(arbitrary_types_allowed=True)
    persist: bool = False



================================================
FILE: src/controlflow/events/events.py
================================================
from typing import TYPE_CHECKING, Literal, Optional, Union

import pydantic_core
from pydantic import ConfigDict, field_validator, model_validator

from controlflow.agents.agent import Agent
from controlflow.events.base import Event, UnpersistedEvent
from controlflow.llm.messages import (
    AIMessage,
    AIMessageChunk,
    BaseMessage,
    HumanMessage,
    ToolMessage,
)
from controlflow.tools.tools import InvalidToolCall, Tool, ToolCall
from controlflow.tools.tools import ToolResult as ToolResultPayload
from controlflow.utilities.logging import get_logger

if TYPE_CHECKING:
    from controlflow.events.message_compiler import CompileContext
logger = get_logger(__name__)

ORCHESTRATOR_PREFIX = "The following message is from the orchestrator."


class OrchestratorMessage(Event):
    """
    Messages from the orchestrator to agents.
    """

    event: Literal["orchestrator-message"] = "orchestrator-message"
    content: Union[str, list[Union[str, dict]]]
    prefix: Optional[str] = ORCHESTRATOR_PREFIX
    name: Optional[str] = None

    def to_messages(self, context: "CompileContext") -> list[BaseMessage]:
        messages = []
        # if self.prefix:
        #     messages.append(SystemMessage(content=self.prefix))
        messages.append(
            HumanMessage(content=f"({self.prefix})\n\n{self.content}", name=self.name)
        )
        return messages


class UserMessage(Event):
    event: Literal["user-message"] = "user-message"
    content: Union[str, list[Union[str, dict]]]

    def to_messages(self, context: "CompileContext") -> list[BaseMessage]:
        return [HumanMessage(content=self.content)]


class AgentMessage(Event):
    event: Literal["agent-message"] = "agent-message"
    agent: Agent
    message: dict

    @field_validator("message", mode="before")
    def _as_message_dict(cls, v):
        if isinstance(v, BaseMessage):
            v = v.model_dump()
        v["type"] = "ai"
        return v

    @model_validator(mode="after")
    def _finalize(self):
        self.message["name"] = self.agent.name
        return self

    @property
    def ai_message(self) -> AIMessage:
        return AIMessage(**self.message)

    def to_tool_calls(self, tools: list[Tool]) -> list["AgentToolCall"]:
        calls = []
        for tool_call in (
            self.message["tool_calls"] + self.message["invalid_tool_calls"]
        ):
            tool = next((t for t in tools if t.name == tool_call.get("name")), None)
            if tool:
                calls.append(
                    AgentToolCall(
                        agent=self.agent,
                        tool_call=tool_call,
                        tool=tool,
                        args=tool_call["args"],
                        agent_message_id=self.message.get("id"),
                    )
                )
        return calls

    def to_content(self) -> Optional["AgentContent"]:
        if self.message.get("content"):
            return AgentContent(
                agent=self.agent,
                content=self.message["content"],
                agent_message_id=self.message.get("id"),
            )

    def all_related_events(self, tools: list[Tool]) -> list[Event]:
        content = self.to_content()
        return [self] + ([content] if content else []) + self.to_tool_calls(tools)

    def to_messages(self, context: "CompileContext") -> list[BaseMessage]:
        if self.agent.name == context.agent.name:
            return [self.ai_message]
        elif self.message["content"]:
            return OrchestratorMessage(
                prefix=f'The following message was posted by Agent "{self.agent.name}" with ID {self.agent.id}',
                content=self.message["content"],
                name=self.agent.name,
            ).to_messages(context)
        else:
            return []


class AgentMessageDelta(UnpersistedEvent):
    event: Literal["agent-message-delta"] = "agent-message-delta"

    agent: Agent
    message_delta: dict
    message_snapshot: dict

    @field_validator("message_delta", "message_snapshot", mode="before")
    def _as_message_dict(cls, v):
        if isinstance(v, BaseMessage):
            v = v.model_dump()
        v["type"] = "AIMessageChunk"
        return v

    @model_validator(mode="after")
    def _finalize(self):
        self.message_delta["name"] = self.agent.name
        self.message_snapshot["name"] = self.agent.name
        return self

    def to_tool_call_deltas(self, tools: list[Tool]) -> list["AgentToolCallDelta"]:
        deltas = []
        for call_delta in self.message_delta.get("tool_call_chunks", []):
            # First match chunks by index because streaming chunks come in sequence (0,1,2...)
            # and this index lets us correlate deltas to their snapshots during streaming
            chunk_snapshot = next(
                (
                    c
                    for c in self.message_snapshot.get("tool_call_chunks", [])
                    if c.get("index", -1) == call_delta.get("index", -2)
                ),
                None,
            )

            if chunk_snapshot and chunk_snapshot.get("id"):
                # Once we have the matching chunk, use its ID to find the full tool call
                # The full tool calls contain properly parsed arguments (as Python dicts)
                # while chunks just contain raw JSON strings
                call_snapshot = next(
                    (
                        c
                        for c in self.message_snapshot["tool_calls"]
                        if c.get("id") == chunk_snapshot["id"]
                    ),
                    None,
                )

                if call_snapshot:
                    tool = next(
                        (t for t in tools if t.name == call_snapshot.get("name")), None
                    )
                    # Use call_snapshot.args which is already parsed into a Python dict
                    # This avoids issues with pydantic's more limited JSON parser
                    deltas.append(
                        AgentToolCallDelta(
                            agent=self.agent,
                            tool_call_delta=call_delta,
                            tool_call_snapshot=call_snapshot,
                            tool=tool,
                            args=call_snapshot.get("args", {}),
                            agent_message_id=self.message_snapshot.get("id"),
                        )
                    )
        return deltas

    def to_content_delta(self) -> Optional["AgentContentDelta"]:
        if self.message_delta.get("content"):
            return AgentContentDelta(
                agent=self.agent,
                content_delta=self.message_delta["content"],
                content_snapshot=self.message_snapshot["content"],
                agent_message_id=self.message_snapshot.get("id"),
            )

    def all_related_events(self, tools: list[Tool]) -> list[Event]:
        content_delta = self.to_content_delta()
        return (
            [self]
            + ([content_delta] if content_delta else [])
            + self.to_tool_call_deltas(tools)
        )


class AgentContent(UnpersistedEvent):
    event: Literal["agent-content"] = "agent-content"
    agent: Agent
    agent_message_id: Optional[str] = None
    content: Union[str, list[Union[str, dict]]]


class AgentContentDelta(UnpersistedEvent):
    event: Literal["agent-content-delta"] = "agent-content-delta"
    agent: Agent
    agent_message_id: Optional[str] = None
    content_delta: Union[str, list[Union[str, dict]]]
    content_snapshot: Union[str, list[Union[str, dict]]]


class AgentToolCall(Event):
    event: Literal["agent-tool-call"] = "agent-tool-call"
    agent: Agent
    agent_message_id: Optional[str] = None
    tool_call: Union[ToolCall, InvalidToolCall]
    tool: Optional[Tool] = None
    args: dict = {}


class AgentToolCallDelta(UnpersistedEvent):
    event: Literal["agent-tool-call-delta"] = "agent-tool-call-delta"
    agent: Agent
    agent_message_id: Optional[str] = None
    tool_call_delta: dict
    tool_call_snapshot: dict
    tool: Optional[Tool] = None
    args: dict = {}


class EndTurn(Event):
    event: Literal["end-turn"] = "end-turn"
    agent: Agent
    next_agent_name: Optional[str] = None


class ToolResult(Event):
    event: Literal["tool-result"] = "tool-result"
    agent: Agent
    tool_result: ToolResultPayload

    def to_messages(self, context: "CompileContext") -> list[BaseMessage]:
        if self.agent.name == context.agent.name:
            return [
                ToolMessage(
                    content=self.tool_result.str_result,
                    tool_call_id=self.tool_result.tool_call["id"],
                    name=self.agent.name,
                )
            ]
        else:
            return OrchestratorMessage(
                prefix=f'Agent "{self.agent.name}" with ID {self.agent.id} made a tool '
                f'call: {self.tool_result.tool_call}. The tool{" failed and" if self.tool_result.is_error else " "} '
                f'produced this result:',
                content=self.tool_result.str_result,
                name=self.agent.name,
            ).to_messages(context)



================================================
FILE: src/controlflow/events/history.py
================================================
import abc
import json
import math
from functools import cache
from pathlib import Path
from typing import Optional, Union

from pydantic import Field, TypeAdapter, field_validator

import controlflow
from controlflow.events.base import Event
from controlflow.utilities.general import ControlFlowModel

# This is a global variable that will be shared between all instances of InMemoryStore
IN_MEMORY_STORE = {}


@cache
def get_event_validator() -> TypeAdapter:
    from controlflow.events.events import (
        AgentMessage,
        EndTurn,
        OrchestratorMessage,
        ToolResult,
        UserMessage,
    )

    types = Union[
        OrchestratorMessage,
        UserMessage,
        AgentMessage,
        EndTurn,
        ToolResult,
        Event,
    ]
    return TypeAdapter(list[types])


def filter_events(
    events: list[Event],
    types: Optional[list[str]] = None,
    before_id: Optional[str] = None,
    after_id: Optional[str] = None,
    limit: Optional[int] = None,
):
    """
    Filters a list of events based on the specified criteria.

    Args:
        events (list[Event]): The list of events to filter.
        tags: (Optional[list[str]]): The tags to filter by. Defaults to None.
        types (Optional[list[str]]): The event types to filter by. Defaults to None.
        before_id (Optional[str]): The ID of the event before which to start including events. Defaults to None.
        after_id (Optional[str]): The ID of the event after which to stop including events. Defaults to None.
        limit (Optional[int]): The maximum number of events to include. Defaults to None.

    Returns:
        list[Event]: The filtered list of events.
    """
    new_events = []
    seen_before_id = True if not before_id else False
    seen_after_id = False if not after_id else True

    for event in reversed(events):
        if event.id == before_id:
            seen_before_id = True
        if event.id == after_id:
            seen_after_id = True

        # if we haven't reached the `before_id` we can skip this event
        if not seen_before_id:
            continue

        # if we've reached the `after_id` we can stop searching
        if seen_after_id:
            break

        # if types are specified and this event is not one of them, skip it
        if types and event.event not in types:
            continue

        new_events.append(event)

        if len(new_events) >= (limit or math.inf):
            break

    return list(reversed(new_events))


class History(ControlFlowModel, abc.ABC):
    @abc.abstractmethod
    def get_events(
        self,
        thread_id: str,
        types: Optional[list[str]] = None,
        before_id: Optional[str] = None,
        after_id: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> list[Event]:
        raise NotImplementedError()

    @abc.abstractmethod
    def add_events(self, thread_id: str, events: list[Event]):
        raise NotImplementedError()


class InMemoryHistory(History):
    history: dict[str, list[Event]] = Field(
        default_factory=lambda: IN_MEMORY_STORE, repr=False
    )

    def add_events(self, thread_id: str, events: list[Event]):
        self.history.setdefault(thread_id, []).extend(events)

    def get_events(
        self,
        thread_id: str,
        types: Optional[list[str]] = None,
        before_id: Optional[str] = None,
        after_id: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> list[Event]:
        """
        Retrieve a list of events based on the specified criteria.

        Args:
            thread_id (str): The ID of the thread to retrieve events from.
            tags (Optional[list[str]]): The tags associated with the events (default: None).
            types (Optional[list[str]]): The list of event types to filter by (default: None).
            before_id (Optional[str]): The ID of the event before which to start retrieving events (default: None).
            after_id (Optional[str]): The ID of the event after which to stop retrieving events (default: None).
            limit (Optional[int]): The maximum number of events to retrieve (default: None).

        Returns:
            list[Event]: A list of events that match the specified criteria.

        """
        events = self.history.get(thread_id, [])
        return filter_events(
            events=events,
            types=types,
            before_id=before_id,
            after_id=after_id,
            limit=limit,
        )


class FileHistory(History):
    base_path: Path = Field(
        default_factory=lambda: controlflow.settings.home_path / "history/FileHistory"
    )

    def path(self, thread_id: str) -> Path:
        return self.base_path / f"{thread_id}.json"

    def get_events(
        self,
        thread_id: str,
        types: Optional[list[str]] = None,
        before_id: Optional[str] = None,
        after_id: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> list[Event]:
        """
        Retrieves a list of events based on the specified criteria.

        Args:
            thread_id (str): The ID of the thread to retrieve events from.
            types (Optional[list[str]]): The list of event types to filter by (default: None).
            before_id (Optional[str]): The ID of the event before which to stop retrieving events (default: None).
            after_id (Optional[str]): The ID of the event after which to start retrieving events (default: None).
            limit (Optional[int]): The maximum number of events to retrieve (default: None).

        Returns:
            list[Event]: A list of events that match the specified criteria.
        """
        file_path = self.path(thread_id)

        if not file_path.exists():
            return []

        with file_path.open("r") as f:
            raw_data = f.read()

        validator = get_event_validator()
        events = validator.validate_json(raw_data)

        return filter_events(
            events=events,
            types=types,
            before_id=before_id,
            after_id=after_id,
            limit=limit,
        )

    def add_events(self, thread_id: str, events: list[Event]):
        # TODO: this is pretty inefficient because we read / write the entire file
        # every time instead of doing it incrementally. Need to switch to JSONL
        # if we want to improve performance.
        file_path = self.path(thread_id)

        if not file_path.exists():
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.touch()

        with file_path.open("r") as f:
            try:
                all_events = json.load(f)
            except json.JSONDecodeError:
                all_events = []

        all_events.extend([event.model_dump(mode="json") for event in events])

        with file_path.open("w") as f:
            json.dump(all_events, f)



================================================
FILE: src/controlflow/events/message_compiler.py
================================================
import re
from dataclasses import dataclass
from typing import TYPE_CHECKING, Literal, Optional

import tiktoken

import controlflow
from controlflow.events.base import Event, UnpersistedEvent
from controlflow.events.events import (
    AgentMessage,
    AgentToolCall,
    ToolResult,
)
from controlflow.llm.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage,
)
from controlflow.llm.rules import LLMRules
from controlflow.utilities.logging import get_logger

if TYPE_CHECKING:
    from controlflow.agents.agent import Agent
logger = get_logger(__name__)


class CombinedAgentMessage(UnpersistedEvent):
    event: Literal["combined-agent-message"] = "combined-agent-message"
    agent_message: AgentMessage
    tool_call: list[AgentToolCall] = []
    tool_results: list[ToolResult] = []

    def to_messages(self, context: "CompileContext") -> list[BaseMessage]:
        messages = []
        messages.extend(self.agent_message.to_messages(context))
        for tool_result in self.tool_results:
            messages.extend(tool_result.to_messages(context))
        return messages


def add_user_message_to_beginning(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    """
    If the LLM requires the user message to be the first message, add a user
    message to the beginning of the list.
    """
    if rules.require_user_message_after_system:
        if not messages or not isinstance(messages[0], HumanMessage):
            messages.insert(0, HumanMessage(content="SYSTEM: Begin."))
    return messages


def ensure_at_least_one_message(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    if not messages and rules.require_at_least_one_message:
        messages.append(HumanMessage(content="SYSTEM: Begin."))
    return messages


def add_user_message_to_end(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    """
    If the LLM doesn't allow the last message to be from the AI when using tools,
    add a user message to the end of the list.
    """
    if not rules.allow_last_message_from_ai_when_using_tools:
        if not messages or isinstance(messages[-1], AIMessage):
            msg = HumanMessage(content="SYSTEM: Continue.")
            messages.append(msg)
    return messages


def remove_duplicate_messages(messages: list[BaseMessage]) -> list[BaseMessage]:
    """
    Removes duplicate messages from the list.
    """
    seen = set()
    new_messages = []
    for message in messages:
        if message.id not in seen:
            new_messages.append(message)
            if message.id:
                seen.add(message.id)
    return new_messages


def break_up_consecutive_ai_messages(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    """
    Breaks up consecutive AI messages by inserting a system message.
    """
    if not messages or rules.allow_consecutive_ai_messages:
        return messages

    new_messages = messages.copy()
    i = 1
    while i < len(new_messages):
        if isinstance(new_messages[i], AIMessage) and isinstance(
            new_messages[i - 1], AIMessage
        ):
            new_messages.insert(i, SystemMessage(content="Continue."))
        i += 1

    return new_messages


def convert_system_messages(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    """
    Converts system messages to human messages if the LLM doesnt support system
    messages, either at all or in the first position.
    """
    new_messages = []
    for i, message in enumerate(messages):
        if isinstance(message, SystemMessage):
            # If system messages are not supported OR if they must be first and
            # this is not the first message, THEN convert the message to a human message
            if not rules.allow_system_messages or (
                i > 0 and rules.require_system_message_first
            ):
                new_messages.append(
                    HumanMessage(
                        content=f"ORCHESTRATOR: {message.content}", name=message.name
                    )
                )
            else:
                # If the system message is allowed, add it as-is
                new_messages.append(message)
        else:
            new_messages.append(message)
    return new_messages


def format_message_name(
    messages: list[BaseMessage], rules: LLMRules
) -> list[BaseMessage]:
    if not rules.require_message_name_format:
        return messages

    for message in messages:
        if message.name:
            name = re.sub(rules.require_message_name_format, "-", message.name)
            message.name = name.strip("-")
    return messages


def count_tokens(message: BaseMessage) -> int:
    # always use gpt-3.5 token counter with the entire message object; we only need to be approximate here
    return len(
        tiktoken.encoding_for_model("gpt-3.5-turbo").encode(message.model_dump_json())
    )


def trim_messages(
    messages: list[BaseMessage], max_tokens: Optional[int]
) -> list[BaseMessage]:
    """
    Trims messages to a maximum number of tokens while keeping the system message at the front.
    """

    if not messages or max_tokens is None:
        return messages

    new_messages = []
    budget = max_tokens

    for message in reversed(messages):
        if count_tokens(message) > budget:
            break
        new_messages.append(message)
        budget -= count_tokens(message)

    return list(reversed(new_messages))


@dataclass
class CompileContext:
    llm_rules: LLMRules
    agent: Optional["Agent"]


class MessageCompiler:
    def __init__(
        self,
        events: list[Event],
        system_prompt: Optional[str] = None,
        llm_rules: Optional[LLMRules] = None,
        max_tokens: Optional[int] = None,
    ):
        self.events = events
        self.system_prompt = system_prompt
        self.llm_rules = llm_rules
        self.max_tokens = max_tokens or controlflow.settings.max_input_tokens

    def organize_events(self, context: CompileContext) -> list[Event]:
        organized_events = []
        tool_calls = {}

        for event in self.events:
            # combine all agent messages and tool results
            if isinstance(event, AgentMessage):
                # add a combined agent message
                combined_event = CombinedAgentMessage(agent_message=event)
                organized_events.append(combined_event)
                # register the combined message under each tool call id
                for tc in (
                    event.ai_message.tool_calls + event.ai_message.invalid_tool_calls
                ):
                    tool_calls[tc["id"]] = combined_event
            elif isinstance(event, ToolResult):
                combined_event: CombinedAgentMessage = tool_calls.get(
                    event.tool_result.tool_call["id"]
                )
                if combined_event:
                    combined_event.tool_results.append(event)

            # all other events are added as-is
            else:
                organized_events.append(event)

        return organized_events

    def compile_to_messages(self, agent: "Agent") -> list[BaseMessage]:
        context = CompileContext(
            agent=agent, llm_rules=self.llm_rules or agent.get_llm_rules()
        )

        if self.system_prompt:
            system_prompt = [SystemMessage(content=self.system_prompt)]
            max_tokens = self.max_tokens - count_tokens(system_prompt[0])
        else:
            system_prompt = []
            max_tokens = self.max_tokens

        events = self.organize_events(context=context)

        messages = []
        for event in events:
            messages.extend(event.to_messages(context))

        # trim messages
        messages = trim_messages(messages, max_tokens=max_tokens)

        # apply LLM rules
        messages = ensure_at_least_one_message(messages, rules=context.llm_rules)
        messages = add_user_message_to_beginning(messages, rules=context.llm_rules)
        messages = add_user_message_to_end(messages, rules=context.llm_rules)
        messages = remove_duplicate_messages(messages)
        messages = break_up_consecutive_ai_messages(messages, rules=context.llm_rules)
        messages = format_message_name(messages, rules=context.llm_rules)

        messages = system_prompt + messages

        # this should go last
        messages = convert_system_messages(messages, rules=context.llm_rules)

        return messages



================================================
FILE: src/controlflow/events/orchestrator_events.py
================================================
from dataclasses import Field
from typing import TYPE_CHECKING, Annotated, Any, Literal, Optional

from pydantic.functional_serializers import PlainSerializer

from controlflow.agents.agent import Agent
from controlflow.events.base import Event, UnpersistedEvent

if TYPE_CHECKING:
    from controlflow.orchestration.conditions import RunContext
    from controlflow.orchestration.orchestrator import Orchestrator


# Orchestrator events
class OrchestratorStart(UnpersistedEvent):
    event: Literal["orchestrator-start"] = "orchestrator-start"
    persist: bool = False
    orchestrator: "Orchestrator"
    run_context: "RunContext"


class OrchestratorEnd(UnpersistedEvent):
    event: Literal["orchestrator-end"] = "orchestrator-end"
    persist: bool = False
    orchestrator: "Orchestrator"
    run_context: "RunContext"


class OrchestratorError(UnpersistedEvent):
    event: Literal["orchestrator-error"] = "orchestrator-error"
    persist: bool = False
    orchestrator: "Orchestrator"
    error: Annotated[Exception, PlainSerializer(lambda x: str(x), return_type=str)]


class AgentTurnStart(UnpersistedEvent):
    event: Literal["agent-turn-start"] = "agent-turn-start"
    persist: bool = False
    orchestrator: "Orchestrator"
    agent: Agent


class AgentTurnEnd(UnpersistedEvent):
    event: Literal["agent-turn-end"] = "agent-turn-end"
    persist: bool = False
    orchestrator: "Orchestrator"
    agent: Agent



================================================
FILE: src/controlflow/events/task_events.py
================================================
from dataclasses import Field
from typing import TYPE_CHECKING, Annotated, Any, Literal, Optional

from pydantic.functional_serializers import PlainSerializer

from controlflow.events.base import UnpersistedEvent
from controlflow.tasks.task import Task


# Task events
class TaskStart(UnpersistedEvent):
    event: Literal["task-start"] = "task-start"
    task: Task


class TaskSuccess(UnpersistedEvent):
    event: Literal["task-success"] = "task-success"
    task: Task
    result: Annotated[
        Any,
        PlainSerializer(lambda x: str(x) if x else None, return_type=Optional[str]),
    ] = None


class TaskFailure(UnpersistedEvent):
    event: Literal["task-failure"] = "task-failure"
    task: Task
    reason: Optional[str] = None


class TaskSkipped(UnpersistedEvent):
    event: Literal["task-skipped"] = "task-skipped"
    task: Task



================================================
FILE: src/controlflow/flows/__init__.py
================================================
from .flow import Flow, get_flow



================================================
FILE: src/controlflow/flows/flow.py
================================================
import uuid
from contextlib import AbstractContextManager, contextmanager, nullcontext
from typing import Any, Callable, Generator, Optional, Union

from prefect.context import FlowRunContext
from pydantic import ConfigDict, Field, PrivateAttr, field_validator
from typing_extensions import Self

import controlflow
from controlflow.agents import Agent
from controlflow.events.base import Event
from controlflow.events.history import History
from controlflow.utilities.context import ctx
from controlflow.utilities.general import ControlFlowModel, unwrap
from controlflow.utilities.logging import get_logger
from controlflow.utilities.prefect import prefect_flow_context

logger = get_logger(__name__)


class Flow(ControlFlowModel):
    model_config = ConfigDict(arbitrary_types_allowed=True)

    thread_id: str = Field(default_factory=lambda: uuid.uuid4().hex)
    name: Optional[str] = None
    description: Optional[str] = None
    history: History = Field(
        default_factory=lambda: controlflow.defaults.history,
        description="An object for storing events that take place during the flow.",
    )
    tools: list[Callable] = Field(
        default_factory=list,
        description="Tools that will be available to every agent in the flow",
    )
    default_agent: Optional[Agent] = Field(
        default=None,
        description=(
            "The default agent for the flow. This agent will be used "
            "for any task that does not specify an agent."
        ),
    )
    prompt: Optional[str] = Field(
        default=None,
        description="A prompt to display to the agent working on the flow.",
    )
    parent: Optional["Flow"] = Field(
        default_factory=lambda: get_flow(),
        description="The parent flow. This is the flow that created this flow.",
    )
    load_parent_events: bool = Field(
        default=True,
        description=(
            "Whether to load events from the parent flow. If a flow is nested, "
            "this will load events from the parent flow so that the child flow can "
            "access the full conversation history, even though the child flow is a separate thread."
        ),
    )
    context: dict[str, Any] = {}

    _cm_stack: list[AbstractContextManager] = PrivateAttr(default_factory=list)

    def __enter__(self) -> Self:
        # use stack so we can enter the context multiple times
        cm = self.create_context()
        self._cm_stack.append(cm)
        return cm.__enter__()

    def __exit__(self, *exc_info):
        # exit the context manager
        return self._cm_stack.pop().__exit__(*exc_info)

    @field_validator("description")
    def _validate_description(cls, v):
        if v:
            v = unwrap(v)
        return v

    def get_prompt(self) -> str:
        """
        Generate a prompt to share information about the flow with an agent.
        """
        from controlflow.orchestration import prompt_templates

        template = prompt_templates.FlowTemplate(template=self.prompt, flow=self)
        return template.render()

    def get_events(
        self,
        before_id: Optional[str] = None,
        after_id: Optional[str] = None,
        limit: Optional[int] = None,
        types: Optional[list[str]] = None,
    ) -> list[Event]:
        events = self.history.get_events(
            thread_id=self.thread_id,
            before_id=before_id,
            after_id=after_id,
            limit=limit,
            types=types,
        )

        if self.parent and self.load_parent_events:
            events.extend(
                self.parent.get_events(
                    before_id=before_id,
                    after_id=after_id,
                    limit=limit,
                    types=types,
                )
            )
        events = sorted(events, key=lambda x: x.timestamp)
        return events

    def add_events(self, events: list[Event]):
        persist_events = [e for e in events if e.persist]
        for event in persist_events:
            event.thread_id = self.thread_id
        if persist_events:
            self.history.add_events(thread_id=self.thread_id, events=persist_events)

    @contextmanager
    def create_context(self, **prefect_kwargs) -> Generator[Self, None, None]:
        # create a new Prefect flow if we're not already in a flow run
        if FlowRunContext.get() is None:
            prefect_context = prefect_flow_context(**prefect_kwargs)
        else:
            prefect_context = nullcontext()

        with prefect_context:
            # creating a new flow will reset any parent task tracking
            with ctx(flow=self, tasks=None):
                yield self


def get_flow() -> Optional[Flow]:
    """
    Loads the flow from the context or returns a new
    """
    flow: Union[Flow, None] = ctx.get("flow")
    return flow


def get_flow_events(limit: Optional[int] = None) -> list[Event]:
    """
    Loads events from the active flow's thread.
    """
    if limit is None:
        limit = 50
    flow = get_flow()
    if flow:
        return flow.get_events(limit=limit)
    else:
        return []



================================================
FILE: src/controlflow/flows/graph.py
================================================
from dataclasses import dataclass
from enum import Enum
from typing import Optional, TypeVar

from controlflow.tasks.task import Task

T = TypeVar("T")


class EdgeType(Enum):
    """
    Edges represent the relationship between two tasks in a graph.

    - `DEPENDENCY_OF` means that the downstream task depends on the upstream task.
    - `PARENT` means that the downstream task is the parent of the upstream task.

    Example:

    # write paper
        ## write outline
        ## write draft based on outline

    Edges:
    outline -> paper # SUBTASK (outline is a subtask of paper)
    draft -> paper # SUBTASK (draft is a subtask of paper)
    outline -> draft # DEPENDENCY (outline is a dependency of draft)

    """

    DEPENDENCY = "dependency"
    SUBTASK = "subtask"


@dataclass
class Edge:
    upstream: Task
    downstream: Task
    type: EdgeType

    def __repr__(self):
        return f"{self.type}: {self.upstream.friendly_name()} -> {self.downstream.friendly_name()}"

    def __hash__(self) -> id:
        return hash((id(self.upstream), id(self.downstream), self.type))


class Graph:
    def __init__(self, tasks: list[Task] = None, edges: list[Edge] = None):
        self.tasks: set[Task] = set()
        self.edges: set[Edge] = set()
        self._cache: dict[str[dict[Task, list[Task]]]] = {}
        if tasks:
            for task in tasks:
                self.add_task(task)
        if edges:
            for edge in edges:
                self.add_edge(edge)

    def add_task(self, task: Task):
        if task in self.tasks:
            return

        self.tasks.add(task)

        # add the task's parent
        if task.parent:
            self.add_edge(
                Edge(
                    upstream=task,
                    downstream=task.parent,
                    type=EdgeType.SUBTASK,
                )
            )

        # add the task's subtasks
        for subtask in task.subtasks:
            self.add_edge(
                Edge(
                    upstream=subtask,
                    downstream=task,
                    type=EdgeType.SUBTASK,
                )
            )

        # add the task's dependencies
        for upstream in task.depends_on:
            if upstream not in task._subtasks:
                self.add_edge(
                    Edge(
                        upstream=upstream,
                        downstream=task,
                        type=EdgeType.DEPENDENCY,
                    )
                )
        self._cache.clear()

    def add_edge(self, edge: Edge):
        if edge in self.edges:
            return
        self.edges.add(edge)
        self.add_task(edge.upstream)
        self.add_task(edge.downstream)
        self._cache.clear()

    def upstream_edges(self) -> dict[Task, list[Edge]]:
        if "upstream_edges" not in self._cache:
            graph = {}
            for task in self.tasks:
                graph[task] = []
            for edge in self.edges:
                graph[edge.downstream].append(edge)
            self._cache["upstream_edges"] = graph
        return self._cache["upstream_edges"]

    def downstream_edges(self) -> dict[Task, list[Edge]]:
        if "downstream_edges" not in self._cache:
            graph = {}
            for task in self.tasks:
                graph[task] = []
            for edge in self.edges:
                graph[edge.upstream].append(edge)
            self._cache["downstream_edges"] = graph
        return self._cache["downstream_edges"]

    def upstream_tasks(
        self, start_tasks: list[Task], immediate: bool = False
    ) -> list[Task]:
        """
        Retrieve the upstream tasks (ancestors) of the given start tasks in topological order.

        Args:
            start_tasks (list[Task]): The list of starting tasks.
            immediate (bool): If True, only retrieve immediate upstream tasks.
                              If False, retrieve all upstream tasks recursively.

        Returns:
            list[Task]: A list of upstream tasks in topological order.
        """
        cache_key = (
            f"upstream_{'immediate' if immediate else 'all'}_{tuple(start_tasks)}"
        )
        if cache_key not in self._cache:
            result = set(start_tasks)
            visited = set()

            def _upstream(task):
                if task in visited:
                    return
                visited.add(task)
                for edge in self.upstream_edges().get(task, []):
                    if edge.upstream not in visited:
                        result.add(edge.upstream)
                        if not immediate:
                            _upstream(edge.upstream)

            for task in start_tasks:
                _upstream(task)

            # Perform a focused topological sort on the result
            sorted_tasks = self.topological_sort(list(result))
            self._cache[cache_key] = sorted_tasks

        return self._cache[cache_key]

    def downstream_tasks(
        self, start_tasks: list[Task], immediate: bool = False
    ) -> list[Task]:
        """
        Retrieve the downstream tasks (descendants) of the given start tasks in topological order.

        Args:
            start_tasks (list[Task]): The list of starting tasks.
            immediate (bool): If True, only retrieve immediate downstream tasks.
                              If False, retrieve all downstream tasks recursively.

        Returns:
            list[Task]: A list of downstream tasks in topological order.
        """
        cache_key = (
            f"downstream_{'immediate' if immediate else 'all'}_{tuple(start_tasks)}"
        )
        if cache_key not in self._cache:
            result = set(start_tasks)
            visited = set()

            def _downstream(task):
                if task in visited:
                    return
                visited.add(task)
                for edge in self.downstream_edges().get(task, []):
                    if edge.downstream not in visited:
                        result.add(edge.downstream)
                        if not immediate:
                            _downstream(edge.downstream)

            for task in start_tasks:
                _downstream(task)

            # Perform a focused topological sort on the result
            sorted_tasks = self.topological_sort(list(result))
            self._cache[cache_key] = sorted_tasks

        return self._cache[cache_key]

    def topological_sort(self, tasks: Optional[list[Task]] = None) -> list[Task]:
        """
        Perform a deterministic topological sort on the provided tasks or all tasks in the graph.

        Args:
            tasks (Optional[list[Task]]): A list of tasks to sort topologically.
                                        If None, all tasks in the graph are sorted.

        Returns:
            list[Task]: A list of tasks in topological order (upstream tasks first).
        """
        # Create a cache key based on the input tasks
        cache_key = (
            f"topo_sort_{tuple(sorted(id(task) for task in (tasks or self.tasks)))}"
        )

        # Check if the result is already in the cache
        if cache_key in self._cache:
            return self._cache[cache_key]

        if tasks is None:
            tasks_to_sort = self.tasks
        else:
            tasks_to_sort = set(tasks)

        # Create a dictionary of tasks and their dependencies within tasks_to_sort
        dependencies = {task: set() for task in tasks_to_sort}
        for edge in self.edges:
            if edge.downstream in tasks_to_sort and edge.upstream in tasks_to_sort:
                dependencies[edge.downstream].add(edge.upstream)

        # Kahn's algorithm for topological sorting
        result = []
        no_incoming = [task for task in tasks_to_sort if not dependencies[task]]
        # sort to create a deterministic order
        no_incoming.sort(key=lambda t: t.created_at)

        while no_incoming:
            task = no_incoming.pop(0)
            result.append(task)

            # Remove the task from the dependencies of its neighbors
            for dependent_task in tasks_to_sort:
                if task in dependencies[dependent_task]:
                    dependencies[dependent_task].remove(task)
                    if not dependencies[dependent_task]:
                        no_incoming.append(dependent_task)
                        # resort to maintain deterministic order
                        no_incoming.sort(key=lambda t: t.created_at)

        # Check for cycles
        if len(result) != len(tasks_to_sort):
            raise ValueError(
                "The graph contains a cycle and cannot be topologically sorted"
            )

        # Cache the result before returning
        self._cache[cache_key] = result
        return result



================================================
FILE: src/controlflow/handlers/__init__.py
================================================
[Empty file]


================================================
FILE: src/controlflow/handlers/callback_handler.py
================================================
"""
A handler that calls a callback function for each event.
"""

from typing import TYPE_CHECKING, Any, Callable, Coroutine

from controlflow.events.base import Event
from controlflow.orchestration.handler import AsyncHandler, Handler


class CallbackHandler(Handler):
    def __init__(self, callback: Callable[[Event], None]):
        self.callback = callback

    def on_event(self, event: Event):
        self.callback(event)


class AsyncCallbackHandler(AsyncHandler):
    def __init__(self, callback: Callable[[Event], Coroutine[Any, Any, None]]):
        self.callback = callback

    async def on_event(self, event: Event):
        await self.callback(event)



================================================
FILE: src/controlflow/handlers/print_handler.py
================================================
import datetime
from typing import Optional, Union

import rich
from pydantic import BaseModel
from rich import box
from rich.console import Group
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.spinner import Spinner
from rich.table import Table

from controlflow.events.events import AgentContentDelta, AgentToolCallDelta, ToolResult
from controlflow.events.orchestrator_events import (
    OrchestratorEnd,
    OrchestratorError,
    OrchestratorStart,
)
from controlflow.orchestration.handler import Handler
from controlflow.tools.tools import Tool
from controlflow.utilities.rich import console as cf_console

# Global spinner for consistent animation
RUNNING_SPINNER = Spinner("dots")


class DisplayState(BaseModel):
    """Base class for content to be displayed."""

    agent_name: str
    first_timestamp: datetime.datetime

    def format_timestamp(self) -> str:
        """Format the timestamp for display."""
        local_timestamp = self.first_timestamp.astimezone()
        return local_timestamp.strftime("%I:%M:%S %p").lstrip("0").rjust(11)


class ContentState(DisplayState):
    """State for content being streamed."""

    content: str = ""

    @staticmethod
    def _convert_content_to_str(content) -> str:
        """Convert various content formats to a string."""
        if isinstance(content, str):
            return content

        if isinstance(content, dict):
            return content.get("content", content.get("text", ""))

        if isinstance(content, list):
            parts = []
            for item in content:
                if isinstance(item, str):
                    parts.append(item)
                elif isinstance(item, dict):
                    part = item.get("content", item.get("text", ""))
                    if part:
                        parts.append(part)
            return "\n".join(parts)

        return str(content)

    def update_content(self, new_content) -> None:
        """Update content, converting complex content types to string."""
        self.content = self._convert_content_to_str(new_content)

    def render_panel(self) -> Panel:
        """Render content as a markdown panel."""
        return Panel(
            Markdown(self.content),
            title=f"[bold]Agent: {self.agent_name}[/]",
            subtitle=f"[italic]{self.format_timestamp()}[/]",
            title_align="left",
            subtitle_align="right",
            border_style="blue",
            box=box.ROUNDED,
            width=100,
            padding=(1, 2),
        )


class ToolState(DisplayState):
    """State for a tool call and its result."""

    name: str
    args: dict
    result: Optional[str] = None
    is_error: bool = False
    is_complete: bool = False
    tool: Optional[Tool] = None

    def get_status_style(self) -> tuple[Union[str, Spinner], str, str]:
        """Returns (icon, text style, border style) for current status."""
        if self.is_complete:
            if self.is_error:
                return "❌", "red", "red"
            else:
                return "✅", "green", "green3"  # Slightly softer green
        return (
            RUNNING_SPINNER,
            "yellow",
            "gray50",
        )  # Use shared spinner instance

    def render_completion_tool(
        self, show_inputs: bool = False, show_outputs: bool = False
    ) -> Panel:
        """Special rendering for completion tools."""
        table = Table.grid(padding=0, expand=True)
        header = Table.grid(padding=1)
        header.add_column(width=2)
        header.add_column()

        is_success_tool = self.tool.metadata.get("is_success_tool", False)
        is_fail_tool = self.tool.metadata.get("is_fail_tool", False)
        task = self.tool.metadata.get("completion_task")
        task_name = task.friendly_name() if task else "Unknown Task"
        # completion tools store their results on the task, rather than returning them directly
        task_result = task.result if task else None

        if not self.is_complete:
            icon = RUNNING_SPINNER  # Use shared spinner instance
            message = f"Working on task: {task_name}"
            text_style = "dim"
            border_style = "gray50"
        else:
            if self.is_error:
                icon = "❌"
                message = f"Error marking task status: {task_name}"
                text_style = "red"
                border_style = "red"
                if show_outputs and self.result:
                    message += f"\nError: {self.result}"
            elif is_fail_tool:
                icon = "❌"
                message = f"Task failed: {task_name}"
                text_style = "red"
                border_style = "red"
                if show_outputs and task_result:
                    message += f"\nReason: {task_result}"
            else:
                icon = "✓"
                message = f"Task complete: {task_name}"
                text_style = "dim"
                border_style = "gray50"

        header.add_row(icon, f"[{text_style}]{message}[/]")
        table.add_row(header)

        # Show details (streaming args or final result)
        if show_outputs and self.args:
            details = Table.grid(padding=(0, 2))
            details.add_column(style="dim", width=9)
            details.add_column()

            # If complete and successful, show task_result
            if (
                self.is_complete
                and not self.is_error
                and not is_fail_tool
                and task_result
            ):
                label = "Result" if is_success_tool else "Reason"
                details.add_row(
                    f"    {label}:",
                    f"{task_result}",
                )
            # Otherwise show streaming args
            else:
                label = "Result" if is_success_tool else "Reason"
                details.add_row(
                    f"    {label}:",
                    rich.pretty.Pretty(self.args, indent_size=2, expand_all=True),
                )
            table.add_row(details)

        return Panel(
            table,
            title=f"[bold]Agent: {self.agent_name}[/]",
            subtitle=f"[italic]{self.format_timestamp()}[/]",
            title_align="left",
            subtitle_align="right",
            border_style=border_style,
            box=box.ROUNDED,
            width=100,
            padding=(0, 1),
        )

    def render_panel(
        self,
        show_inputs: bool = True,
        show_outputs: bool = True,
    ) -> Panel:
        """Render tool state as a panel with status indicator."""
        if self.tool and self.tool.metadata.get("is_completion_tool"):
            return self.render_completion_tool(
                show_inputs=show_inputs, show_outputs=show_outputs
            )

        icon, text_style, border_style = self.get_status_style()
        table = Table.grid(padding=0, expand=True)

        header = Table.grid(padding=1)
        header.add_column(width=2)
        header.add_column()
        tool_name = self.name.replace("_", " ").title()
        header.add_row(icon, f"[{text_style} bold]{tool_name}[/]")
        table.add_row(header)

        if show_inputs or show_outputs:
            details = Table.grid(padding=(0, 2))
            details.add_column(style="dim", width=9)
            details.add_column()

            if show_inputs and self.args:
                details.add_row(
                    "    Input:",
                    rich.pretty.Pretty(self.args, indent_size=2, expand_all=True),
                )

            if show_outputs and self.is_complete and self.result:
                label = "Error" if self.is_error else "Output"
                style = "red" if self.is_error else "green3"
                details.add_row(
                    f"    {label}:",
                    f"[{style}]{self.result}[/]",
                )

            table.add_row(details)

        return Panel(
            table,
            title=f"[bold]Agent: {self.agent_name}[/]",
            subtitle=f"[italic]{self.format_timestamp()}[/]",
            title_align="left",
            subtitle_align="right",
            border_style=border_style,
            box=box.ROUNDED,
            width=100,
            padding=(0, 1),
        )


class PrintHandler(Handler):
    def __init__(
        self,
        show_completion_tools: bool = True,
        show_tool_inputs: bool = True,
        show_tool_outputs: bool = True,
        show_completion_tool_results: bool = False,
    ):
        super().__init__()
        # Tool display settings
        self.show_completion_tools = show_completion_tools
        self.show_tool_inputs = show_tool_inputs
        self.show_tool_outputs = show_tool_outputs
        # Completion tool specific settings
        self.show_completion_tool_results = show_completion_tool_results

        self.live: Optional[Live] = None
        self.paused_id: Optional[str] = None
        self.states: dict[str, DisplayState] = {}

    def update_display(self):
        """Render all current state as panels and update display."""
        if not self.live or not self.live.is_started or self.paused_id:
            return

        sorted_states = sorted(self.states.values(), key=lambda s: s.first_timestamp)
        panels = []

        for state in sorted_states:
            if isinstance(state, ToolState):
                is_completion_tool = state.tool and state.tool.metadata.get(
                    "is_completion_tool"
                )

                # Skip completion tools if disabled
                if not self.show_completion_tools and is_completion_tool:
                    continue

                if is_completion_tool:
                    panels.append(
                        state.render_completion_tool(
                            show_outputs=self.show_completion_tool_results
                        )
                    )
                else:
                    panels.append(
                        state.render_panel(
                            show_inputs=self.show_tool_inputs,
                            show_outputs=self.show_tool_outputs,
                        )
                    )
            else:
                panels.append(state.render_panel())

        if panels:
            self.live.update(Group(*panels), refresh=True)

    def on_agent_content_delta(self, event: AgentContentDelta):
        """Handle content delta events by updating content state."""
        if not event.content_delta:
            return
        if event.agent_message_id not in self.states:
            state = ContentState(
                agent_name=event.agent.name,
                first_timestamp=event.timestamp,
            )
            state.update_content(event.content_snapshot)
            self.states[event.agent_message_id] = state
        else:
            state = self.states[event.agent_message_id]
            if isinstance(state, ContentState):
                state.update_content(event.content_snapshot)

        self.update_display()

    def on_agent_tool_call_delta(self, event: AgentToolCallDelta):
        """Handle tool call delta events by updating tool state."""
        # Handle CLI input special case
        if event.tool_call_snapshot["name"] == "cli_input":
            self.paused_id = event.tool_call_snapshot["id"]
            if self.live and self.live.is_started:
                self.live.stop()
            return

        tool_id = event.tool_call_snapshot["id"]
        if tool_id not in self.states:
            self.states[tool_id] = ToolState(
                agent_name=event.agent.name,
                first_timestamp=event.timestamp,
                name=event.tool_call_snapshot["name"],
                args=event.args,
                tool=event.tool,
            )
        else:
            state = self.states[tool_id]
            if isinstance(state, ToolState):
                state.args = event.args

        self.update_display()

    def on_tool_result(self, event: ToolResult):
        """Handle tool result events by updating tool state."""
        # Handle CLI input resume
        if event.tool_result.tool_call["name"] == "cli_input":
            if self.paused_id == event.tool_result.tool_call["id"]:
                self.paused_id = None
                print()
                self.live = Live(
                    console=cf_console,
                    vertical_overflow="visible",
                    auto_refresh=True,
                )
                self.live.start()
            return

        # Skip completion tools if disabled
        if (
            not self.show_completion_tools
            and event.tool_result.tool
            and event.tool_result.tool.metadata.get("is_completion_tool")
        ):
            return

        tool_id = event.tool_result.tool_call["id"]
        if tool_id in self.states:
            state = self.states[tool_id]
            if isinstance(state, ToolState):
                state.is_complete = True
                state.is_error = event.tool_result.is_error
                state.result = event.tool_result.str_result

        self.update_display()

    def on_orchestrator_start(self, event: OrchestratorStart):
        """Initialize live display."""
        self.live = Live(
            console=cf_console,
            vertical_overflow="visible",
            auto_refresh=True,
        )
        self.states.clear()
        try:
            self.live.start()
        except rich.errors.LiveError:
            pass

    def on_orchestrator_end(self, event: OrchestratorEnd):
        """Clean up live display."""
        if self.live and self.live.is_started:
            self.live.stop()

    def on_orchestrator_error(self, event: OrchestratorError):
        """Clean up live display on error."""
        if self.live and self.live.is_started:
            self.live.stop()



================================================
FILE: src/controlflow/handlers/queue_handler.py
================================================
"""
A handler that queues events in a queue.
"""

import asyncio
import queue
from typing import TYPE_CHECKING, Any, Callable, Coroutine

from controlflow.events.base import Event
from controlflow.events.events import (
    AgentMessage,
    AgentMessageDelta,
    AgentToolCall,
    ToolResult,
)
from controlflow.orchestration.handler import AsyncHandler, Handler


class QueueHandler(Handler):
    def __init__(
        self, queue: queue.Queue = None, event_filter: Callable[[Event], bool] = None
    ):
        self.queue = queue or queue.Queue()
        self.event_filter = event_filter

    def on_event(self, event: Event):
        if self.event_filter and not self.event_filter(event):
            return
        self.queue.put(event)


class AsyncQueueHandler(AsyncHandler):
    def __init__(
        self, queue: asyncio.Queue = None, event_filter: Callable[[Event], bool] = None
    ):
        self.queue = queue or asyncio.Queue()
        self.event_filter = event_filter

    async def on_event(self, event: Event):
        if self.event_filter and not self.event_filter(event):
            return
        await self.queue.put(event)


def message_filter(event: Event) -> bool:
    return isinstance(event, (AgentMessage, AgentMessageDelta))


def tool_filter(event: Event) -> bool:
    return isinstance(event, (AgentToolCall, ToolResult))


def result_filter(event: Event) -> bool:
    return isinstance(event, (AgentToolCall, ToolResult)) and event.tool_call[
        "name"
    ].startswith("mark_task_")



================================================
FILE: src/controlflow/llm/__init__.py
================================================
from controlflow.llm import models, messages, rules



================================================
FILE: src/controlflow/llm/messages.py
================================================
from langchain_core.messages import (
    AIMessage,
    AIMessageChunk,
    BaseMessage,
    HumanMessage,
    InvalidToolCall,
    SystemMessage,
    ToolCall,
    ToolCallChunk,
    ToolMessage,
)

__all__ = [
    "AIMessage",
    "AIMessageChunk",
    "BaseMessage",
    "HumanMessage",
    "InvalidToolCall",
    "SystemMessage",
    "ToolCall",
    "ToolCallChunk",
    "ToolMessage",
]



================================================
FILE: src/controlflow/llm/models.py
================================================
import inspect
from typing import Any, Optional

from langchain_core.language_models import BaseChatModel
from pydantic import ValidationError

import controlflow
from controlflow.utilities.general import unwrap
from controlflow.utilities.logging import get_logger

logger = get_logger(__name__)


def get_default_model() -> BaseChatModel:
    if getattr(controlflow.defaults, "model", None) is None:
        return get_model(controlflow.settings.llm_model)
    else:
        return controlflow.defaults.model


def get_model(
    model: str, temperature: Optional[float] = None, **kwargs: Any
) -> BaseChatModel:
    """Get a model from a string."""
    if "/" not in model:
        raise ValueError(
            f"The model `{model}` is not valid. Please specify the provider "
            "and model name, e.g. 'openai/gpt-4o-mini' or 'anthropic/claude-3-haiku-20240307'."
        )
    provider, model = model.split("/")

    if temperature is None:
        temperature = controlflow.settings.llm_temperature

    if provider == "openai":
        from langchain_openai import ChatOpenAI

        cls = ChatOpenAI
    elif provider == "anthropic":
        from langchain_anthropic import ChatAnthropic

        cls = ChatAnthropic
    elif provider == "azure-openai":
        from langchain_openai import AzureChatOpenAI

        cls = AzureChatOpenAI
    elif provider == "google":
        try:
            from langchain_google_genai import ChatGoogleGenerativeAI
        except ImportError:
            raise ImportError(
                "To use Google as an LLM provider, please install the `langchain_google_genai` package."
            )
        cls = ChatGoogleGenerativeAI
        if temperature is None:
            temperature = 0.7
    elif provider == "groq":
        try:
            from langchain_groq import ChatGroq
        except ImportError:
            raise ImportError(
                "To use Groq as an LLM provider, please install the `langchain_groq` package."
            )
        cls = ChatGroq
        if temperature is None:
            temperature = 0.7
    elif provider == "ollama":
        try:
            from langchain_ollama import ChatOllama
        except ImportError:
            raise ImportError(
                "To use Ollama as an LLM provider, please install the `langchain-ollama` package."
            )
        cls = ChatOllama
    else:
        raise ValueError(
            f"Could not load provider `{provider}` automatically. Please provide the LLM class manually."
        )

    if temperature is not None:
        kwargs["temperature"] = temperature
    return cls(model=model, **kwargs)


def _get_initial_default_model() -> BaseChatModel:
    # special error messages for the initial attempt to create a model
    try:
        return get_model(controlflow.settings.llm_model)
    except Exception as exc:
        if isinstance(exc, ValidationError) and "Did not find openai_api_key" in str(
            exc
        ):
            msg = unwrap("""
                The default LLM model could not be created because the OpenAI
                API key was not found. ControlFlow will continue to work, but
                you must manually provide an LLM model for each agent. Please
                set the OPENAI_API_KEY environment variable or choose a
                different default LLM model. For more information, please see
                https://controlflow.ai/guides/configure-llms.
                """).replace("\n", " ")
        else:
            msg = (
                unwrap("""
                The default LLM model could not be created. ControlFlow will
                continue to work, but you must manually provide an LLM model for
                each agent. For more information, please see
                https://controlflow.ai/guides/configure-llms. The error was:
                """).replace("\n", " ")
                + f"\n{exc}"
            )
        logger.warning(msg)



================================================
FILE: src/controlflow/llm/rules.py
================================================
import textwrap
from typing import Any, Optional, Union

from langchain_anthropic import ChatAnthropic
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from pydantic import Field

from controlflow.llm.models import BaseChatModel
from controlflow.utilities.general import ControlFlowModel, unwrap


class LLMRules(ControlFlowModel):
    """
    LLM rules let us tailor DAG compilation, message generation, tool use, and
    other behavior to the requirements of different LLM provider APIs.

    Rules can be added here (to the base class) and overridden in subclasses, if
    necessary.
    """

    model: Any

    # require at least one non-system message
    require_at_least_one_message: bool = False

    # system messages are supported as a role
    allow_system_messages: bool = True

    # system messages can only be provided as the very first message in a thread
    require_system_message_first: bool = False

    # other than a system message, the first message must be from the user
    require_user_message_after_system: bool = False

    # the last message in a thread can't be from an AI if tool use is allowed
    allow_last_message_from_ai_when_using_tools: bool = True

    # consecutive AI messages must be separated by a user message
    allow_consecutive_ai_messages: bool = True

    # add system messages to identify speakers in multi-agent conversations
    # (some APIs can use the `name` field for this purpose, but others can't)
    add_system_messages_for_multi_agent: bool = False

    # if a tool is used, the result must follow the tool call immediately
    tool_result_must_follow_tool_call: bool = True

    # the name associated with a message must conform to a specific format
    require_message_name_format: Optional[str] = None

    def model_instructions(self) -> Optional[list[str]]:
        pass


class OpenAIRules(LLMRules):
    require_message_name_format: str = r"[^a-zA-Z0-9_-]"

    model: Any

    def model_instructions(self) -> list[str]:
        instructions = []
        return instructions


class AnthropicRules(LLMRules):
    require_at_least_one_message: bool = True
    require_system_message_first: bool = True
    require_user_message_after_system: bool = True
    allow_last_message_from_ai_when_using_tools: bool = False
    allow_consecutive_ai_messages: bool = False


def rules_for_model(model: BaseChatModel) -> LLMRules:
    if isinstance(model, (ChatOpenAI, AzureChatOpenAI)):
        return OpenAIRules(model=model)
    if isinstance(model, ChatAnthropic):
        return AnthropicRules(model=model)

    try:
        from langchain_google_vertexai.model_garden import ChatAnthropicVertex

        if isinstance(model, ChatAnthropicVertex):
            return AnthropicRules(model=model)
    except ImportError:
        pass

    # catchall
    return LLMRules(model=model)



================================================
FILE: src/controlflow/memory/__init__.py
================================================
from .memory import Memory
from .async_memory import AsyncMemory



================================================
FILE: src/controlflow/memory/async_memory.py
================================================
import abc
import re
from typing import Dict, List, Optional, Union

from pydantic import Field, field_validator, model_validator

import controlflow
from controlflow.tools.tools import Tool
from controlflow.utilities.general import ControlFlowModel, unwrap
from controlflow.utilities.logging import get_logger

logger = get_logger("controlflow.memory")


def sanitize_memory_key(key: str) -> str:
    # Remove any characters that are not alphanumeric or underscore
    return re.sub(r"[^a-zA-Z0-9_]", "", key)


class AsyncMemoryProvider(ControlFlowModel, abc.ABC):
    async def configure(self, memory_key: str) -> None:
        """Configure the provider for a specific memory."""
        pass

    @abc.abstractmethod
    async def add(self, memory_key: str, content: str) -> str:
        """Create a new memory and return its ID."""
        pass

    @abc.abstractmethod
    async def delete(self, memory_key: str, memory_id: str) -> None:
        """Delete a memory by its ID."""
        pass

    @abc.abstractmethod
    async def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        """Search for n memories using a string query."""
        pass


class AsyncMemory(ControlFlowModel):
    """
    A memory module is a partitioned collection of memories that are stored in a
    vector database, configured by a MemoryProvider.
    """

    key: str
    instructions: str = Field(
        description="Explain what this memory is for and how it should be used."
    )
    provider: AsyncMemoryProvider = Field(
        default_factory=lambda: controlflow.defaults.memory_provider,
        validate_default=True,
    )

    def __hash__(self) -> int:
        return id(self)

    @field_validator("provider", mode="before")
    @classmethod
    def validate_provider(
        cls, v: Optional[Union[AsyncMemoryProvider, str]]
    ) -> AsyncMemoryProvider:
        if isinstance(v, str):
            return get_memory_provider(v)
        if v is None:
            raise ValueError(
                unwrap(
                    """
                    Memory modules require a MemoryProvider to configure the
                    underlying vector database. No provider was passed as an
                    argument, and no default value has been configured. 
                    
                    For more information on configuring a memory provider, see
                    the [Memory
                    documentation](https://controlflow.ai/patterns/memory), and
                    please review the [default provider
                    guide](https://controlflow.ai/guides/default-memory) for
                    information on configuring a default provider.
                    
                    Please note that if you are using ControlFlow for the first
                    time, this error is expected because ControlFlow does not include
                    vector dependencies by default.
                    """
                )
            )
        return v

    @field_validator("key")
    @classmethod
    def validate_key(cls, v: str) -> str:
        sanitized = sanitize_memory_key(v)
        if sanitized != v:
            raise ValueError(
                "Memory key must contain only alphanumeric characters and underscores"
            )
        return sanitized

    async def _configure_provider(self):
        await self.provider.configure(self.key)
        return self

    async def add(self, content: str) -> str:
        return await self.provider.add(self.key, content)

    async def delete(self, memory_id: str) -> None:
        await self.provider.delete(self.key, memory_id)

    async def search(self, query: str, n: int = 20) -> Dict[str, str]:
        return await self.provider.search(self.key, query, n)

    def get_tools(self) -> List[Tool]:
        return [
            Tool.from_function(
                self.add,
                name=f"store_memory_{self.key}",
                description=f'Create a new memory in Memory: "{self.key}".',
            ),
            Tool.from_function(
                self.delete,
                name=f"delete_memory_{self.key}",
                description=f'Delete a memory by its ID from Memory: "{self.key}".',
            ),
            Tool.from_function(
                self.search,
                name=f"search_memories_{self.key}",
                description=f'Search for memories relevant to a string query in Memory: "{self.key}". Returns a dictionary of memory IDs and their contents.',
            ),
        ]


def get_memory_provider(provider: str) -> AsyncMemoryProvider:
    logger.debug(f"Loading memory provider: {provider}")

    # --- async postgres ---

    if provider.startswith("async-postgres"):
        try:
            import sqlalchemy
        except ImportError:
            raise ImportError(
                """To use async Postgres as a memory provider, please install the `sqlalchemy, `psycopg-pool`,
                    `psycopg-binary`, and `psycopg` packages."""
            )

        import controlflow.memory.providers.postgres as postgres_providers

        return postgres_providers.AsyncPostgresMemory()
    raise ValueError(f'Memory provider "{provider}" could not be loaded from a string.')



================================================
FILE: src/controlflow/memory/memory.py
================================================
import abc
import re
from typing import Dict, List, Optional, Union

from pydantic import Field, field_validator, model_validator

import controlflow
from controlflow.tools.tools import Tool
from controlflow.utilities.general import ControlFlowModel, unwrap
from controlflow.utilities.logging import get_logger

logger = get_logger("controlflow.memory")


def sanitize_memory_key(key: str) -> str:
    # Remove any characters that are not alphanumeric or underscore
    return re.sub(r"[^a-zA-Z0-9_]", "", key)


class MemoryProvider(ControlFlowModel, abc.ABC):
    def configure(self, memory_key: str) -> None:
        """Configure the provider for a specific memory."""
        pass

    @abc.abstractmethod
    def add(self, memory_key: str, content: str) -> str:
        """Create a new memory and return its ID."""
        pass

    @abc.abstractmethod
    def delete(self, memory_key: str, memory_id: str) -> None:
        """Delete a memory by its ID."""
        pass

    @abc.abstractmethod
    def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        """Search for n memories using a string query."""
        pass


class Memory(ControlFlowModel):
    """
    A memory module is a partitioned collection of memories that are stored in a
    vector database, configured by a MemoryProvider.
    """

    key: str
    instructions: str = Field(
        description="Explain what this memory is for and how it should be used."
    )
    provider: MemoryProvider = Field(
        default_factory=lambda: controlflow.defaults.memory_provider,
        validate_default=True,
    )

    def __hash__(self) -> int:
        return id(self)

    @field_validator("provider", mode="before")
    @classmethod
    def validate_provider(
        cls, v: Optional[Union[MemoryProvider, str]]
    ) -> MemoryProvider:
        if isinstance(v, str):
            return get_memory_provider(v)
        if v is None:
            raise ValueError(
                unwrap(
                    """
                    Memory modules require a MemoryProvider to configure the
                    underlying vector database. No provider was passed as an
                    argument, and no default value has been configured. 
                    
                    For more information on configuring a memory provider, see
                    the [Memory
                    documentation](https://controlflow.ai/patterns/memory), and
                    please review the [default provider
                    guide](https://controlflow.ai/guides/default-memory) for
                    information on configuring a default provider.
                    
                    Please note that if you are using ControlFlow for the first
                    time, this error is expected because ControlFlow does not include
                    vector dependencies by default.
                    """
                )
            )
        return v

    @field_validator("key")
    @classmethod
    def validate_key(cls, v: str) -> str:
        sanitized = sanitize_memory_key(v)
        if sanitized != v:
            raise ValueError(
                "Memory key must contain only alphanumeric characters and underscores"
            )
        return sanitized

    @model_validator(mode="after")
    def _configure_provider(self):
        self.provider.configure(self.key)
        return self

    def add(self, content: str) -> str:
        return self.provider.add(self.key, content)

    def delete(self, memory_id: str) -> None:
        self.provider.delete(self.key, memory_id)

    def search(self, query: str, n: int = 20) -> Dict[str, str]:
        return self.provider.search(self.key, query, n)

    def get_tools(self) -> List[Tool]:
        return [
            Tool.from_function(
                self.add,
                name=f"store_memory_{self.key}",
                description=f'Create a new memory in Memory: "{self.key}".',
            ),
            Tool.from_function(
                self.delete,
                name=f"delete_memory_{self.key}",
                description=f'Delete a memory by its ID from Memory: "{self.key}".',
            ),
            Tool.from_function(
                self.search,
                name=f"search_memories_{self.key}",
                description=f'Search for memories relevant to a string query in Memory: "{self.key}". Returns a dictionary of memory IDs and their contents.',
            ),
        ]


def get_memory_provider(provider: str) -> MemoryProvider:
    logger.debug(f"Loading memory provider: {provider}")

    # --- CHROMA ---

    if provider.startswith("chroma"):
        try:
            import chromadb
        except ImportError:
            raise ImportError(
                "To use Chroma as a memory provider, please install the `chromadb` package."
            )

        import controlflow.memory.providers.chroma as chroma_providers

        if provider == "chroma-ephemeral":
            return chroma_providers.ChromaEphemeralMemory()
        elif provider == "chroma-db":
            return chroma_providers.ChromaPersistentMemory()
        elif provider == "chroma-cloud":
            return chroma_providers.ChromaCloudMemory()

    # --- LanceDB ---

    elif provider.startswith("lancedb"):
        try:
            import lancedb
        except ImportError:
            raise ImportError(
                "To use LanceDB as a memory provider, please install the `lancedb` package."
            )

        import controlflow.memory.providers.lance as lance_providers

        return lance_providers.LanceMemory()

    # --- Postgres ---
    elif provider.startswith("postgres"):
        try:
            import sqlalchemy
        except ImportError:
            raise ImportError(
                """To use Postgres as a memory provider, please install the `sqlalchemy, `psycopg-pool`,
                    `psycopg-binary`, and `psycopg` `psycopg2-binary` packages."""
            )

        import controlflow.memory.providers.postgres as postgres_providers

        return postgres_providers.PostgresMemory()

    raise ValueError(f'Memory provider "{provider}" could not be loaded from a string.')



================================================
FILE: src/controlflow/memory/providers/__init__.py
================================================
[Empty file]


================================================
FILE: src/controlflow/memory/providers/chroma.py
================================================
import uuid
from typing import Dict, Optional

import chromadb
from pydantic import Field, PrivateAttr

import controlflow
from controlflow.memory.memory import MemoryProvider


class ChromaMemory(MemoryProvider):
    model_config = dict(arbitrary_types_allowed=True)
    client: chromadb.ClientAPI = Field(
        default_factory=lambda: chromadb.PersistentClient(
            path=str(controlflow.settings.home_path / "memory/chroma")
        )
    )
    collection_name: str = Field(
        "memory-{key}",
        description="""
            Optional; the name of the collection to use. This should be a 
            string optionally formatted with the variable `key`, which 
            will be provided by the memory module. The default is `"memory-{{key}}"`.
            """,
    )

    def get_collection(self, memory_key: str) -> chromadb.Collection:
        return self.client.get_or_create_collection(
            self.collection_name.format(key=memory_key)
        )

    def add(self, memory_key: str, content: str) -> str:
        collection = self.get_collection(memory_key)
        memory_id = str(uuid.uuid4())
        collection.add(
            documents=[content], metadatas=[{"id": memory_id}], ids=[memory_id]
        )
        return memory_id

    def delete(self, memory_key: str, memory_id: str) -> None:
        collection = self.get_collection(memory_key)
        collection.delete(ids=[memory_id])

    def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        results = self.get_collection(memory_key).query(
            query_texts=[query], n_results=n
        )
        return dict(zip(results["ids"][0], results["documents"][0]))


def ChromaEphemeralMemory(**kwargs) -> ChromaMemory:
    return ChromaMemory(client=chromadb.EphemeralClient(**kwargs))


def ChromaPersistentMemory(path: str = None, **kwargs) -> ChromaMemory:
    return ChromaMemory(
        client=chromadb.PersistentClient(
            path=path or str(controlflow.settings.home_path / "memory" / "chroma"),
            **kwargs,
        )
    )


def ChromaCloudMemory(
    tenant: Optional[str] = None,
    database: Optional[str] = None,
    api_key: Optional[str] = None,
    **kwargs,
) -> ChromaMemory:
    return ChromaMemory(
        client=chromadb.CloudClient(
            api_key=api_key or controlflow.settings.chroma_cloud_api_key,
            tenant=tenant or controlflow.settings.chroma_cloud_tenant,
            database=database or controlflow.settings.chroma_cloud_database,
            **kwargs,
        )
    )



================================================
FILE: src/controlflow/memory/providers/lance.py
================================================
import functools
import uuid
from pathlib import Path
from typing import Callable, Dict, Optional

import lancedb
from lancedb.embeddings import get_registry
from lancedb.pydantic import LanceModel, Vector
from pydantic import Field, PrivateAttr

import controlflow
from controlflow.memory.memory import MemoryProvider


class LanceMemory(MemoryProvider):
    uri: Path = Field(
        default=controlflow.settings.home_path / "memory" / "lancedb",
        description="The URI of the Lance database to use.",
    )
    table_name: str = Field(
        "memory-{key}",
        description="""
            Optional; the name of the table to use. This should be a 
            string optionally formatted with the variable `key`, which 
            will be provCallablethe memory module. The default is `"memory-{{key}}"`.
            """,
    )
    embedding_fn: Callable = Field(
        default_factory=lambda: get_registry()
        .get("openai")
        .create(name="text-embedding-ada-002"),
        description="The LanceDB embedding function to use. Defaults to `get_registry().get('openai').create(name='text-embedding-ada-002')`.",
    )
    _cached_model: Optional[LanceModel] = None

    def get_model(self) -> LanceModel:
        if self._cached_model is None:
            fn = self.embedding_fn

            class Memory(LanceModel):
                id: str = Field(..., description="The ID of the memory.")
                text: str = fn.SourceField()
                vector: Vector(fn.ndims()) = fn.VectorField()  # noqa

            self._cached_model = Memory

        return self._cached_model

    def get_db(self) -> lancedb.DBConnection:
        return lancedb.connect(self.uri)

    def get_table(self, memory_key: str) -> lancedb.table.Table:
        table_name = self.table_name.format(key=memory_key)
        db = self.get_db()
        model = self.get_model()
        try:
            return db.open_table(table_name)
        except FileNotFoundError:
            return db.create_table(table_name, schema=model)

    def add(self, memory_key: str, content: str) -> str:
        memory_id = str(uuid.uuid4())
        table = self.get_table(memory_key)
        table.add([{"id": memory_id, "text": content}])
        return memory_id

    def delete(self, memory_key: str, memory_id: str) -> None:
        table = self.get_table(memory_key)
        table.delete(f'id = "{memory_id}"')

    def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        table = self.get_table(memory_key)
        results = table.search(query).limit(n).to_pydantic(self.get_model())
        return {r.id: r.text for r in results}



================================================
FILE: src/controlflow/memory/providers/postgres.py
================================================
import uuid
from typing import Callable, Dict, Optional

# async pg
import anyio
import sqlalchemy
from pgvector.sqlalchemy import Vector
from pydantic import Field
from sqlalchemy import Column, String, select, text
from sqlalchemy.dialects.postgresql import ARRAY
from sqlalchemy.exc import ProgrammingError
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.orm import Session, declarative_base, sessionmaker
from sqlalchemy_utils import create_database, database_exists

import controlflow
from controlflow.memory.async_memory import AsyncMemoryProvider
from controlflow.memory.memory import MemoryProvider

try:
    # For embeddings, we can use langchain_openai or any other library:
    from langchain_openai import OpenAIEmbeddings
except ImportError:
    raise ImportError(
        "To use an embedding function similar to LanceDB's default, "
        "please install lancedb with: pip install lancedb"
    )

# SQLAlchemy base class for declarative models
Base = declarative_base()


class SQLMemoryTable(Base):
    """
    A simple declarative model that represents a memory record.

    We’ll dynamically set the __tablename__ at runtime.
    """

    __abstract__ = True
    id = Column(String, primary_key=True)
    text = Column(String)
    # Use pgvector for storing embeddings in a Postgres Vector column
    # vector = Column(Vector(dim=1536))  # Adjust dimension to match your embedding model


class PostgresMemory(MemoryProvider):
    """
    A ControlFlow MemoryProvider that stores text + embeddings in PostgreSQL
    using SQLAlchemy and pg_vector. Each Memory module gets its own table.
    """

    # Default database URL. You can point this to your actual Postgres instance.
    # Requires the pgvector extension installed and the sqlalchemy-pgvector package.
    database_url: str = Field(
        default="postgresql://user:password@localhost:5432/your_database",
        description="SQLAlchemy-compatible database URL to a Postgres instance with pgvector.",
    )
    table_name: str = Field(
        "memory_{key}",
        description="""
            Name of the table to store this memory partition. "{key}" will be replaced 
            by the memory’s key attribute.
        """,
    )

    embedding_dimension: int = Field(
        default=1536,
        description="Dimension of the embedding vectors. Match your model's output.",
    )

    embedding_fn: OpenAIEmbeddings = Field(
        default_factory=lambda: OpenAIEmbeddings(
            model="text-embedding-ada-002",
        ),
        description="A function that turns a string into a vector.",
    )

    # Connection pool settings
    pool_size: int = Field(
        5,
        description="Number of connections to keep open in the pool.",
    )

    max_overflow: int = Field(
        10,
        description="Number of connections to allow that can overflow the pool.",
    )

    pool_timeout: int = Field(
        30,
        description="Number of seconds to wait before giving up on getting a connection.",
    )

    pool_recycle: int = Field(
        1800,
        description="Number of seconds a connection can be idle before being recycled.",
    )

    pool_pre_ping: bool = Field(
        True,
        description="Check the connection health upon checkout.",
    )

    # Internal: keep a cached Session maker
    _SessionLocal: Optional[sessionmaker] = None

    # This dict will map "table_name" -> "model class"
    _table_class_cache: Dict[str, Base] = {}

    def configure(self, memory_key: str) -> None:
        """
        Configure a SQLAlchemy session w/connection pooling and ensure the table for this
        memory partition is created if it does not already exist.
        """
        engine = sqlalchemy.create_engine(
            self.database_url,
            pool_size=self.pool_size,
            max_overflow=self.max_overflow,
            pool_timeout=self.pool_timeout,
            pool_recycle=self.pool_recycle,
            pool_pre_ping=self.pool_pre_ping,
        )

        # 2) If DB doesn't exist, create it!
        if not database_exists(engine.url):
            create_database(engine.url)

        with engine.connect() as conn:
            conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            conn.commit()

        self._SessionLocal = sessionmaker(bind=engine)

        # Dynamically create a specialized table model for this memory_key
        table_name = self.table_name.format(key=memory_key)

        # 1) Check if table already in metadata
        if table_name not in Base.metadata.tables:
            # 2) Create the dynamic class + table
            memory_model = type(
                f"SQLMemoryTable_{memory_key}",
                (SQLMemoryTable,),
                {
                    "__tablename__": table_name,
                    "vector": Column(Vector(dim=self.embedding_dimension)),
                },
            )

            try:
                Base.metadata.create_all(engine, tables=[memory_model.__table__])
                # Store it in the cache
                self._table_class_cache[table_name] = memory_model
            except ProgrammingError as e:
                raise RuntimeError(f"Failed to create table {table_name}: {e}")

    def _get_session(self) -> Session:
        if not self._SessionLocal:
            raise RuntimeError(
                "Session is not initialized. Make sure to call configure() first."
            )
        return self._SessionLocal()

    def _get_table(self, memory_key: str) -> Base:
        """
        Return a dynamically generated declarative model class
        mapped to the memory_{key} table. Each memory partition
        has a separate table.
        """
        table_name = self.table_name.format(key=memory_key)

        # Return the cached class if already built
        if table_name in self._table_class_cache:
            return self._table_class_cache[table_name]

        # If for some reason it's not there, create it now (or raise error):
        memory_model = type(
            f"SQLMemoryTable_{memory_key}",
            (SQLMemoryTable,),
            {
                "__tablename__": table_name,
                "vector": Column(Vector(dim=self.embedding_dimension)),
            },
        )
        self._table_class_cache[table_name] = memory_model
        return memory_model

    def add(self, memory_key: str, content: str) -> str:
        """
        Insert a new memory record into the Postgres table,
        generating an embedding and storing it in a vector column.
        Returns the memory’s ID (uuid).
        """
        memory_id = str(uuid.uuid4())
        model_cls = self._get_table(memory_key)

        # Generate an embedding for the content
        embedding = self.embedding_fn.embed_query(content)

        with self._get_session() as session:
            record = model_cls(id=memory_id, text=content, vector=embedding)
            session.add(record)
            session.commit()

        return memory_id

    def delete(self, memory_key: str, memory_id: str) -> None:
        """
        Delete a memory record by its UUID.
        """
        model_cls = self._get_table(memory_key)

        with self._get_session() as session:
            session.query(model_cls).filter(model_cls.id == memory_id).delete()
            session.commit()

    def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        """
        Uses pgvector’s approximate nearest neighbor search with the `<->` operator to find
        the top N matching records for the embedded query. Returns a dict of {id: text}.
        """
        model_cls = self._get_table(memory_key)
        # Generate embedding for the query
        query_embedding = self.embedding_fn.embed_query(query)
        embedding_col = model_cls.vector

        with self._get_session() as session:
            results = session.execute(
                select(model_cls.id, model_cls.text)
                .order_by(embedding_col.l2_distance(query_embedding))
                .limit(n)
            ).all()

        return {row.id: row.text for row in results}


class AsyncPostgresMemory(AsyncMemoryProvider):
    """
    An async MemoryProvider storing text + embeddings in PostgreSQL
    using SQLAlchemy + pg_vector, but with full async support.
    """

    database_url: str = Field(
        default="postgresql+asyncpg://user:password@localhost:5432/your_database",
        description="Async Postgres URL with the asyncpg driver, e.g. "
        "'postgresql+asyncpg://user:pass@host:5432/dbname'.",
    )

    table_name: str = Field(
        "memory_{key}",
        description="""
            Name of the table for this memory partition. "{key}" gets replaced by the memory key.
        """,
    )

    embedding_dimension: int = Field(
        default=1536,
        description="Dimension of the embedding vectors. Must match your model output size.",
    )

    embedding_fn: OpenAIEmbeddings = Field(
        default_factory=lambda: OpenAIEmbeddings(model="text-embedding-ada-002"),
        description="Function that turns a string into a numeric vector.",
    )

    # -- Pool / Engine settings (SQLAlchemy will do the pooling)
    pool_size: int = Field(
        5, description="Number of permanent connections in the async pool."
    )
    max_overflow: int = Field(
        10, description="Number of 'overflow' connections if the pool is full."
    )
    pool_timeout: int = Field(
        30, description="Seconds to wait for a connection before raising an error."
    )
    pool_recycle: int = Field(
        1800,
        description="Recycle connections after N seconds to avoid stale connections.",
    )
    pool_pre_ping: bool = Field(
        True, description="Check connection health before using from the pool."
    )

    # We'll store an async engine + session factory:
    _engine: Optional[AsyncEngine] = None
    _SessionLocal: Optional[async_sessionmaker[AsyncSession]] = None

    # Cache for dynamically generated table classes
    _table_class_cache: Dict[str, Base] = {}

    _configured: bool = False

    async def configure(self, memory_key: str) -> None:
        """
        1) Create an async engine.
        2) Optionally create the DB if it doesn't exist (requires sync workaround).
        3) Install pgvector extension.
        4) Generate the memory table if missing.
        5) Initialize the async sessionmaker.
        """
        if self._configured:
            return
        # 1) Create an async engine. Use the asyncpg dialect.
        #    The pool settings are configured in 'create_async_engine' with 'pool_size', etc.
        else:
            self._engine = create_async_engine(
                self.database_url,
                pool_size=self.pool_size,
                max_overflow=self.max_overflow,
                pool_timeout=self.pool_timeout,
                pool_recycle=self.pool_recycle,
                pool_pre_ping=self.pool_pre_ping,
            )

            exists = await anyio.to_thread.run_sync(database_exists, self.database_url)
            if not exists:
                await anyio.to_thread.run_sync(create_database, self.database_url)

            # 3) Run migrations / create extension in an async context:
            async with self._engine.begin() as conn:
                # Create the pgvector extension if not exists
                await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
                # We'll create the table for the memory_key specifically
                # (1) Build the dynamic table class
                table_name = self.table_name.format(key=memory_key)
                if table_name not in Base.metadata.tables:
                    memory_model = type(
                        f"SQLMemoryTable_{memory_key}",
                        (SQLMemoryTable,),
                        {
                            "__tablename__": table_name,
                            "vector": Column(Vector(dim=self.embedding_dimension)),
                        },
                    )
                    self._table_class_cache[table_name] = memory_model

                    # (2) Actually create it (async):
                    def _sync_create(connection):
                        """Helper function to run table creation in sync context."""
                        Base.metadata.create_all(
                            connection, tables=[memory_model.__table__]
                        )

                    try:
                        await conn.run_sync(_sync_create)
                    except ProgrammingError as e:
                        raise RuntimeError(
                            f"Failed to create table '{table_name}': {e}"
                        )

            # 4) Now that the DB and table are ready, create a session factory
            self._SessionLocal = async_sessionmaker(
                self._engine,
                expire_on_commit=False,
            )

            self._configured = True

    def _get_table(self, memory_key: str) -> Base:
        """
        Return or create the dynamic model class for 'memory_{key}' table.
        """
        table_name = self.table_name.format(key=memory_key)
        if table_name in self._table_class_cache:
            return self._table_class_cache[table_name]

        # If not found, define it at runtime (we won't auto-create it here though)
        memory_model = type(
            f"SQLMemoryTable_{memory_key}",
            (SQLMemoryTable,),
            {
                "__tablename__": table_name,
                "vector": Column(Vector(dim=self.embedding_dimension)),
            },
        )
        self._table_class_cache[table_name] = memory_model
        return memory_model

    async def add(self, memory_key: str, content: str) -> str:
        """
        Insert a new record with an embedding vector.
        Returns the inserted record's UUID.
        """
        # lazy config
        if not self._configured:
            await self.configure(memory_key)

        if not self._SessionLocal:
            raise RuntimeError("Call 'configure(...)' before using this provider.")

        memory_id = str(uuid.uuid4())
        model_cls = self._get_table(memory_key)
        embedding = self.embedding_fn.embed_query(content)

        async with self._SessionLocal() as session:
            record = model_cls(
                id=memory_id,
                text=content,
                vector=embedding,
            )
            session.add(record)
            await session.commit()

        return memory_id

    async def delete(self, memory_key: str, memory_id: str) -> None:
        """
        Delete a record by UUID.
        """
        # lazy config
        if not self._configured:
            await self.configure(memory_key)

        if not self._SessionLocal:
            raise RuntimeError("Not configured. Call 'configure(...)' first.")

        model_cls = self._get_table(memory_key)

        async with self._SessionLocal() as session:
            await session.execute(
                sqlalchemy.delete(model_cls).where(model_cls.id == memory_id)
            )
            await session.commit()

    async def search(self, memory_key: str, query: str, n: int = 20) -> Dict[str, str]:
        """
        Async nearest-neighbor search via pgvector <-> operator or .l2_distance(),
        returning up to N results as {id: text}.
        """

        # lazy config
        if not self._configured:
            await self.configure(memory_key)

        if not self._SessionLocal:
            raise RuntimeError("Not configured. Call 'configure(...)' first.")

        model_cls = self._get_table(memory_key)
        embedding = self.embedding_fn.embed_query(query)
        embedding_col = model_cls.vector

        async with self._SessionLocal() as session:
            # Example using l2_distance:
            results = await session.execute(
                select(model_cls.id, model_cls.text)
                .order_by(embedding_col.l2_distance(embedding))
                .limit(n)
            )
            rows = results.all()

        # Convert list of Row objects -> dict
        return {row.id: row.text for row in rows}



================================================
FILE: src/controlflow/orchestration/__init__.py
================================================
from . import conditions
from .orchestrator import Orchestrator
from .handler import Handler



================================================
FILE: src/controlflow/orchestration/conditions.py
================================================
import logging
from typing import TYPE_CHECKING, Any, Callable, Optional, Union

from pydantic import BaseModel, field_validator

from controlflow.utilities.general import ControlFlowModel
from controlflow.utilities.logging import get_logger

if TYPE_CHECKING:
    from controlflow.orchestration.orchestrator import Orchestrator
    from controlflow.tasks.task import Task

logger = get_logger(__name__)


class RunContext(ControlFlowModel):
    """
    Context for a run.
    """

    model_config = dict(arbitrary_types_allowed=True)

    orchestrator: "Orchestrator"
    llm_calls: int = 0
    agent_turns: int = 0
    run_end_condition: "RunEndCondition"

    @field_validator("run_end_condition", mode="before")
    def validate_condition(cls, v: Any) -> "RunEndCondition":
        if not isinstance(v, RunEndCondition):
            v = FnCondition(v)
        return v

    def should_end(self) -> bool:
        return self.run_end_condition.should_end(self)


class RunEndCondition:
    def should_end(self, context: RunContext) -> bool:
        """
        Returns True if the run should end, False otherwise.
        """
        return False

    def __or__(
        self, other: Union["RunEndCondition", Callable[[RunContext], bool]]
    ) -> "RunEndCondition":
        if isinstance(other, RunEndCondition):
            return OR_(self, other)
        elif callable(other):
            return OR_(self, FnCondition(other))
        else:
            raise NotImplementedError(
                f"Cannot combine RunEndCondition with {type(other)}"
            )

    def __and__(
        self, other: Union["RunEndCondition", Callable[[RunContext], bool]]
    ) -> "RunEndCondition":
        if isinstance(other, RunEndCondition):
            return AND_(self, other)
        elif callable(other):
            return AND_(self, FnCondition(other))
        else:
            raise NotImplementedError(
                f"Cannot combine RunEndCondition with {type(other)}"
            )


class FnCondition(RunEndCondition):
    def __init__(self, fn: Callable[[RunContext], bool]):
        self.fn = fn

    def should_end(self, context: RunContext) -> bool:
        result = self.fn(context)
        if result:
            logger.debug("Custom function condition met; ending run.")
        return result


class OR_(RunEndCondition):
    def __init__(self, *conditions: RunEndCondition):
        self.conditions = conditions

    def should_end(self, context: RunContext) -> bool:
        result = any(condition.should_end(context) for condition in self.conditions)
        if result:
            logger.debug("At least one condition in OR clause met.")
        return result


class AND_(RunEndCondition):
    def __init__(self, *conditions: RunEndCondition):
        self.conditions = conditions

    def should_end(self, context: RunContext) -> bool:
        result = all(condition.should_end(context) for condition in self.conditions)
        if result:
            logger.debug("All conditions in AND clause met.")
        return result


class AllComplete(RunEndCondition):
    def __init__(self, tasks: Optional[list["Task"]] = None):
        self.tasks = tasks

    def should_end(self, context: RunContext) -> bool:
        tasks = self.tasks if self.tasks is not None else context.orchestrator.tasks
        result = all(t.is_complete() for t in tasks)
        if result:
            logger.debug("All tasks are complete; ending run.")
        return result


class AnyComplete(RunEndCondition):
    def __init__(self, tasks: Optional[list["Task"]] = None, min_complete: int = 1):
        self.tasks = tasks
        if min_complete < 1:
            raise ValueError("min_complete must be at least 1")
        self.min_complete = min_complete

    def should_end(self, context: RunContext) -> bool:
        tasks = self.tasks if self.tasks is not None else context.orchestrator.tasks
        result = sum(t.is_complete() for t in tasks) >= self.min_complete
        if result:
            logger.debug("At least one task is complete; ending run.")
        return result


class AnyFailed(RunEndCondition):
    def __init__(self, tasks: Optional[list["Task"]] = None, min_failed: int = 1):
        self.tasks = tasks
        if min_failed < 1:
            raise ValueError("min_failed must be at least 1")
        self.min_failed = min_failed

    def should_end(self, context: RunContext) -> bool:
        tasks = self.tasks if self.tasks is not None else context.orchestrator.tasks
        result = sum(t.is_failed() for t in tasks) >= self.min_failed
        if result:
            logger.debug("At least one task has failed; ending run.")
        return result


class MaxAgentTurns(RunEndCondition):
    def __init__(self, n: int):
        self.n = n

    def should_end(self, context: RunContext) -> bool:
        result = context.agent_turns >= self.n
        if result:
            logger.debug(
                f"Maximum number of agent turns ({self.n}) reached; ending run."
            )
        return result


class MaxLLMCalls(RunEndCondition):
    def __init__(self, n: int):
        self.n = n

    def should_end(self, context: RunContext) -> bool:
        result = context.llm_calls >= self.n
        if result:
            logger.debug(f"Maximum number of LLM calls ({self.n}) reached; ending run.")
        return result



================================================
FILE: src/controlflow/orchestration/handler.py
================================================
import asyncio
from typing import TYPE_CHECKING, Callable, Coroutine, Union

from controlflow.events.base import Event

if TYPE_CHECKING:
    from controlflow.events.events import (
        AgentMessage,
        AgentMessageDelta,
        AgentToolCall,
        EndTurn,
        OrchestratorMessage,
        ToolResult,
        UserMessage,
    )
    from controlflow.events.orchestrator_events import (
        OrchestratorEnd,
        OrchestratorError,
        OrchestratorStart,
    )


class Handler:
    def handle(self, event: Event):
        """
        Handle is called whenever an event is emitted.

        By default, it dispatches to a method named after the event type e.g.
        `self.on_{event_type}(event=event)`.

        The `on_event` method is always called for every event.
        """
        self.on_event(event=event)
        event_type = event.event.replace("-", "_")
        method = getattr(self, f"on_{event_type}", None)
        if method:
            method(event=event)

    def on_event(self, event: Event):
        pass

    def on_orchestrator_start(self, event: "OrchestratorStart"):
        pass

    def on_orchestrator_end(self, event: "OrchestratorEnd"):
        pass

    def on_orchestrator_error(self, event: "OrchestratorError"):
        pass

    def on_agent_message(self, event: "AgentMessage"):
        pass

    def on_agent_message_delta(self, event: "AgentMessageDelta"):
        pass

    def on_tool_call(self, event: "AgentToolCall"):
        pass

    def on_tool_result(self, event: "ToolResult"):
        pass

    def on_orchestrator_message(self, event: "OrchestratorMessage"):
        pass

    def on_user_message(self, event: "UserMessage"):
        pass

    def on_end_turn(self, event: "EndTurn"):
        pass


class AsyncHandler:
    async def handle(self, event: Event):
        """
        Handle is called whenever an event is emitted.

        By default, it dispatches to a method named after the event type e.g.
        `self.on_{event_type}(event=event)`.

        The `on_event` method is always called for every event.
        """
        await self.on_event(event=event)
        event_type = event.event.replace("-", "_")
        method = getattr(self, f"on_{event_type}", None)
        if method:
            await method(event=event)

    async def on_event(self, event: Event):
        pass

    async def on_orchestrator_start(self, event: "OrchestratorStart"):
        pass

    async def on_orchestrator_end(self, event: "OrchestratorEnd"):
        pass

    async def on_orchestrator_error(self, event: "OrchestratorError"):
        pass

    async def on_agent_message(self, event: "AgentMessage"):
        pass

    async def on_agent_message_delta(self, event: "AgentMessageDelta"):
        pass

    async def on_tool_call(self, event: "AgentToolCall"):
        pass

    async def on_tool_result(self, event: "ToolResult"):
        pass

    async def on_orchestrator_message(self, event: "OrchestratorMessage"):
        pass

    async def on_user_message(self, event: "UserMessage"):
        pass

    async def on_end_turn(self, event: "EndTurn"):
        pass



================================================
FILE: src/controlflow/orchestration/orchestrator.py
================================================
import logging
from collections import deque
from contextlib import contextmanager
from typing import AsyncIterator, Callable, Iterator, Optional, Set, TypeVar, Union

from pydantic import BaseModel, Field, PrivateAttr, field_validator

import controlflow
from controlflow.agents.agent import Agent
from controlflow.events.base import Event
from controlflow.events.events import AgentMessageDelta, OrchestratorMessage
from controlflow.events.message_compiler import MessageCompiler
from controlflow.events.orchestrator_events import (
    AgentTurnEnd,
    AgentTurnStart,
    OrchestratorEnd,
    OrchestratorError,
    OrchestratorStart,
)
from controlflow.flows import Flow
from controlflow.instructions import get_instructions
from controlflow.llm.messages import BaseMessage
from controlflow.memory import Memory
from controlflow.memory.async_memory import AsyncMemory
from controlflow.orchestration.conditions import (
    AllComplete,
    FnCondition,
    MaxAgentTurns,
    MaxLLMCalls,
    RunContext,
    RunEndCondition,
)
from controlflow.orchestration.handler import AsyncHandler, Handler
from controlflow.orchestration.turn_strategies import Popcorn, TurnStrategy
from controlflow.tasks.task import Task
from controlflow.tools.tools import Tool, as_tools
from controlflow.utilities.context import ctx
from controlflow.utilities.general import ControlFlowModel
from controlflow.utilities.prefect import prefect_task

logger = logging.getLogger(__name__)

T = TypeVar("T")


class Orchestrator(ControlFlowModel):
    """
    The orchestrator is responsible for managing the flow of tasks and agents.
    It is given tasks to execute in a flow context, and an agent to execute the
    tasks. The turn strategy determines how agents take turns and collaborate.
    """

    model_config = dict(arbitrary_types_allowed=True)
    flow: "Flow" = Field(description="The flow that the orchestrator is managing")
    agent: Optional[Agent] = Field(
        None,
        description="The currently active agent. If not provided, the turn strategy will select one.",
    )
    tasks: list[Task] = Field(description="Tasks to be executed by the agent.")
    turn_strategy: TurnStrategy = Field(
        default=None,
        description="The strategy to use for managing agent turns",
        validate_default=True,
    )
    handlers: list[Union[Handler, AsyncHandler]] = Field(
        None, validate_default=True, exclude=True
    )
    _processed_event_ids: Set[str] = PrivateAttr(default_factory=set)
    _pending_events: deque[Event] = PrivateAttr(default_factory=deque)

    @field_validator("turn_strategy", mode="before")
    def _validate_turn_strategy(cls, v):
        if v is None:
            v = Popcorn()
        return v

    @field_validator("handlers", mode="before")
    def _validate_handlers(cls, v):
        """
        Validate and set default handlers.

        Args:
            v: The input value for handlers.

        Returns:
            list[Handler]: The validated list of handlers.
        """
        from controlflow.handlers.print_handler import PrintHandler

        if v is None and controlflow.settings.enable_default_print_handler:
            v = [
                PrintHandler(
                    show_completion_tools=controlflow.settings.default_print_handler_show_completion_tools,
                    show_completion_tool_results=controlflow.settings.default_print_handler_show_completion_tool_results,
                )
            ]
        return v or []

    def add_event(self, event: Event) -> None:
        """Add an event to be handled and yielded during the next run loop iteration"""
        self._pending_events.append(event)

    def handle_event(self, event: Event) -> Event:
        """
        Handle an event by passing it to all handlers and persisting if necessary.
        Includes idempotency check to prevent double-processing events.
        """
        # Skip if we've already processed this event
        if event.id in self._processed_event_ids:
            return event

        for handler in self.handlers:
            if isinstance(handler, Handler):
                handler.handle(event)
        if event.persist:
            self.flow.add_events([event])

        # Mark event as processed
        self._processed_event_ids.add(event.id)
        return event

    async def handle_event_async(self, event: Event) -> Event:
        """
        Handle an event asynchronously by passing it to all handlers and persisting if necessary.
        Includes idempotency check to prevent double-processing events.

        Args:
            event (Event): The event to handle.
        """
        # Skip if we've already processed this event
        if event.id in self._processed_event_ids:
            return event

        if not isinstance(event, AgentMessageDelta):
            logger.debug(f"Handling event asynchronously: {repr(event)}")
        for handler in self.handlers:
            if isinstance(handler, AsyncHandler):
                await handler.handle(event)
            elif isinstance(handler, Handler):
                handler.handle(event)
        if event.persist:
            self.flow.add_events([event])

        # Mark event as processed
        self._processed_event_ids.add(event.id)
        return event

    def get_available_agents(self) -> dict[Agent, list[Task]]:
        """
        Get a dictionary of all available agents for active tasks, mapped to
        their assigned tasks.

        Returns:
            dict[Agent, list[Task]]
        """
        ready_tasks = self.get_tasks("ready")
        agents = {}
        for task in ready_tasks:
            for agent in task.get_agents():
                agents.setdefault(agent, []).append(task)
        return agents

    def get_tools(self) -> list[Tool]:
        """
        Get all tools available for the current turn.

        Returns:
            list[Tool]: A list of available tools.
        """
        tools = []

        # add flow tools
        tools.extend(self.flow.tools)

        # add task tools
        for task in self.get_tasks("assigned"):
            tools.extend(task.get_tools())

            # add completion tools
            if task.completion_agents is None or self.agent in task.completion_agents:
                tools.extend(task.get_completion_tools())

        # add turn strategy tools only if there are multiple available agents
        available_agents = self.get_available_agents()
        if len(available_agents) > 1:
            tools.extend(self.turn_strategy.get_tools(self.agent, available_agents))

        tools = as_tools(tools)
        return tools

    def get_memories(self) -> list[Union[Memory, AsyncMemory]]:
        memories = set()

        memories.update(self.agent.memories)

        for task in self.get_tasks("assigned"):
            memories.update(task.memories)

        return memories

    def _run_agent_turn(
        self,
        run_context: RunContext,
        model_kwargs: Optional[dict] = None,
    ) -> Iterator[Event]:
        """Run a single agent turn, yielding events as they occur."""
        assigned_tasks = self.get_tasks("assigned")

        self.turn_strategy.begin_turn()

        # Mark assigned tasks as running
        for task in assigned_tasks:
            if not task.is_running():
                task.mark_running()
                yield OrchestratorMessage(
                    content=f"Starting task {task.name + ' ' if task.name else ''}(ID {task.id}) "
                    f"with objective: {task.objective}"
                )

        while not self.turn_strategy.should_end_turn():
            # fail any tasks that have reached their max llm calls
            for task in assigned_tasks:
                if task.max_llm_calls and task._llm_calls >= task.max_llm_calls:
                    task.mark_failed(reason="Max LLM calls reached for this task.")

            # Check if there are any ready tasks left
            if not any(t.is_ready() for t in assigned_tasks):
                logger.debug("No `ready` tasks to run")
                break

            if run_context.should_end():
                break

            messages = self.compile_messages()
            tools = self.get_tools()

            # Run model and yield events
            with ctx(orchestrator=self):
                for event in self.agent._run_model(
                    messages=messages,
                    tools=tools,
                    model_kwargs=model_kwargs,
                ):
                    yield event

            run_context.llm_calls += 1
            for task in assigned_tasks:
                task._llm_calls += 1

        run_context.agent_turns += 1

    @prefect_task(task_run_name="Run agent orchestrator")
    def _run(
        self,
        run_context: RunContext,
        model_kwargs: Optional[dict] = None,
    ) -> Iterator[Event]:
        """Run the orchestrator, yielding handled events as they occur."""
        # Initialize the agent if not already set
        if not self.agent:
            self.agent = self.turn_strategy.get_next_agent(
                None, self.get_available_agents()
            )

        # Signal the start of orchestration
        start_event = OrchestratorStart(orchestrator=self, run_context=run_context)
        self.handle_event(start_event)
        yield start_event

        try:
            while True:
                if run_context.should_end():
                    break

                turn_start = AgentTurnStart(orchestrator=self, agent=self.agent)
                self.handle_event(turn_start)
                yield turn_start

                # Run turn and yield its events
                for event in self._run_agent_turn(
                    run_context=run_context,
                    model_kwargs=model_kwargs,
                ):
                    self.handle_event(event)
                    yield event

                # Handle any events added during the turn
                while self._pending_events:
                    event = self._pending_events.popleft()
                    self.handle_event(event)
                    yield event

                turn_end = AgentTurnEnd(orchestrator=self, agent=self.agent)
                self.handle_event(turn_end)
                yield turn_end

                # Select the next agent for the following turn
                if available_agents := self.get_available_agents():
                    self.agent = self.turn_strategy.get_next_agent(
                        self.agent, available_agents
                    )

        except Exception as exc:
            # Yield error event if something goes wrong
            error_event = OrchestratorError(orchestrator=self, error=exc)
            self.handle_event(error_event)
            yield error_event
            raise
        finally:
            # Signal the end of orchestration
            end_event = OrchestratorEnd(orchestrator=self, run_context=run_context)
            self.handle_event(end_event)
            yield end_event

            # Handle any final pending events
            while self._pending_events:
                event = self._pending_events.popleft()
                self.handle_event(event)
                yield event

    def run(
        self,
        max_llm_calls: Optional[int] = None,
        max_agent_turns: Optional[int] = None,
        model_kwargs: Optional[dict] = None,
        run_until: Optional[
            Union[RunEndCondition, Callable[[RunContext], bool]]
        ] = None,
        stream: bool = False,
    ) -> Union[RunContext, Iterator[Event]]:
        """
        Run the orchestrator.

        Args:
            max_llm_calls: Maximum number of LLM calls allowed
            max_agent_turns: Maximum number of agent turns allowed
            model_kwargs: Additional kwargs for the model
            run_until: Condition for ending the run
            stream: If True, return iterator of events. If False, consume events and return context

        Returns:
            If stream=True, returns Iterator[Event]
            If stream=False, returns RunContext
        """
        # Create run context at the outermost level
        if run_until is None:
            run_until = AllComplete()
        elif not isinstance(run_until, RunEndCondition):
            run_until = FnCondition(run_until)

        # Add max_llm_calls condition
        if max_llm_calls is None:
            max_llm_calls = controlflow.settings.orchestrator_max_llm_calls
        run_until = run_until | MaxLLMCalls(max_llm_calls)

        # Add max_agent_turns condition
        if max_agent_turns is None:
            max_agent_turns = controlflow.settings.orchestrator_max_agent_turns
        run_until = run_until | MaxAgentTurns(max_agent_turns)

        run_context = RunContext(orchestrator=self, run_end_condition=run_until)

        result = self._run(
            run_context=run_context,
            model_kwargs=model_kwargs,
        )

        if stream:
            return result
        else:
            for _ in result:
                pass
            return run_context

    @prefect_task(task_run_name="Run agent orchestrator")
    async def _run_async(
        self,
        run_context: RunContext,
        model_kwargs: Optional[dict] = None,
    ) -> AsyncIterator[Event]:
        """Run the orchestrator asynchronously, yielding handled events as they occur."""
        # Initialize the agent if not already set
        if not self.agent:
            self.agent = self.turn_strategy.get_next_agent(
                None, self.get_available_agents()
            )

        # Signal the start of orchestration
        start_event = OrchestratorStart(orchestrator=self, run_context=run_context)
        await self.handle_event_async(start_event)
        yield start_event

        try:
            while True:
                if run_context.should_end():
                    break

                turn_start = AgentTurnStart(orchestrator=self, agent=self.agent)
                await self.handle_event_async(turn_start)
                yield turn_start

                # Run turn and yield its events
                async for event in self._run_agent_turn_async(
                    run_context=run_context,
                    model_kwargs=model_kwargs,
                ):
                    await self.handle_event_async(event)
                    yield event

                # Handle any events added during the turn
                while self._pending_events:
                    event = self._pending_events.popleft()
                    await self.handle_event_async(event)
                    yield event

                turn_end = AgentTurnEnd(orchestrator=self, agent=self.agent)
                await self.handle_event_async(turn_end)
                yield turn_end

                # Select the next agent for the following turn
                if available_agents := self.get_available_agents():
                    self.agent = self.turn_strategy.get_next_agent(
                        self.agent, available_agents
                    )

        except Exception as exc:
            # Yield error event if something goes wrong
            error_event = OrchestratorError(orchestrator=self, error=exc)
            await self.handle_event_async(error_event)
            yield error_event
            raise
        finally:
            # Signal the end of orchestration
            end_event = OrchestratorEnd(orchestrator=self, run_context=run_context)
            await self.handle_event_async(end_event)
            yield end_event

            # Handle any final pending events
            while self._pending_events:
                event = self._pending_events.popleft()
                await self.handle_event_async(event)
                yield event

    async def run_async(
        self,
        max_llm_calls: Optional[int] = None,
        max_agent_turns: Optional[int] = None,
        model_kwargs: Optional[dict] = None,
        run_until: Optional[
            Union[RunEndCondition, Callable[[RunContext], bool]]
        ] = None,
        stream: bool = False,
    ) -> Union[RunContext, AsyncIterator[Event]]:
        """
        Run the orchestrator asynchronously.

        Args:
            max_llm_calls: Maximum number of LLM calls allowed
            max_agent_turns: Maximum number of agent turns allowed
            model_kwargs: Additional kwargs for the model
            run_until: Condition for ending the run
            stream: If True, return async iterator of events. If False, consume events and return context

        Returns:
            If stream=True, returns AsyncIterator[Event]
            If stream=False, returns RunContext
        """
        # Create run context at the outermost level
        if run_until is None:
            run_until = AllComplete()
        elif not isinstance(run_until, RunEndCondition):
            run_until = FnCondition(run_until)

        # Add max_llm_calls condition
        if max_llm_calls is None:
            max_llm_calls = controlflow.settings.orchestrator_max_llm_calls
        run_until = run_until | MaxLLMCalls(max_llm_calls)

        # Add max_agent_turns condition
        if max_agent_turns is None:
            max_agent_turns = controlflow.settings.orchestrator_max_agent_turns
        run_until = run_until | MaxAgentTurns(max_agent_turns)

        run_context = RunContext(orchestrator=self, run_end_condition=run_until)

        result = self._run_async(
            run_context=run_context,
            model_kwargs=model_kwargs,
        )

        if stream:
            return result
        else:
            async for _ in result:
                pass
            return run_context

    def compile_prompt(self) -> str:
        """
        Compile the prompt for the current turn.

        Returns:
            str: The compiled prompt.
        """
        from controlflow.orchestration.prompt_templates import (
            InstructionsTemplate,
            LLMInstructionsTemplate,
            MemoryTemplate,
            TasksTemplate,
            ToolTemplate,
        )

        llm_rules = self.agent.get_llm_rules()

        prompts = [
            self.agent.get_prompt(),
            self.flow.get_prompt(),
            TasksTemplate(tasks=self.get_tasks("ready")).render(),
            ToolTemplate(tools=self.get_tools()).render(),
            MemoryTemplate(memories=self.get_memories()).render(),
            InstructionsTemplate(instructions=get_instructions()).render(),
            LLMInstructionsTemplate(
                instructions=llm_rules.model_instructions()
            ).render(),
        ]

        prompt = "\n\n".join([p for p in prompts if p])
        logger.debug(f"{'=' * 10}\nCompiled prompt: {prompt}\n{'=' * 10}")
        return prompt

    def compile_messages(self) -> list[BaseMessage]:
        """
        Compile messages for the current turn.

        Returns:
            list[BaseMessage]: The compiled messages.
        """
        events = self.flow.get_events(limit=100)

        compiler = MessageCompiler(
            events=events,
            llm_rules=self.agent.get_llm_rules(),
            system_prompt=self.compile_prompt(),
        )
        messages = compiler.compile_to_messages(agent=self.agent)
        return messages

    def get_tasks(self, filter: str = "assigned") -> list[Task]:
        """
        Collect tasks based on the specified filter.

        Args:
            filter (str): Determines which tasks to return.
                - "ready": Tasks ready to execute (no unmet dependencies).
                - "assigned": Ready tasks assigned to the current agent.
                - "all": All tasks including subtasks, dependencies, and direct ancestors of root tasks.

        Returns:
            list[Task]: List of tasks based on the specified filter.
        """
        if filter not in ["ready", "assigned", "all"]:
            raise ValueError(f"Invalid filter: {filter}")

        all_tasks: set[Task] = set()
        ready_tasks: list[Task] = []

        def collect_tasks(task: Task):
            if task in all_tasks:
                return
            all_tasks.add(task)

            # Collect subtasks
            for subtask in task.subtasks:
                collect_tasks(subtask)

            # Collect dependencies
            for dependency in task.depends_on:
                collect_tasks(dependency)

            # Collect parent
            if task.parent and not task.parent.wait_for_subtasks:
                collect_tasks(task.parent)

            # Check if the task is ready
            if task.is_ready():
                ready_tasks.append(task)

        # Collect tasks from self.tasks (root tasks) and their direct ancestors
        for task in self.tasks:
            collect_tasks(task)

            # Collect direct ancestors of root tasks
            current = task.parent
            while current:
                all_tasks.add(current)
                current = current.parent

        if filter == "ready":
            return ready_tasks

        if filter == "assigned":
            return [task for task in ready_tasks if self.agent in task.get_agents()]

        # "all" filter
        return list(all_tasks)

    def get_task_hierarchy(self) -> dict:
        """
        Build a hierarchical structure of all tasks.

        Returns:
            dict: A nested dictionary representing the task hierarchy,
            where each task has 'task' and 'children' keys.
        """
        all_tasks = self.get_tasks("all")

        hierarchy = {}
        task_dict_map = {task.id: {"task": task, "children": []} for task in all_tasks}

        for task in all_tasks:
            if task.parent:
                parent_dict = task_dict_map[task.parent.id]
                parent_dict["children"].append(task_dict_map[task.id])
            else:
                hierarchy[task.id] = task_dict_map[task.id]

        return hierarchy

    async def _run_agent_turn_async(
        self,
        run_context: RunContext,
        model_kwargs: Optional[dict] = None,
    ) -> AsyncIterator[Event]:
        """Async version of _run_agent_turn."""
        assigned_tasks = self.get_tasks("assigned")

        self.turn_strategy.begin_turn()

        # Mark assigned tasks as running
        for task in assigned_tasks:
            if not task.is_running():
                task.mark_running()
                yield OrchestratorMessage(
                    content=f"Starting task {task.name} (ID {task.id}) "
                    f"with objective: {task.objective}"
                )

        while not self.turn_strategy.should_end_turn():
            # fail any tasks that have reached their max llm calls
            for task in assigned_tasks:
                if task.max_llm_calls and task._llm_calls >= task.max_llm_calls:
                    task.mark_failed(reason="Max LLM calls reached for this task.")

            # Check if there are any ready tasks left
            if not any(t.is_ready() for t in assigned_tasks):
                logger.debug("No `ready` tasks to run")
                break

            if run_context.should_end():
                break

            messages = self.compile_messages()
            tools = self.get_tools()

            # Run model and yield events
            with ctx(orchestrator=self):
                async for event in self.agent._run_model_async(
                    messages=messages,
                    tools=tools,
                    model_kwargs=model_kwargs,
                ):
                    yield event

            run_context.llm_calls += 1
            for task in assigned_tasks:
                task._llm_calls += 1

        run_context.agent_turns += 1


# Rebuild all models with forward references after Orchestrator is defined
OrchestratorStart.model_rebuild()
OrchestratorEnd.model_rebuild()
OrchestratorError.model_rebuild()
AgentTurnStart.model_rebuild()
AgentTurnEnd.model_rebuild()
RunContext.model_rebuild()



================================================
FILE: src/controlflow/orchestration/prompt_templates.py
================================================
from typing import Any, Dict, List, Optional, Union

from pydantic import model_validator

from controlflow.agents.agent import Agent
from controlflow.flows import Flow
from controlflow.memory.async_memory import AsyncMemory
from controlflow.memory.memory import Memory
from controlflow.tasks.task import Task
from controlflow.tools.tools import Tool
from controlflow.utilities.general import ControlFlowModel
from controlflow.utilities.jinja import prompt_env


class Template(ControlFlowModel):
    model_config = dict(extra="allow")
    template: Optional[str] = None
    template_path: Optional[str] = None

    @model_validator(mode="after")
    def _validate(self):
        if not self.template and not self.template_path:
            raise ValueError("Template or template_path must be provided.")
        return self

    def render(self, **kwargs) -> str:
        if not self.should_render():
            return ""

        render_kwargs = dict(self)
        del render_kwargs["template"]
        del render_kwargs["template_path"]

        if self.template is not None:
            template = prompt_env.from_string(self.template)
        else:
            template = prompt_env.get_template(self.template_path)
        return template.render(**render_kwargs | kwargs)

    def should_render(self) -> bool:
        return True


class AgentTemplate(Template):
    template_path: str = "agent.jinja"
    agent: Agent


class TasksTemplate(Template):
    template_path: str = "tasks.jinja"
    tasks: List[Task]

    def render(self, **kwargs):
        task_hierarchy = build_task_hierarchy(self.tasks)
        return super().render(task_hierarchy=task_hierarchy, **kwargs)

    def should_render(self) -> bool:
        return bool(self.tasks)


class TaskTemplate(Template):
    """
    Template for the active tasks
    """

    template_path: str = "task.jinja"
    task: Task


class FlowTemplate(Template):
    template_path: str = "flow.jinja"
    flow: Flow


class InstructionsTemplate(Template):
    template_path: str = "instructions.jinja"
    instructions: list[str] = []

    def should_render(self) -> bool:
        return bool(self.instructions)


class LLMInstructionsTemplate(Template):
    template_path: str = "llm_instructions.jinja"
    instructions: Optional[list[str]] = None

    def should_render(self) -> bool:
        return bool(self.instructions)


class ToolTemplate(Template):
    template_path: str = "tools.jinja"
    tools: list[Tool]

    def should_render(self) -> bool:
        return any(t.instructions for t in self.tools)


class MemoryTemplate(Template):
    template_path: str = "memories.jinja"
    memories: list[Union[Memory, AsyncMemory]]

    def should_render(self) -> bool:
        return bool(self.memories)


def build_task_hierarchy(provided_tasks: List[Task]) -> List[Dict[str, Any]]:
    """
    Builds a hierarchical structure of tasks, including all descendants of provided tasks
    and their direct ancestors up to the root.

    This function takes a list of tasks and creates a dictionary representation of the
    task hierarchy. It includes all descendants (subtasks) of the provided tasks and
    all direct ancestors up to the root tasks. The resulting structure allows for
    easy traversal of the task hierarchy.

    Args:
        provided_tasks (List[Task]): The initial list of tasks to build the hierarchy from.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries representing the root tasks.
        Each dictionary contains the following keys:
            - 'task': The Task object
            - 'children': A list of child task dictionaries (recursively structured)
            - 'is_active': Boolean indicating if the task was in the original provided_tasks list

    Example:
        If task A has subtasks B and C, and B has a subtask D, calling
        build_task_hierarchy([B]) would return a structure representing:
        A (is_active: False)
        └── B (is_active: True)
            ├── C (is_active: False)
            └── D (is_active: False)
    """
    task_dict = {}
    active_tasks = set(provided_tasks)

    def collect_descendants(task: Task):
        """Recursively collects all descendants of a task."""
        if task not in task_dict:
            task_dict[task] = {
                "task": task,
                "children": [],
                "is_active": task in active_tasks,
            }
        for subtask in task.subtasks:
            if subtask not in task_dict:
                collect_descendants(subtask)
            task_dict[task]["children"].append(task_dict[subtask])

    def collect_ancestors(task: Task):
        """Recursively collects all direct ancestors of a task."""
        if task.parent and task.parent not in task_dict:
            task_dict[task.parent] = {
                "task": task.parent,
                "children": [],
                "is_active": task.parent in active_tasks,
            }
            collect_ancestors(task.parent)
            task_dict[task.parent]["children"].append(task_dict[task])

    # First pass: Collect all descendants of the provided tasks
    for task in provided_tasks:
        collect_descendants(task)

    # Second pass: Collect all direct ancestors of the provided tasks
    for task in provided_tasks:
        collect_ancestors(task)

    # Get root tasks (those without parents or whose parents are not in the task list)
    roots = [
        v for k, v in task_dict.items() if not k.parent or k.parent not in task_dict
    ]

    # Sort children by creation time
    def sort_children(task_info: dict[str, Any]):
        task_info["children"].sort(key=lambda x: x["task"].created_at)
        for child in task_info["children"]:
            sort_children(child)

    for root in roots:
        sort_children(root)

    return roots



================================================
FILE: src/controlflow/orchestration/turn_strategies.py
================================================
import random
from abc import ABC, abstractmethod
from typing import Dict, List, Optional

from controlflow.agents import Agent
from controlflow.tasks.task import Task
from controlflow.tools.tools import Tool, tool
from controlflow.utilities.general import ControlFlowModel


class TurnStrategy(ControlFlowModel, ABC):
    end_turn: bool = False
    next_agent: Optional[Agent] = None

    @abstractmethod
    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        pass

    @abstractmethod
    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        pass

    def begin_turn(self):
        self.end_turn = False
        self.next_agent = None

    def should_end_turn(self) -> bool:
        """
        Determine if the current turn should end.

        Returns:
            bool: True if the turn should end, False otherwise.
        """
        return self.end_turn


def get_end_turn_tool(strategy: TurnStrategy) -> Tool:
    @tool
    def end_turn() -> str:
        """
        End your turn. Only use this tool if you have no other options and
        want a different agent to take over. This tool does not mark tasks as complete.
        """
        strategy.end_turn = True
        return "Turn ended."

    return end_turn


def get_delegate_tool(
    strategy: TurnStrategy, available_agents: dict[Agent, list[Task]]
) -> Tool:
    @tool
    def delegate_to_agent(agent_id: str, message: str = None) -> str:
        """Delegate to another agent and optionally send a message."""
        if len(available_agents) <= 1:
            return "Cannot delegate as there are no other available agents."
        next_agent = next(
            (a for a in available_agents.keys() if a.id == agent_id), None
        )
        if next_agent is None:
            raise ValueError(f"Agent with ID {agent_id} not found or not available.")
        strategy.end_turn = True
        strategy.next_agent = next_agent
        return f"Delegated to agent {next_agent.name} with ID {agent_id}"

    return delegate_to_agent


class SingleAgent(TurnStrategy):
    agent: Agent

    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        return [get_end_turn_tool(self)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        if self.agent not in available_agents:
            raise ValueError(
                "The agent specified by the turn strategy is not available."
            )
        return self.agent


class Popcorn(TurnStrategy):
    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        return [get_delegate_tool(self, available_agents)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        if self.next_agent and self.next_agent in available_agents:
            return self.next_agent
        return next(iter(available_agents))


class Random(TurnStrategy):
    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        return [get_end_turn_tool(self)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        return random.choice(list(available_agents.keys()))


class RoundRobin(TurnStrategy):
    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        return [get_end_turn_tool(self)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        agents = list(available_agents.keys())
        if current_agent is None or current_agent not in agents:
            return agents[0]
        current_index = agents.index(current_agent)
        next_index = (current_index + 1) % len(agents)
        return agents[next_index]


class MostBusy(TurnStrategy):
    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        return [get_end_turn_tool(self)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        # Select the agent with the most tasks
        return max(available_agents, key=lambda agent: len(available_agents[agent]))


class Moderated(TurnStrategy):
    moderator: Agent

    def get_tools(
        self, current_agent: Agent, available_agents: dict[Agent, list[Task]]
    ) -> list[Tool]:
        if current_agent == self.moderator:
            return [get_delegate_tool(self, available_agents)]
        else:
            return [get_end_turn_tool(self)]

    def get_next_agent(
        self, current_agent: Optional[Agent], available_agents: Dict[Agent, List[Task]]
    ) -> Agent:
        if current_agent is None or current_agent is self.moderator:
            return (
                self.next_agent
                if self.next_agent in available_agents
                else self.moderator
            )
        else:
            return self.moderator



================================================
FILE: src/controlflow/orchestration/prompt_templates/agent.jinja
================================================
# Agent

I am a workflow orchestrator. You are an AI agent. I am assigning you tasks to complete. Follow all instructions
carefully. Note that I can not respond to your messages.

Your name is {{agent.name}}.

{% if agent.description %}
Your description is: {{ agent.description }}
{% endif %}

{% if agent.instructions %}
Your instructions are: {{ agent.instructions }}
{% endif %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/flow.jinja
================================================
# Flow

Here is context about the flow/thread you are participating in.

- Name: {{ flow.name }}
{% if flow.description %}
- Description: {{ flow.description }}
{% endif %}
{% if flow.context %}
Context:
{% for key, value in flow.context.items() %}
- {{ key }}: {{ value }}
{% endfor %}
{% endif %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/instructions.jinja
================================================
# Instructions

You must follow these instructions at all times. Note that instructions can be changed at any time.

{% for instruction in instructions %}
- {{ instruction }}

{% endfor %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/llm_instructions.jinja
================================================
# LLM Instructions

These instructions are specific to your LLM model. They must be followed to ensure compliance with the orchestrator and
other agents.

{% for instruction in instructions %}
- {{ instruction }}

{% endfor %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/memories.jinja
================================================
# Memories

You have the following memory modules installed. Consult your memory whenever
you think it would be helpful, and make sure to add new memories when you learn
something new. You should not refer directly to memories in your responses.

{% for memory in memories %}
## Memory: {{ memory.key }}

Instructions: {{ memory.instructions }}

{% endfor %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/task.jinja
================================================
- id: {{ task.id }}
{% if task.name %}- name: {{ task.name }}{% endif %}
- objective: {{ task.objective }}
{% if task.instructions %}- instructions: {{ task.instructions }}{% endif %}
{% if task.result_type %}- result type: {{ task.result_type }}{% endif %}
{% if task.context %}- context: {{ task.context }}{% endif %}
{% if task.parent %}- parent task ID: {{ task.parent.id }}{%endif %}
{% if task._subtasks%}- this task has the following subtask IDs: {{ task._subtasks | map(attribute='id') | join(', ') }}
{% if not task.wait_for_subtasks %}- complete this task as soon as you meet its objective, even if you haven't completed
its subtasks{% endif%}{% endif %}
{% if task.depends_on %}- this task depends on these upstream task IDs (includes subtasks): {{ task.depends_on |
map(attribute='id') | join(', ') }}{% endif %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/tasks.jinja
================================================
{% macro render_task_hierarchy(task_info, indent='') %}
{{ indent }}- {{ task_info.task.id }} ({{ task_info.task.status.value }}){% if task_info['is_active'] %}
(active){%endif%}
{%- if task_info.children %}

{% for child in task_info.children %}
{{ render_task_hierarchy(child, indent + '-') }}
{% endfor %}
{%- endif %}
{%- endmacro -%}

# Active Tasks

The following tasks are active:

{% for task in tasks %}
<Task ID {{ task.id }}>
    Assigned agents: {{ task._serialize_agents(task.get_agents()) }}
    {% if task.completion_agents -%}
    Completion agents: {{ task._serialize_agents(task.completion_agents) }}
    {% endif %}

    {{ task.get_prompt() }}
</Task>


{% endfor %}

Only agents assigned to a task are able to mark the task as complete. You must
use a tool to end your turn to let other agents participate. If you are asked to
talk to other agents, post messages. Do not impersonate another agent! Do not
impersonate the orchestrator! If you have been assigned a task, then you (and
other agents) must have the resources, knowledge, or tools required to complete
it.

A task can only be marked complete one time. Do not attempt to mark a task
successful more than once. Even if the `result_type` does not appear to match
the objective, you must supply a single compatible result. Only mark a task
failed if there is a technical error or issue preventing completion.

When a parent task must wait for subtasks, it means that all of its subtasks are
treated as upstream dependencies and must be completed before the parent task
can be marked as complete. However, if the parent task has
`wait_for_subtasks=False`, then it can and should be marked as complete as soon
as you can, regardless of the status of its subtasks.

## Subtask hierarchy

{% for task in task_hierarchy %}
{{ render_task_hierarchy(task) }}
{% endfor %}


================================================
FILE: src/controlflow/orchestration/prompt_templates/tools.jinja
================================================
# Tools

The following tools have additional instructions:

{% for tool in tools %}
{% if tool.instructions %}
## Tool: {{ tool.name }}
{{ tool.instructions }}
{% endif %}
{% endfor %}


================================================
FILE: src/controlflow/planning/__init__.py
================================================
from . import plan



================================================
FILE: src/controlflow/tasks/__init__.py
================================================
from .task import Task



================================================
FILE: src/controlflow/tasks/task.py
================================================
import datetime
import textwrap
import warnings
from contextlib import ExitStack, contextmanager
from enum import Enum
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Generator,
    GenericAlias,
    Iterator,
    Literal,
    Optional,
    TypeVar,
    Union,
    _AnnotatedAlias,
    _GenericAlias,
    _LiteralGenericAlias,
    _SpecialGenericAlias,
)
from uuid import uuid4

from prefect.context import TaskRunContext
from pydantic import (
    BaseModel,
    Field,
    PydanticSchemaGenerationError,
    RootModel,
    TypeAdapter,
    field_serializer,
    field_validator,
)
from pydantic_extra_types.pendulum_dt import DateTime
from typing_extensions import Self

import controlflow
from controlflow.agents import Agent
from controlflow.instructions import get_instructions
from controlflow.memory.async_memory import AsyncMemory
from controlflow.memory.memory import Memory
from controlflow.tools import Tool, tool
from controlflow.tools.input import cli_input
from controlflow.tools.tools import as_tools
from controlflow.utilities.context import ctx
from controlflow.utilities.general import (
    NOTSET,
    ControlFlowModel,
    hash_objects,
    safe_issubclass,
    unwrap,
)
from controlflow.utilities.logging import get_logger

if TYPE_CHECKING:
    from controlflow.events.events import Event
    from controlflow.flows import Flow
    from controlflow.orchestration.handler import AsyncHandler, Handler
    from controlflow.orchestration.turn_strategies import TurnStrategy
    from controlflow.stream import Stream

T = TypeVar("T")
logger = get_logger(__name__)

COMPLETION_TOOLS = Literal["SUCCEED", "FAIL"]


class Labels(RootModel):
    root: tuple[Any, ...]

    def __iter__(self):
        return iter(self.root)

    def __getitem__(self, item):
        return self.root[item]

    def __repr__(self) -> str:
        return f"Labels: {', '.join(self.root)}"


class TaskStatus(Enum):
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    SUCCESSFUL = "SUCCESSFUL"
    FAILED = "FAILED"
    SKIPPED = "SKIPPED"


INCOMPLETE_STATUSES = {TaskStatus.PENDING, TaskStatus.RUNNING}
COMPLETE_STATUSES = {TaskStatus.SUCCESSFUL, TaskStatus.FAILED, TaskStatus.SKIPPED}


class Task(ControlFlowModel):
    id: str = None
    name: Optional[str] = Field(None, description="A name for the task.")
    objective: str = Field(
        ..., description="A brief description of the required result."
    )
    instructions: Union[str, None] = Field(
        None, description="Detailed instructions for completing the task."
    )
    agents: Optional[list[Agent]] = Field(
        default=None,
        description="A list of agents assigned to the task. "
        "If not provided, it will be inferred from the caller, parent task, flow, or global default.",
    )
    context: dict = Field(
        default_factory=dict,
        description="Additional context for the task.",
    )
    parent: Optional["Task"] = Field(
        NOTSET,
        description="The parent task of this task. Subtasks are considered"
        " upstream dependencies of their parents.",
        validate_default=True,
    )
    depends_on: set["Task"] = Field(
        default_factory=set, description="Tasks that this task depends on explicitly."
    )
    prompt: Optional[str] = Field(
        None, description="A prompt to display to the agent working on the task."
    )
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Union[T, str]] = None
    result_type: Union[
        type[T],
        GenericAlias,
        _GenericAlias,
        _SpecialGenericAlias,
        _AnnotatedAlias,
        Labels,
        None,
    ] = Field(
        NOTSET,
        description="The expected type of the result. This should be a type"
        ", generic alias, BaseModel subclass, or list of choices. "
        "Can be None if no result is expected or the agent should communicate internally.",
        validate_default=True,
    )
    result_validator: Optional[Callable] = Field(
        None,
        description="A function that validates the result. This should be a "
        "function that takes the raw result and either returns a validated "
        "result or raises an informative error if the result is not valid. The "
        "result validator function is called *after* the `result_type` is "
        "processed.",
    )
    tools: list[Tool] = Field(
        default_factory=list,
        description="Tools available to every agent working on this task.",
    )
    completion_tools: Optional[list[COMPLETION_TOOLS]] = Field(
        default=None,
        description="""
            Completion tools that will be generated for this task. If None, all 
            tools will be generated; if a list of strings, only the corresponding 
            tools will be generated automatically.
            """,
    )
    completion_agents: Optional[list[Agent]] = Field(
        default=None,
        description="Agents that are allowed to mark this task as complete. If None, all agents are allowed.",
    )
    interactive: bool = False
    memories: list[Union[Memory, AsyncMemory]] = Field(
        default=[],
        description="A list of memory modules for the task to use.",
    )
    max_llm_calls: Optional[int] = Field(
        default_factory=lambda: controlflow.settings.task_max_llm_calls,
        description="Maximum number of LLM calls to make before the task should be marked as failed. "
        "The total calls are measured over the life of the task, and include any LLM call for "
        "which this task is considered `assigned`.",
    )
    created_at: DateTime = Field(default_factory=datetime.datetime.now)
    wait_for_subtasks: bool = Field(
        default=True,
        description="If True, the task will not be considered ready until all subtasks are complete.",
    )
    _subtasks: set["Task"] = set()
    _downstreams: set["Task"] = set()
    _cm_stack: list[contextmanager] = []
    _llm_calls: int = 0

    model_config = dict(extra="forbid", arbitrary_types_allowed=True)

    def __init__(
        self,
        objective: str = None,
        user_access: bool = None,
        **kwargs,
    ):
        """
        Initialize a Task object.

        Args:
            objective (str, optional): The objective of the task. Defaults to None.
            result_type (Any, optional): The type of the result. Defaults to NOTSET.
            user_access (bool, optional): Whether the task is interactive. Defaults to None.
            **kwargs: Additional keyword arguments.
        """
        # allow certain args to be provided as a positional args
        if objective is not None:
            kwargs["objective"] = objective

        if additional_instructions := get_instructions():
            kwargs["instructions"] = (
                kwargs.get("instructions")
                or "" + "\n" + "\n".join(additional_instructions)
            ).strip()

        # deprecated in 0.9
        if user_access:
            warnings.warn(
                "The `user_access` argument is deprecated. Use `interactive=True` instead.",
                DeprecationWarning,
            )
            kwargs["interactive"] = True

        super().__init__(**kwargs)

        # create dependencies to tasks passed in as depends_on
        for task in self.depends_on:
            self.add_dependency(task)

        # create dependencies to tasks passed as subtasks
        if self.parent is not None:
            self.parent.add_subtask(self)

        if self.id is None:
            self.id = self._generate_id()

    def _generate_id(self):
        return str(uuid4())[:8]
        # generate a short, semi-stable ID for a task
        # return hash_objects(
        #     (
        #         type(self).__name__,
        #         self.objective,
        #         self.instructions,
        #         str(self.result_type),
        #         self.prompt,
        #         str(self.context),
        #     )
        # )

    def __hash__(self) -> int:
        return id(self)

    def __eq__(self, other):
        """
        Tasks have set attributes and set equality is based on id() of their
        contents, not equality of objects. This means that two tasks are not
        equal unless their set attributes satisfy an identity criteria, which is
        too strict.
        """
        if type(self) is type(other):
            d1 = dict(self)
            d2 = dict(other)

            for attr in ["id", "created_at"]:
                d1.pop(attr)
                d2.pop(attr)

            # conver sets to lists for comparison
            d1["depends_on"] = list(d1["depends_on"])
            d2["depends_on"] = list(d2["depends_on"])
            d1["subtasks"] = list(self.subtasks)
            d2["subtasks"] = list(other.subtasks)
            return d1 == d2
        return False

    def __repr__(self) -> str:
        serialized = self.model_dump(include={"id", "objective"})
        return f"{self.__class__.__name__}({', '.join(f'{key}={repr(value)}' for key, value in serialized.items())})"

    @field_validator("objective")
    def _validate_objective(cls, v):
        if v:
            v = unwrap(v)
        return v

    @field_validator("instructions")
    def _validate_instructions(cls, v):
        if v:
            v = unwrap(v)
        return v

    @field_validator("agents")
    def _validate_agents(cls, v):
        if isinstance(v, list) and not v:
            raise ValueError("Agents must be `None` or a non-empty list of agents.")
        return v

    @field_validator("parent", mode="before")
    def _default_parent(cls, v):
        if v == NOTSET:
            parent_tasks = ctx.get("tasks", [])
            v = parent_tasks[-1] if parent_tasks else None
        return v

    @field_validator("result_type", mode="before")
    def _validate_result_type(cls, v):
        if v == NOTSET:
            v = str
        if isinstance(v, _LiteralGenericAlias):
            v = v.__args__
        if isinstance(v, (list, tuple, set)):
            v = Labels(v)
        return v

    @field_validator("tools", mode="before")
    def _validate_tools(cls, v):
        return as_tools(v or [])

    @field_serializer("parent")
    def _serialize_parent(self, parent: Optional["Task"]):
        return parent.id if parent is not None else None

    @field_serializer("depends_on")
    def _serialize_depends_on(self, depends_on: set["Task"]):
        return [t.id for t in depends_on]

    @field_serializer("result_type")
    def _serialize_result_type(self, result_type: list["Task"]):
        if result_type is None:
            return None
        try:
            schema = TypeAdapter(result_type).json_schema()
        except PydanticSchemaGenerationError:
            schema = "<schema could not be generated>"

        return dict(type=repr(result_type), schema=schema)

    @field_serializer("agents")
    def _serialize_agents(self, agents: list[Agent]):
        return [agent.serialize_for_prompt() for agent in self.get_agents()]

    @field_serializer("completion_agents")
    def _serialize_completion_agents(self, completion_agents: Optional[list[Agent]]):
        if completion_agents is not None:
            return [agent.serialize_for_prompt() for agent in completion_agents]
        else:
            return None

    @field_serializer("tools")
    def _serialize_tools(self, tools: list[Callable]):
        return [t.serialize_for_prompt() for t in controlflow.tools.as_tools(tools)]

    def friendly_name(self):
        if self.name:
            name = self.name
        elif len(self.objective) > 50:
            name = f'"{self.objective[:50]}..."'
        else:
            name = f'"{self.objective}"'
        return f"Task #{self.id} ({name})"

    def serialize_for_prompt(self) -> dict:
        """
        Generate a prompt to share information about the task, for use in another object's prompt (like Flow)
        """
        return self.model_dump_json()

    @property
    def subtasks(self) -> list["Task"]:
        return list(sorted(self._subtasks, key=lambda t: t.created_at))

    # def subtask(self, **kwargs) -> "Task":
    #     task = Task(**kwargs)
    #     self.add_subtask(task)
    #     return task

    def add_subtask(self, task: "Task"):
        """
        Indicate that this task has a subtask (which becomes an implicit dependency).
        """
        if task.parent is None:
            task.parent = self
        elif task.parent is not self:
            raise ValueError(f"{self.friendly_name()} already has a parent.")
        self._subtasks.add(task)

    def add_dependency(self, task: "Task"):
        """
        Indicate that this task depends on another task.
        """
        self.depends_on.add(task)
        task._downstreams.add(self)

    def run(
        self,
        agent: Optional[Agent] = None,
        flow: "Flow" = None,
        turn_strategy: "TurnStrategy" = None,
        max_llm_calls: int = None,
        max_agent_turns: int = None,
        handlers: list["Handler"] = None,
        raise_on_failure: bool = True,
        model_kwargs: Optional[dict] = None,
        stream: Union[bool, "Stream"] = False,
    ) -> Union[T, Iterator[tuple["Event", Any, Optional[Any]]]]:
        """
        Run the task

        Args:
            agent: Optional agent to run the task
            flow: Optional flow to run the task in
            turn_strategy: Optional turn strategy to use
            max_llm_calls: Maximum number of LLM calls to make
            max_agent_turns: Maximum number of agent turns to make
            handlers: Optional list of handlers
            raise_on_failure: Whether to raise on task failure
            model_kwargs: Optional kwargs to pass to the model
            stream: If True, stream all events. Can also provide StreamFilter flags.

        Returns:
            If not streaming: The task result
            If streaming: Iterator of (event, snapshot, delta) tuples
        """
        result = controlflow.run_tasks(
            tasks=[self],
            flow=flow,
            agent=agent,
            turn_strategy=turn_strategy,
            max_llm_calls=max_llm_calls,
            max_agent_turns=max_agent_turns,
            raise_on_failure=False,
            handlers=handlers,
            model_kwargs=model_kwargs,
            stream=stream,
        )

        if stream:
            return result
        elif self.is_successful():
            return self.result
        elif raise_on_failure and self.is_failed():
            raise ValueError(f"{self.friendly_name()} failed: {self.result}")

    async def run_async(
        self,
        agent: Optional[Agent] = None,
        flow: "Flow" = None,
        turn_strategy: "TurnStrategy" = None,
        max_llm_calls: int = None,
        max_agent_turns: int = None,
        handlers: list[Union["Handler", "AsyncHandler"]] = None,
        raise_on_failure: bool = True,
        stream: Union[bool, "Stream"] = False,
    ) -> T:
        """
        Run the task
        """

        result = await controlflow.run_tasks_async(
            tasks=[self],
            flow=flow,
            agent=agent,
            turn_strategy=turn_strategy,
            max_llm_calls=max_llm_calls,
            max_agent_turns=max_agent_turns,
            raise_on_failure=False,
            handlers=handlers,
            stream=stream,
        )

        if stream:
            return result
        elif self.is_successful():
            return self.result
        elif raise_on_failure and self.is_failed():
            raise ValueError(f"{self.friendly_name()} failed: {self.result}")

    @contextmanager
    def create_context(self) -> Generator[Self, None, None]:
        stack = ctx.get("tasks") or []
        with ctx(tasks=stack + [self]):
            yield self

    def __enter__(self) -> Self:
        # use stack so we can enter the context multiple times
        self._cm_stack.append(ExitStack())
        return self._cm_stack[-1].enter_context(self.create_context())

    def __exit__(self, *exc_info):
        return self._cm_stack.pop().close()

    def is_incomplete(self) -> bool:
        return self.status in INCOMPLETE_STATUSES

    def is_complete(self) -> bool:
        return self.status in COMPLETE_STATUSES

    def is_pending(self) -> bool:
        return self.status == TaskStatus.PENDING

    def is_running(self) -> bool:
        return self.status == TaskStatus.RUNNING

    def is_successful(self) -> bool:
        return self.status == TaskStatus.SUCCESSFUL

    def is_failed(self) -> bool:
        return self.status == TaskStatus.FAILED

    def is_skipped(self) -> bool:
        return self.status == TaskStatus.SKIPPED

    def is_ready(self) -> bool:
        """
        Returns True if all dependencies are complete and this task is
        incomplete, meaning it is ready to be worked on.
        """
        depends_on = self.depends_on
        if self.wait_for_subtasks:
            depends_on = depends_on.union(self._subtasks)

        return self.is_incomplete() and all(t.is_complete() for t in depends_on)

    def get_agents(self) -> list[Agent]:
        if self.agents is not None:
            return self.agents
        elif self.parent:
            return self.parent.get_agents()
        else:
            from controlflow.flows import get_flow

            try:
                flow = get_flow()
            except ValueError:
                flow = None
            if flow and flow.default_agent:
                return [flow.default_agent]
            else:
                return [controlflow.defaults.agent]

    def get_tools(self) -> list[Tool]:
        """
        Return a list of all tools available for the task.

        Note this does not include completion tools, which are handled separately.
        """
        tools = self.tools.copy()
        if self.interactive:
            tools.append(cli_input)
        for memory in self.memories:
            tools.extend(memory.get_tools())
        return as_tools(tools)

    def get_completion_tools(self) -> list[Tool]:
        """
        Return a list of all completion tools available for the task.
        """
        tools = []
        completion_tools = self.completion_tools
        if completion_tools is None:
            completion_tools = ["SUCCEED", "FAIL"]

        if "SUCCEED" in completion_tools:
            tools.append(self.get_success_tool())
        if "FAIL" in completion_tools:
            tools.append(self.get_fail_tool())
        return tools

    def get_prompt(self) -> str:
        """
        Generate a prompt to share information about the task with an agent.
        """
        from controlflow.orchestration import prompt_templates

        template = prompt_templates.TaskTemplate(template=self.prompt, task=self)
        return template.render()

    def set_status(self, status: TaskStatus):
        self.status = status

        # update TUI
        if tui := ctx.get("tui"):
            tui.update_task(self)

    def mark_running(self):
        """Mark the task as running and emit a TaskStart event."""
        self.set_status(TaskStatus.RUNNING)
        if orchestrator := ctx.get("orchestrator"):
            from controlflow.events.task_events import TaskStart

            orchestrator.add_event(TaskStart(task=self))

    def mark_successful(self, result: T = None):
        """Mark the task as successful and emit a TaskSuccess event."""
        self.result = self.validate_result(result)
        self.set_status(TaskStatus.SUCCESSFUL)
        if orchestrator := ctx.get("orchestrator"):
            from controlflow.events.task_events import TaskSuccess

            orchestrator.add_event(TaskSuccess(task=self, result=result))

    def mark_failed(self, reason: Optional[str] = None):
        """Mark the task as failed and emit a TaskFailure event."""
        self.result = reason
        self.set_status(TaskStatus.FAILED)
        if orchestrator := ctx.get("orchestrator"):
            from controlflow.events.task_events import TaskFailure

            orchestrator.add_event(TaskFailure(task=self, reason=reason))

    def mark_skipped(self):
        """Mark the task as skipped and emit a TaskSkipped event."""
        self.set_status(TaskStatus.SKIPPED)
        if orchestrator := ctx.get("orchestrator"):
            from controlflow.events.task_events import TaskSkipped

            orchestrator.add_event(TaskSkipped(task=self))

    def get_success_tool(self) -> Tool:
        """
        Create an agent-compatible tool for marking this task as successful.
        """
        options = {}
        instructions = []
        metadata = {
            "is_completion_tool": True,
            "is_success_tool": True,
            "completion_task": self,
        }
        result_schema = None

        # if the result_type is a tuple of options, then we want the LLM to provide
        # a single integer index instead of writing out the entire option. Therefore
        # we create a tool that describes a series of options and accepts the index
        # as a result.
        if isinstance(self.result_type, Labels):
            result_schema = int
            options = {}
            serialized_options = {}
            for i, option in enumerate(self.result_type):
                options[i] = option
                try:
                    serialized = TypeAdapter(type(option)).dump_python(option)
                except PydanticSchemaGenerationError:
                    serialized = repr(option)
                serialized_options[i] = serialized
            options_str = "\n\n".join(
                f"Option {i}: {option}" for i, option in serialized_options.items()
            )
            instructions.append(
                unwrap(
                    """
                    Provide a single integer as the task result, corresponding to the index
                    of your chosen option. Your options are: 
                    
                    {options_str}
                    """
                ).format(options_str=options_str)
            )

        # otherwise try to load the schema for the result type
        elif self.result_type is not None:
            try:
                # see if the result type is a valid pydantic type
                TypeAdapter(self.result_type)
                result_schema = self.result_type
            except PydanticSchemaGenerationError:
                pass
            if result_schema is None:
                raise ValueError(
                    f"Could not load or infer schema for result type {self.result_type}. "
                    "Please use a custom type or add compatibility."
                )

        # for basemodel subclasses, we accept the model properties directly as kwargs
        if safe_issubclass(result_schema, BaseModel):
            instructions.append(
                unwrap(
                    f"""
                    Use this tool to mark the task as successful and provide a
                    result. The result schema is: {result_schema}
                    """
                )
            )

            def succeed(**kwargs) -> str:
                self.mark_successful(result=result_schema(**kwargs))
                return f"{self.friendly_name()} marked successful."

            return Tool(
                fn=succeed,
                name=f"mark_task_{self.id}_successful",
                description=f"Mark task {self.id} as successful.",
                instructions="\n\n".join(instructions) or None,
                parameters=result_schema.model_json_schema(),
                metadata=metadata,
            )

        # for all other results, we create a single `result` kwarg to capture the result
        elif result_schema is not None:
            instructions.append(
                unwrap(
                    f"""
                    Use this tool to mark the task as successful and provide a
                    `result` value. The `result` value has the following schema:
                    {result_schema}.
                    """
                )
            )

            @tool(
                name=f"mark_task_{self.id}_successful",
                description=f"Mark task {self.id} as successful.",
                instructions="\n\n".join(instructions) or None,
                include_return_description=False,
                metadata=metadata,
            )
            def succeed(result: result_schema) -> str:  # type: ignore
                if self.is_successful():
                    raise ValueError(
                        f"{self.friendly_name()} is already marked successful."
                    )
                if options:
                    if result not in options:
                        raise ValueError(
                            f"Invalid option. Please choose one of {options}"
                        )
                    result = options[result]
                self.mark_successful(result=result)
                return f"{self.friendly_name()} marked successful."

            return succeed
        # for no result schema, we provide a tool that takes no arguments
        else:

            @tool(
                name=f"mark_task_{self.id}_successful",
                description=f"Mark task {self.id} as successful.",
                instructions="\n\n".join(instructions) or None,
                include_return_description=False,
                metadata=metadata,
            )
            def succeed() -> str:
                self.mark_successful()
                return f"{self.friendly_name()} marked successful."

        return succeed

    def get_fail_tool(self) -> Tool:
        """
        Create an agent-compatible tool for failing this task.
        """

        @tool(
            name=f"mark_task_{self.id}_failed",
            description=unwrap(
                f"""Mark task {self.id} as failed. Only use when technical
                 errors prevent success. Provide a detailed reason for the
                 failure."""
            ),
            include_return_description=False,
            metadata={
                "is_completion_tool": True,
                "is_fail_tool": True,
                "completion_task": self,
            },
        )
        def fail(reason: str) -> str:
            self.mark_failed(reason=reason)
            return f"{self.friendly_name()} marked failed."

        return fail

    def validate_result(self, raw_result: Any) -> T:
        if self.result_type is None and raw_result is not None:
            raise ValueError("Task has result_type=None, but a result was provided.")
        elif isinstance(self.result_type, Labels):
            if raw_result not in self.result_type:
                raise ValueError(
                    f"Result {raw_result} is not in the list of valid result types: {self.result_type}"
                )
            else:
                result = raw_result
        elif self.result_type is not None:
            try:
                result = TypeAdapter(self.result_type).validate_python(raw_result)
            except PydanticSchemaGenerationError:
                if isinstance(raw_result, dict):
                    result = self.result_type(**raw_result)
                else:
                    result = self.result_type(raw_result)

        # the raw result is None
        else:
            result = raw_result

            # Convert DataFrame schema back into pd.DataFrame object
            # if result_type == PandasDataFrame:
            #     import pandas as pd

            #     result = pd.DataFrame(**result)
            # elif result_type == PandasSeries:
            #     import pandas as pd

            #     result = pd.Series(**result)

        # apply custom validation
        if self.result_validator is not None:
            result = self.result_validator(result)

        return result


def _generate_result_schema(result_type: type[T]) -> type[T]:
    if result_type is None:
        return None

    result_schema = None
    # try loading pydantic-compatible schemas
    try:
        TypeAdapter(result_type)
        result_schema = result_type
    except PydanticSchemaGenerationError:
        pass
    if result_schema is None:
        raise ValueError(
            f"Could not load or infer schema for result type {result_type}. "
            "Please use a custom type or add compatibility."
        )
    return result_schema



================================================
FILE: src/controlflow/tasks/validators.py
================================================
import re
from typing import Any, Callable, Optional, Sized, TypeVar

T = TypeVar("T")


def chain(*fns: Callable[[T], T]) -> Callable[[T], T]:
    """
    Chain multiple validator functions together.

    This function takes multiple validator functions and returns a new function
    that applies all the validators in sequence. If any validator in the chain
    raises an exception, it will propagate up and stop the validation process.

    Args:
        *fns: Variable number of validator functions to be chained.

    Returns:
        A function that applies all the validator functions in sequence.

    Example:
        >>> def is_even(x: int) -> int:
        ...     if x % 2 != 0:
        ...         raise ValueError("Value must be even")
        ...     return x
        >>> chained = chain(between(min_value=0, max_value=10), is_even)
        >>> chained(4)  # Returns 4
        >>> chained(5)  # Raises ValueError: Value must be even
        >>> chained(12)  # Raises ValueError: Value must be less than or equal to 10
    """

    def chained_validator(value: T) -> T:
        for fn in fns:
            value = fn(value)
        return value

    return chained_validator


def between(
    min_value: Optional[Any] = None,
    max_value: Optional[Any] = None,
) -> Callable[[Any], Any]:
    """
    Create a validator function for values with optional minimum and maximum.

    Args:
        min_value: The minimum allowed value (inclusive). If None, no minimum is enforced.
        max_value: The maximum allowed value (inclusive). If None, no maximum is enforced.

    Returns:
        A function that validates a value based on the specified constraints.

    Raises:
        ValueError: If the value is less than min_value or greater than max_value.

    Example:
        >>> validator = between(min_value=0, max_value=100)
        >>> validator(50)  # Returns 50
        >>> validator(-1)  # Raises ValueError
        >>> validator(101)  # Raises ValueError
    """

    def validate(value: Any) -> Any:
        if min_value is not None and value < min_value:
            raise ValueError(f"Value must be greater than or equal to {min_value}")
        if max_value is not None and value > max_value:
            raise ValueError(f"Value must be less than or equal to {max_value}")
        return value

    return validate


def has_len(
    min_length: Optional[int] = None,
    max_length: Optional[int] = None,
) -> Callable[[Sized], Sized]:
    """
    Create a validator function for any sized object (e.g., list, str, tuple) with optional
    minimum and maximum lengths.

    Args:
        min_length: The minimum allowed length. If None, no minimum is enforced.
        max_length: The maximum allowed length. If None, no maximum is enforced.

    Returns:
        A function that validates a sized object based on the specified length constraints.

    Raises:
        ValueError: If the object length is less than min_length or greater than max_length.

    Example:
        >>> validator = has_len(min_length=2, max_length=5)
        >>> validator([1, 2])  # Returns [1, 2]
        >>> validator("hello")  # Returns "hello"
        >>> validator((1,))  # Raises ValueError
        >>> validator([1, 2, 3, 4, 5, 6])  # Raises ValueError
    """

    def validate(value: Sized) -> Sized:
        if min_length is not None and len(value) < min_length:
            raise ValueError(f"Length must be at least {min_length}")
        if max_length is not None and len(value) > max_length:
            raise ValueError(f"Length must be at most {max_length}")
        return value

    return validate


def is_email() -> Callable[[str], str]:
    """
    Create a validator function for email addresses.

    This validator checks if the given string matches a basic email format.
    It does not perform a comprehensive check against all possible valid email formats,
    but covers most common cases.

    Returns:
        A function that validates an email address string.

    Raises:
        ValueError: If the string is not a valid email address format.

    Example:
        >>> validator = is_email()
        >>> validator("user@example.com")  # Returns "user@example.com"
        >>> validator("invalid-email")  # Raises ValueError
    """
    email_regex = re.compile(r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$")

    def validate(value: str) -> str:
        if not email_regex.match(value):
            raise ValueError("Invalid email address format")
        return value

    return validate


def is_url() -> Callable[[str], str]:
    """
    Create a validator function for URLs.

    This validator checks if the given string matches a basic URL format.
    It does not perform a comprehensive check against all possible valid URL formats,
    but covers most common cases.

    Returns:
        A function that validates a URL string.

    Raises:
        ValueError: If the string is not a valid URL format.

    Example:
        >>> validator = is_url()
        >>> validator("https://www.example.com")  # Returns "https://www.example.com"
        >>> validator("invalid-url")  # Raises ValueError

    """
    url_regex = re.compile(
        r"^((https?:\/\/)?"  # optional protocol
        r"((([a-z\d]([a-z\d-]*[a-z\d])*)\.)+[a-z]{2,}|"  # domain name
        r"((\d{1,3}\.){3}\d{1,3}))"  # OR ip (v4) address
        r"(\:\d+)?(\/[-a-z\d%_.~+]*)*"  # port and path
        r"(\?[;&a-z\d%_.~+=-]*)?"  # query string
        r"(\#[-a-z\d_]*)?$)",  # fragment locator
        re.IGNORECASE,
    )

    def validate(value: str) -> str:
        if not url_regex.match(value):
            raise ValueError("Invalid URL format")
        return value

    return validate


def has_keys(required_keys: set[str]) -> Callable[[dict], dict]:
    """
    Create a validator function for dictionaries to assert that they have certain keys.

    Args:
        required_keys: A set of keys that must be present in the dictionary.

    Returns:
        A function that validates a dictionary based on the specified required keys.

    Raises:
        ValueError: If the dictionary is missing any of the required keys.

    Example:
        >>> validator = has_keys({"name", "age"})
        >>> validator({"name": "John", "age": 30})  # Returns the dict
        >>> validator({"name": "John"})  # Raises ValueError
    """

    def validate(value: dict) -> dict:
        missing_keys = required_keys - set(value.keys())
        if missing_keys:
            raise ValueError(f"Missing required keys: {', '.join(missing_keys)}")
        return value

    return validate



================================================
FILE: src/controlflow/tools/__init__.py
================================================
from controlflow.tools.tools import tool, Tool, as_tools



================================================
FILE: src/controlflow/tools/code.py
================================================
# 🚨 WARNING 🚨
# These functions allow ARBITRARY code execution and should be used with caution.

import json
import subprocess


def shell(command: str) -> str:
    """
    Executes a shell command and returns the output

    NOTE: this tool is not sandboxed and can execute arbitrary code. Be careful.
    """
    result = subprocess.run(command, shell=True, text=True, capture_output=True)

    # Output and error
    output = result.stdout
    error = result.stderr

    return json.dumps(dict(command_output=output, command_error=error))


def python(code: str) -> str:
    """
    Executes Python code on the local machine and returns the output.

    NOTE: this tool is not sandboxed and can execute arbitrary code. Be careful.
    """
    return str(eval(code))



================================================
FILE: src/controlflow/tools/filesystem.py
================================================
import glob as glob_module
import os
import shutil
from pathlib import Path


def _safe_create_file(path: str) -> Path:
    file_path = Path(path).expanduser()
    file_path.parent.mkdir(parents=True, exist_ok=True)
    file_path.touch(exist_ok=True)
    return file_path


def getcwd() -> str:
    """Returns the current working directory"""
    return os.getcwd()


def write(path: str, contents: str) -> str:
    """Creates or overwrites a file with the given contents"""
    path = _safe_create_file(path)
    path.write_text(contents)
    return f'Successfully wrote "{path}"'


def generate_constrained_write(root: str) -> str:
    """
    Returns a `write` function that will only write to files under the given root directory.
    """

    def constrained_write(path: str, contents: str) -> str:
        """
        Write `contents` to a `path`.
        """
        path: Path = Path(path).expanduser().absolute()
        root_path = Path(root).expanduser().absolute()

        if root_path not in path.parents:
            raise ValueError(
                f'Cannot write to "{path}". It\'s not under the root directory "{root_path}"'
            )

        return write(path, contents)

    constrained_write.__doc__ = (
        write.__doc__
        + f'\n\nNote: this function is constrained to files under "{root}".'
    )
    return constrained_write


def delete(path: str, is_dir: bool = False) -> str:
    """Deletes a file or directory based on the is_dir flag."""
    path = Path(path).expanduser()

    if is_dir:
        if path.is_dir():
            shutil.rmtree(path)  # Recursively delete directory and its contents
            return f'Successfully deleted directory "{path}"'
        else:
            return f'Error: "{path}" is not a directory.'
    else:
        if path.is_file():
            path.unlink()  # Delete the file
            return f'Successfully deleted "{path}"'
        else:
            return f'Error: "{path}" is not a file or does not exist.'


def generate_constrained_delete(root: str) -> str:
    """
    Returns a `delete` function that will only write to files under the given root directory.
    """

    def constrained_delete(path: str, is_dir: bool = False) -> str:
        """
        Delete a file or directory at `path`.
        """
        path: Path = Path(path).expanduser().absolute()
        root_path = Path(root).expanduser().absolute()

        if root_path not in path.parents:
            raise ValueError(
                f'Cannot delete "{path}". It\'s not under the root directory "{root_path}"'
            )

        return delete(path, is_dir=is_dir)

    constrained_delete.__doc__ = (
        delete.__doc__
        + f'\n\nNote: this function is constrained to files under "{root}".'
    )

    return constrained_delete


def write_lines(
    path: str, contents: str, insert_line: int = -1, mode: str = "insert"
) -> str:
    """Writes content to a specific line in the file.

    Args:
        path (str): The name of the file to write to.
        contents (str): The content to write to the file.
        insert_line (int, optional): The line number to insert the content at.
            Negative values count from the end of the file. Defaults to -1.
        mode (str, optional): The mode to use when writing the content. Can be
            "insert" or "overwrite". Defaults to "insert".

    Returns:
        str: A message indicating whether the write was successful.
    """
    path = _safe_create_file(path)
    with open(path, "r") as f:
        lines = f.readlines()
        if insert_line < 0:
            insert_line = len(lines) + insert_line + 1
        if mode == "insert":
            lines[insert_line:insert_line] = contents.splitlines(True)
        elif mode == "overwrite":
            lines[insert_line : insert_line + len(contents.splitlines())] = (
                contents.splitlines(True)
            )
        else:
            raise ValueError(f"Invalid mode: {mode}")
    with open(path, "w") as f:
        f.writelines(lines)
    return f'Successfully wrote to "{path}"'


def read(path: str, include_line_numbers: bool = False) -> str:
    """Reads a file and returns the contents.

    Args:
        path (str): The path to the file.
        include_line_numbers (bool, optional): Whether to include line numbers
            in the returned contents. Defaults to False.

    Returns:
        str: The contents of the file.
    """
    path = Path(path).expanduser()
    with open(path, "r") as f:
        if include_line_numbers:
            lines = f.readlines()
            lines_with_numbers = [f"{i+1}: {line}" for i, line in enumerate(lines)]
            return "".join(lines_with_numbers)
        else:
            return f.read()


def read_lines(
    path: str,
    start_line: int = 0,
    end_line: int = -1,
    include_line_numbers: bool = False,
) -> str:
    """Reads a partial file and returns the contents with optional line numbers.

    Args:
        path (str): The path to the file.
        start_line (int, optional): The starting line number to read. Defaults
            to 0.
        end_line (int, optional): The ending line number to read. Defaults to
            -1, which means read until the end of the file.
        include_line_numbers (bool, optional): Whether to include line numbers
            in the returned contents. Defaults to False.

    Returns:
        str: The contents of the file.
    """
    path = os.path.expanduser(path)
    with open(path, "r") as f:
        lines = f.readlines()
        if start_line < 0:
            start_line = len(lines) + start_line
        if end_line < 0:
            end_line = len(lines) + end_line
        if include_line_numbers:
            lines_with_numbers = [
                f"{i+1}: {line}" for i, line in enumerate(lines[start_line:end_line])
            ]
            return "".join(lines_with_numbers)
        else:
            return "".join(lines[start_line:end_line])


def mkdir(path: str) -> str:
    """Creates a directory (and any parent directories))"""
    path = Path(path).expanduser()
    path.mkdir(parents=True, exist_ok=True)
    return f'Successfully created directory "{path}"'


def mv(src: str, dest: str) -> str:
    """Moves a file or directory"""
    src = Path(src).expanduser()
    dest = Path(dest).expanduser()
    src.rename(dest)
    return f'Successfully moved "{src}" to "{dest}"'


def cp(src: str, dest: str) -> str:
    """Copies a file or directory"""
    src = Path(src).expanduser()
    dest = Path(dest).expanduser()
    shutil.copytree(src, dest)
    return f'Successfully copied "{src}" to "{dest}"'


def ls(path: str) -> str:
    """Lists the contents of a directory"""
    path = Path(path).expanduser()
    return "\n".join(str(p) for p in path.iterdir())


def glob(pattern: str) -> list[str]:
    """
    Returns a list of paths matching a valid glob pattern. The pattern can
    include ** for recursive matching, such as '/path/**/dir/*.py'. Only simple
    glob patterns are supported, compound queries like '/path/*.{py, md}' are
    NOT supported.
    """
    return glob_module.glob(pattern, recursive=True)


def concat(source_paths: list[str], dest_path: str, add_headers: bool = True) -> str:
    """
    Concatenates the contents of multiple source files into a single destination
    file. The result should be markdown. If add_headers is True, the file path
    will be added as a header above the contents of each file.

    Note that source paths can include simple glob patterns, such as
    '/path/**/dir/*.py'. Compound queries like '/path/*.{py, md}' are NOT
    supported.
    """
    # source_paths can include glob patterns
    source_paths = [path for pattern in source_paths for path in glob(pattern)]

    dest_path = _safe_create_file(dest_path)
    with open(dest_path, "w") as dest_file:
        for source_path in source_paths:
            source_path = os.path.expanduser(source_path)
            if add_headers:
                dest_file.write(f"\n\n# File: {source_path}\n")
            with open(source_path, "r") as source_file:
                dest_file.write(source_file.read())
    return f'Successfully concatenated files to "{dest_path}"'


def generate_constrained_concat(root: str) -> callable:
    """
    Returns a `concat` function that will only concatenate files under the given root directory.
    """

    def constrained_concat(
        source_paths: list[str], dest_path: str, add_headers: bool = True
    ) -> str:
        root_path = Path(root).expanduser().absolute()

        # Check if destination path is under root directory
        dest_path_abs = Path(dest_path).expanduser().absolute()
        if root_path not in dest_path_abs.parents and dest_path_abs != root_path:
            raise ValueError(
                f'Cannot write to "{dest_path_abs}". It\'s not under the root directory "{root_path}"'
            )

        # Proceed with concatenation
        return concat(source_paths, dest_path, add_headers=add_headers)

    constrained_concat.__doc__ = (
        concat.__doc__
        + f'\n\nNote: this function is constrained to files under "{root}".'
    )

    return constrained_concat


READ_TOOLS = [
    getcwd,
    read,
    read_lines,
    ls,
    glob,
]

WRITE_TOOLS = [
    write,
    write_lines,
    mkdir,
    mv,
    cp,
    delete,
    concat,
]

ALL_TOOLS = READ_TOOLS + WRITE_TOOLS



================================================
FILE: src/controlflow/tools/input.py
================================================
from rich.prompt import Prompt as RichPrompt

from controlflow.tools import tool

INSTRUCTIONS = """
If a task requires you to interact with a user, it will show
`interactive=True` and you will be given this tool. You can use it to send
messages to the user and optionally wait for a response. This is how you
tell the user things and ask questions. Do not mention your tasks or the
workflow. The user can only see messages you send them via tool. They can
not read the rest of the thread. Do not send the user concurrent messages
that require responses, as this will cause confusion.

You may need to ask the human about multiple tasks at once. Consolidate your
questions into a single message. For example, if Task 1 requires information
X and Task 2 needs information Y, send a single message that naturally asks
for both X and Y.

Human users may give poor, incorrect, or partial responses. You may need to
ask questions multiple times in order to complete your tasks. Do not make up
answers for omitted information; ask again and only fail the task if you
truly can not make progress. If your task requires human interaction and
neither it nor any assigned agents have `interactive`, you can fail the
task.
"""


class Prompt(RichPrompt):
    # remove the prompt suffix
    prompt_suffix = " "


@tool(instructions=INSTRUCTIONS, include_return_description=False)
def cli_input(message: str, wait_for_response: bool = True) -> str:
    """
    Send a message to a human user and optionally wait for a response from the CLI
    """

    if wait_for_response:
        result = RichPrompt.ask(
            f"\n[bold blue]🤖 Agent:[/] [blue]{message}[/]\nType your response"
        )
        return f"User response: {result}"

    return "Message sent to user."



================================================
FILE: src/controlflow/tools/tools.py
================================================
import functools
import inspect
import json
import typing
from typing import Annotated, Any, Callable, Optional, Union

import langchain_core.tools
import pydantic
from langchain_core.messages import InvalidToolCall, ToolCall
from prefect.utilities.asyncutils import run_coro_as_sync
from pydantic import Field, PydanticSchemaGenerationError, TypeAdapter

import controlflow
from controlflow.utilities.general import ControlFlowModel, unwrap
from controlflow.utilities.prefect import create_markdown_artifact, prefect_task

TOOL_CALL_FUNCTION_RESULT_TEMPLATE = """
# Tool call: {name}

**Description:** {description}

## Arguments

```json
{args}
```

## Result

```
{result}
```
"""


class Tool(ControlFlowModel):
    name: str = Field(description="The name of the tool")
    description: str = Field(
        description="A description of the tool, which is provided to the LLM"
    )
    instructions: Optional[str] = Field(
        None,
        description="Optional instructions to display to the agent as part of the system prompt"
        " when this tool is available. Tool descriptions have a 1024 "
        "character limit, so this is a way to provide extra detail about behavior.",
    )
    parameters: dict = Field(
        description="The JSON schema for the tool's input parameters"
    )
    metadata: dict = {}

    fn: Callable = Field(None, exclude=True)
    _lc_tool: Optional[langchain_core.tools.BaseTool] = None

    def to_lc_tool(self) -> dict:
        payload = self.model_dump(include={"name", "description", "parameters"})
        return payload

    @prefect_task(task_run_name="Tool call: {self.name}")
    def run(self, input: dict):
        result = self.fn(**input)
        if inspect.isawaitable(result):
            result = run_coro_as_sync(result)

        # prepare artifact
        passed_args = inspect.signature(self.fn).bind(**input).arguments
        try:
            # try to pretty print the args
            passed_args = json.dumps(passed_args, indent=2)
        except Exception:
            pass
        create_markdown_artifact(
            markdown=TOOL_CALL_FUNCTION_RESULT_TEMPLATE.format(
                name=self.name,
                description=self.description or "(none provided)",
                args=passed_args,
                result=result,
            ),
            key="tool-result",
        )
        return result

    @prefect_task(task_run_name="Tool call: {self.name}")
    async def run_async(self, input: dict):
        result = self.fn(**input)
        if inspect.isawaitable(result):
            result = await result

        # prepare artifact
        passed_args = inspect.signature(self.fn).bind(**input).arguments
        try:
            # try to pretty print the args
            passed_args = json.dumps(passed_args, indent=2)
        except Exception:
            pass
        create_markdown_artifact(
            markdown=TOOL_CALL_FUNCTION_RESULT_TEMPLATE.format(
                name=self.name,
                description=self.description or "(none provided)",
                args=passed_args,
                result=result,
            ),
            key="tool-result",
        )
        return result

    @classmethod
    def from_function(
        cls,
        fn: Callable,
        name: Optional[str] = None,
        description: Optional[str] = None,
        instructions: Optional[str] = None,
        include_param_descriptions: bool = True,
        include_return_description: bool = True,
        metadata: Optional[dict] = None,
        **kwargs,
    ):
        name = name or fn.__name__
        description = description or fn.__doc__ or ""
        signature = inspect.signature(fn)

        # If parameters are provided in kwargs, use those instead of generating them
        if "parameters" in kwargs:
            parameters = kwargs.pop("parameters")  # Custom parameters are respected
        else:
            try:
                parameters = TypeAdapter(fn).json_schema()
            except PydanticSchemaGenerationError:
                raise ValueError(
                    f'Could not generate a schema for tool "{name}". '
                    "Tool functions must have type hints that are compatible with Pydantic."
                )

        # load parameter descriptions
        if include_param_descriptions:
            for param in signature.parameters.values():
                # ensure we only try to add descriptions for parameters that exist in the schema
                if param.name not in parameters.get("properties", {}):
                    continue

                # handle Annotated type hints
                if typing.get_origin(param.annotation) is Annotated:
                    param_description = " ".join(
                        str(a) for a in typing.get_args(param.annotation)[1:]
                    )
                # handle pydantic Field descriptions
                elif param.default is not inspect.Parameter.empty and isinstance(
                    param.default, pydantic.fields.FieldInfo
                ):
                    param_description = param.default.description
                else:
                    param_description = None

                if param_description:
                    parameters["properties"][param.name]["description"] = (
                        param_description
                    )

        # Handle return type description

        if (
            include_return_description
            and signature.return_annotation is not inspect._empty
        ):
            return_schema = {}
            try:
                return_schema.update(
                    TypeAdapter(signature.return_annotation).json_schema()
                )
            except PydanticSchemaGenerationError:
                pass
            finally:
                if typing.get_origin(signature.return_annotation) is Annotated:
                    return_schema["annotation"] = " ".join(
                        str(a) for a in typing.get_args(signature.return_annotation)[1:]
                    )

            if return_schema:
                description += f"\n\nReturn value schema: {return_schema}"

        if not description:
            description = "(No description provided)"

        if len(description) > 1024:
            raise ValueError(
                unwrap(f"""
                    {name}: The tool's description exceeds 1024
                    characters. Please provide a shorter description, fewer
                    annotations, or pass
                    `include_param_descriptions=False` or
                    `include_return_description=False` to `from_function`.
                    """)
            )

        return cls(
            name=name,
            description=description,
            parameters=parameters,
            fn=fn,
            instructions=instructions,
            metadata=metadata or {},
            **kwargs,
        )

    @classmethod
    def from_lc_tool(cls, tool: langchain_core.tools.BaseTool, **kwargs):
        fn = tool._run
        return cls(
            name=tool.name,
            description=tool.description,
            parameters=tool.args_schema.schema(),
            fn=fn,
            **kwargs,
        )

    def serialize_for_prompt(self) -> dict:
        return self.model_dump(include={"name", "description", "metadata"})


def tool(
    fn: Optional[Callable] = None,
    *,
    name: Optional[str] = None,
    description: Optional[str] = None,
    instructions: Optional[str] = None,
    include_param_descriptions: bool = True,
    include_return_description: bool = True,
    metadata: Optional[dict] = None,
    **kwargs,
) -> Tool:
    """
    Decorator for turning a function into a Tool
    """
    kwargs.update(
        instructions=instructions,
        include_param_descriptions=include_param_descriptions,
        include_return_description=include_return_description,
        metadata=metadata or {},
    )
    if fn is None:
        return functools.partial(tool, name=name, description=description, **kwargs)
    return Tool.from_function(fn, name=name, description=description, **kwargs)


def as_tools(
    tools: list[Union[Callable, langchain_core.tools.BaseTool, Tool]],
) -> list[Tool]:
    """
    Converts a list of tools (either Tool objects or callables) into a list of
    Tool objects.

    If duplicate tools are found, where the name, function, and coroutine are
    the same, only one is kept.
    """
    seen = set()
    new_tools = []
    for t in tools:
        if isinstance(t, Tool):
            pass
        elif isinstance(t, langchain_core.tools.BaseTool):
            t = Tool.from_lc_tool(t)
        elif inspect.isfunction(t) or inspect.ismethod(t):
            t = Tool.from_function(t)
        elif isinstance(t, dict):
            t = Tool(**t)
        else:
            raise ValueError(f"Invalid tool: {t}")

        if (t.name, t.description) in seen:
            continue
        new_tools.append(t)
        seen.add((t.name, t.description))
    return new_tools


def as_lc_tools(
    tools: list[Union[Callable, langchain_core.tools.BaseTool, Tool]],
) -> list[langchain_core.tools.BaseTool]:
    new_tools = []
    for t in tools:
        if isinstance(t, langchain_core.tools.BaseTool):
            pass
        elif isinstance(t, Tool):
            t = t.to_lc_tool()
        elif inspect.isfunction(t) or inspect.ismethod(t):
            t = langchain_core.tools.StructuredTool.from_function(t)
        else:
            raise ValueError(f"Invalid tool: {t}")
        new_tools.append(t)
    return new_tools


def output_to_string(output: Any) -> str:
    """
    Function outputs must be provided as strings
    """
    if output is None:
        return ""
    elif isinstance(output, str):
        return output
    try:
        return pydantic.TypeAdapter(type(output)).dump_json(output).decode()
    except Exception:
        return str(output)


class ToolResult(ControlFlowModel):
    tool_call: Union[ToolCall, InvalidToolCall]
    tool: Optional[Tool] = None
    result: Any = Field(exclude=True, repr=False)
    str_result: str = Field(repr=False)
    is_error: bool = False


def handle_tool_call(
    tool_call: Union[ToolCall, InvalidToolCall], tools: list[Tool]
) -> ToolResult:
    """
    Given a ToolCall and set of available tools, runs the tool call and returns
    a ToolResult object
    """
    is_error = False
    tool = None
    tool_lookup = {t.name: t for t in tools}
    fn_name = tool_call["name"]

    if fn_name not in tool_lookup:
        fn_output = f'There is no tool called "{fn_name}".'
        is_error = True
        if controlflow.settings.tools_raise_on_error:
            raise ValueError(fn_output)

    if not is_error:
        try:
            tool = tool_lookup[fn_name]
            fn_args = tool_call["args"]
            if isinstance(tool, Tool):
                fn_output = tool.run(input=fn_args)
            elif isinstance(tool, langchain_core.tools.BaseTool):
                fn_output = tool.invoke(input=fn_args)
            else:
                raise ValueError(f"Invalid tool: {tool}")
        except Exception as exc:
            fn_output = f'Error calling function "{fn_name}": {exc}'
            is_error = True
            if controlflow.settings.tools_raise_on_error:
                raise exc

    return ToolResult(
        tool_call=tool_call,
        tool=tool,
        result=fn_output,
        str_result=output_to_string(fn_output),
        is_error=is_error,
    )


async def handle_tool_call_async(tool_call: ToolCall, tools: list[Tool]) -> ToolResult:
    """
    Given a ToolCall and set of available tools, runs the tool call and returns
    a ToolResult object
    """
    is_error = False
    tool = None
    tool_lookup = {t.name: t for t in tools}
    fn_name = tool_call["name"]

    if fn_name not in tool_lookup:
        fn_output = f'There is no tool called "{fn_name}".'
        is_error = True
        if controlflow.settings.tools_raise_on_error:
            raise ValueError(fn_output)

    if not is_error:
        try:
            tool = tool_lookup[fn_name]
            fn_args = tool_call["args"]
            if isinstance(tool, Tool):
                fn_output = await tool.run_async(input=fn_args)
            elif isinstance(tool, langchain_core.tools.BaseTool):
                fn_output = await tool.ainvoke(input=fn_args)
            else:
                raise ValueError(f"Invalid tool: {tool}")
        except Exception as exc:
            fn_output = f'Error calling function "{fn_name}": {exc}'
            is_error = True
            if controlflow.settings.tools_raise_on_error:
                raise exc

    return ToolResult(
        tool_call=tool_call,
        tool=tool,
        result=fn_output,
        str_result=output_to_string(fn_output),
        is_error=is_error,
    )



================================================
FILE: src/controlflow/tools/web.py
================================================
import httpx
from markdownify import markdownify as md


def get_url(
    url: str, clean: bool = True, clean_images: bool = True, clean_links: bool = False
) -> str:
    """
    Make a GET request to the given URL, exactly as provided,
    and return the response text.

    If clean is True, the response text is converted from HTML to a
    Markdown-like format that removes extraneous tags. The `clean_images`
    (removes image tags) and `clean_links` (removes link tags) parameters can be
    used to further clean the text.

    Raises an exception if the response status code is not 2xx.
    """
    response = httpx.get(url)
    response.raise_for_status()
    if clean:
        strip = []
        if clean_images:
            strip.append("img")
        if clean_links:
            strip.append("a")
        return md(response.text, strip=strip)
    return response.text



================================================
FILE: src/controlflow/tui/__init__.py
================================================
from .app import TUIApp



================================================
FILE: src/controlflow/tui/app.py
================================================
import asyncio
from contextlib import asynccontextmanager
from typing import TYPE_CHECKING, Union

from textual.app import App, ComposeResult
from textual.containers import Container
from textual.css.query import NoMatches
from textual.reactive import reactive
from textual.widgets import Footer, Header, Label

import controlflow
import controlflow.utilities
import controlflow.utilities.asyncio
from controlflow.llm.messages import AIMessage, ToolMessage, UserMessage

from .basic import Column, Row
from .task import TUITask
from .thread import TUIMessage, TUIToolMessage

if TYPE_CHECKING:
    import controlflow


class TUIApp(App):
    CSS_PATH = "app.tcss"
    BINDINGS = [
        ("q", "quit", "Quit"),
        ("h", "toggle_hold", "Hold"),
    ]

    agent: reactive["controlflow.Agent"] = reactive(None)
    hold: reactive[bool] = reactive(False)

    def __init__(self, flow: "controlflow.Flow", **kwargs):
        self._flow = flow
        self._tasks = flow.tasks
        self._is_ready = False
        super().__init__(**kwargs)

    @asynccontextmanager
    async def run_context(
        self,
        run: bool = True,
        inline: bool = True,
        inline_stay_visible: bool = True,
        headless: bool = None,
        hold: bool = False,
    ):
        if headless is None:
            headless = controlflow.settings.run_tui_headless

        if run:
            controlflow.utilities.asyncio.create_task(
                self.run_async(
                    inline=inline,
                    inline_no_clear=inline_stay_visible,
                    headless=headless,
                )
            )

            while not self._is_ready:
                await asyncio.sleep(0.01)

            if hold is not None:
                self.hold = hold

        try:
            yield self
        except Exception:
            self.hold = False
            raise
        finally:
            if run:
                while self.hold:
                    await asyncio.sleep(0.01)
                self.exit()

    def exit(self, *args, **kwargs):
        self.hold = False
        self._is_ready = False
        return super().exit(*args, **kwargs)

    def action_toggle_hold(self):
        self.hold = not self.hold

    def watch_hold(self, hold: bool):
        try:
            if hold:
                self.query_one("#hold-banner").display = "block"
            else:
                self.query_one("#hold-banner").display = "none"
        except NoMatches:
            pass

    def on_mount(self):
        if self._flow.name:
            self.title = f"ControlFlow: {self._flow.name}"
        else:
            self.title = "ControlFlow"
        # self.sub_title = "With title and sub-title"
        self._is_ready = True

    # ---------------------------
    #
    # Interaction methods
    #
    # ---------------------------

    def update_task(self, task: "controlflow.Task"):
        try:
            component = self.query_one(f"#task-{task.id}", TUITask)
            component.task = task
            component.scroll_visible()
        except NoMatches:
            new_task = TUITask(task=task, id=f"task-{task.id}")
            self.query_one("#tasks-container", Column).mount(new_task)
            new_task.scroll_visible()

    def update_message(self, message: Union[UserMessage, AIMessage]):
        try:
            component = self.query_one(f"#message-{message.id}", TUIMessage)
            component.message = message
            component.scroll_visible()
        except NoMatches:
            new_message = TUIMessage(message=message, id=f"message-{message.id}")
            self.query_one("#thread-container", Column).mount(new_message)
            new_message.scroll_visible()

    def update_tool_result(self, message: ToolMessage):
        try:
            component = self.query_one(f"#message-{message.id}", TUIToolMessage)
            component.message = message
            component.scroll_visible()
        except NoMatches:
            new_step = TUIToolMessage(message=message, id=f"message-{message.id}")
            self.query_one("#thread-container", Column).mount(new_step)
            new_step.scroll_visible()

    def set_agent(self, agent: "controlflow.Agent"):
        self.agent = agent

    def compose(self) -> ComposeResult:
        yield Header()
        with Container(id="app-container"):
            with Row(id="hold-banner"):
                yield Label(
                    "TUI will stay running after the run ends. Press 'h' to toggle."
                )
            with Row(id="main-container"):
                with Column(id="tasks"):
                    yield Label("Tasks", id="tasks-title", classes="title")
                    with Column(id="tasks-container"):
                        for task in self._tasks.values():
                            yield TUITask(task=task, id=f"task-{task.id}")
                yield Column(id="separator")
                with Column(id="thread"):
                    yield Label("Thread", id="thread-title", classes="title")
                    yield Column(id="thread-container")

        yield Footer()

    # async def get_input(self, message: str, container: list):
    #     self.query_one("#input-container").display = "block"
    #     self._container = container

    # @on(Button.Pressed, "#submit-input")
    # def submit_input(self):
    #     text = self.query_one("#input", TextArea).text
    #     self._container.append(text)
    #     self.query_one("#input-container").display = "none"



================================================
FILE: src/controlflow/tui/app.tcss
================================================
Screen {
    align: center middle;
    width: 100%;
    
    &:inline {
        border: none;
        width: 100%;
        min-height: 30;
        height: 75vh;
        # height: auto;
    }
}

#app-container {
    height: 100%;
}

#hold-banner {
    text-style: italic;
    background: darkred;
}

#main-container {
    height: 100%;
}

Column .title {
    text-align: center;
    text-style: bold;
    background: $primary;
    width: 100%;
    height:1;
}
#tasks {
    width: 40%;
    height: 100%;
    background: $panel;
    # overflow: hidden;
}
#tasks-container{
    height:1fr;
    padding-bottom:1;
}

#separator{
    width: 1;
    height: 100%;
}


#thread {
    height:100%;
}

#thread-container {
    height: 1fr;
    padding-bottom:1;
}

# -------------------------------- 
# Tasks
# -------------------------------- 


TUITask {
    margin-top:0;
    margin-left: 2;
    margin-right: 2;
    border: round white 30%;  
    width: 100%;
}

.task-info-row {
    height: auto;
    width: 1fr;
    margin-top: 0;
    # margin-left: 4;

}

.task-info {
    width: auto;
    color: $text-muted;
    # height: auto;
    margin-left: 1;
    margin-right: 1;
}

 TUITask .status {
    width:3;
}

TUITask .objective {
    color: $text;
    text-style: bold;
    width: 1fr;
}

TUITask .result-collapsible {
    width: 100%;
    border:none;
    padding: 0;
    margin: 0;
    color: $success;
    background: $panel;
}

TUITask .result{
    width: 100%;
}

TUITask .error-collapsible {
    width: 100%;
    border:none;
    padding: 0;
    margin: 0;
    color: $error;
    background: $panel;
}

TUITask .error{
    width: 100%;
}

# --------------------------------
# Input
# --------------------------------

#input-container {
    display: block;
}




================================================
FILE: src/controlflow/tui/basic.py
================================================
from textual.containers import Horizontal, VerticalScroll
from textual.reactive import reactive
from textual.widgets import Label


class Row(Horizontal):
    DEFAULT_CLASSES = "row"
    DEFAULT_CSS = """
        Row {
            height: auto;
        }
    """


class Column(VerticalScroll):
    DEFAULT_CLASSES = "column"
    DEFAULT_CSS = """
        Column {
            height: auto;
        }
    """


class ReactiveLabel(Label):
    value = reactive(None)

    def render(self):
        return str(self.value)



================================================
FILE: src/controlflow/tui/task.py
================================================
from textual.containers import Vertical
from textual.reactive import reactive
from textual.widgets import Collapsible, Label, Static

from controlflow.tasks.task import Task, TaskStatus

from .basic import ReactiveLabel, Row


def bool_to_emoji(value: bool) -> str:
    return "✅" if value else "❌"


class EmojiStatus(Label):
    task: Task = reactive(None, always_update=True)

    def render(self) -> str:
        if self.task.is_ready():
            return "🔜"
        elif self.task.status == TaskStatus.PENDING:
            return "⏳"
        elif self.task.status == TaskStatus.SUCCESSFUL:
            return "✅"
        elif self.task.status == TaskStatus.FAILED:
            return "❌"
        elif self.task.status == TaskStatus.SKIPPED:
            return "⏭️"
        else:
            return "❓"


class TUITask(Static):
    task: Task = reactive(None, always_update=True)
    result: str = reactive(None)
    error_msg: str = reactive(None)

    def __init__(self, task: Task, **kwargs):
        super().__init__(**kwargs)
        self.task = task

    def on_mount(self):
        def refresh():
            self.task = self.task

        # refresh the task periodically in case it goes "ready"
        self.set_interval(1 / 2, refresh)

    def watch_task(self, task: Task):
        if task is None:
            return

        if task.is_ready():
            self.status = "READY"
        else:
            self.status = task.status.value

        self.result = task.result
        if self.is_mounted and self.result is not None:
            if self.status.value == "SUCCESSFUL":
                self.query_one(".result-collapsible", Collapsible).display = "block"
            elif self.status.value == "FAILED":
                self.query_one(".error-collapsible", Collapsible).display = "block"

    def compose(self):
        self.border_title = f"Task {self.task.id}"
        with Row(classes="task-status-row"):
            yield (EmojiStatus(classes="status task-info").data_bind(TUITask.task))
            yield Label(self.task.objective, classes="objective task-info")

        with Vertical(classes="task-info-row"):
            yield Label(
                f"Agents: {', '.join(a.name for a in self.task.get_agents())}",
                classes="interactive task-info",
            )

            # ------------------ success

            result_collapsible = Collapsible(
                title="Result", classes="task-info result-collapsible"
            )
            result_collapsible.display = "none"
            with result_collapsible:
                yield ReactiveLabel(classes="task-info result").data_bind(
                    value=TUITask.result
                )

            # ------------------ failure

            error_collapsible = Collapsible(
                title="Error", classes="task-info error-collapsible"
            )
            error_collapsible.display = "none"
            with error_collapsible:
                yield ReactiveLabel(classes="task-info error").data_bind(
                    value=TUITask.error_msg
                )



================================================
FILE: src/controlflow/tui/test.py
================================================
import asyncio
from math import inf

from pydantic import BaseModel

from controlflow import Task
from controlflow.flows import Flow
from controlflow.llm.messages import AIMessage
from controlflow.tui.app import TUIApp


class Name(BaseModel):
    first: str
    last: str


# Example usage with mock data

with Flow() as flow:
    # t = Task("get the user's name", result_type=str, interactive=True)
    t0 = Task(
        "Introduce yourself",
        # status="SUCCESSFUL",
        result_type=str,
        # result="this is my result",
    )
    t1 = Task(
        objective="Come up with a book title",
        result_type=str,
        depends_on=[t0],
    )
    t2 = Task(
        objective="write a short summary of the book",
        result_type=str,
        context=dict(title=t1),
    )
    t3 = Task(
        objective="rate the book from 1-5 and write a paragraph on why",
        result_type=int,
        depends_on=[t2],
    )


async def run():
    app = TUIApp(flow=flow)
    async with app.run_context(run=True, inline=True, hold=True):
        await asyncio.sleep(1)
        t0.mark_successful(
            result="this is my result\n\n and here is more  and here is more  and here is more and here is more and here is more and here is more\n\n and here is more and here is more and here is more"
        )
        await asyncio.sleep(1)
        t0.mark_failed(reason="this is my result")
        app.update_message(AIMessage(content="hello there"))
        await asyncio.sleep(1)
        app.update_message(AIMessage(content="hello there"))
        await asyncio.sleep(1)
        app.update_message(AIMessage(content="hello there" * 50))
        await asyncio.sleep(1)
        app.update_message(AIMessage(content="hello there"))
        await asyncio.sleep(1)

        await asyncio.sleep(inf)


# run_task = asyncio.create_task(.run_async())


if __name__ == "__main__":
    # asyncio.run(run())
    flow.run()



================================================
FILE: src/controlflow/tui/test2.py
================================================
import asyncio

from controlflow import Task
from controlflow.flows import Flow
from controlflow.tui.app import TUIApp

asyncio
with Flow() as flow:
    t = Task("get the user name", interactive=True)


async def run():
    app = TUIApp(flow=flow)
    async with app.run_context(run=True, inline=True, hold=True, headless=False):
        response = await app.get_input("hello")

    return response


# run_task = asyncio.create_task(.run_async())


if __name__ == "__main__":
    r = asyncio.run(run())
    # print(r)
    # flow.run()



================================================
FILE: src/controlflow/tui/thread.py
================================================
import datetime
from typing import Union

from textual.reactive import reactive
from textual.widgets import Static

from controlflow.llm.formatting import format_message, format_tool_message
from controlflow.llm.messages import AIMessage, ToolMessage, UserMessage


def format_timestamp(timestamp: datetime.datetime) -> str:
    return timestamp.strftime("%l:%M:%S %p")


class TUIMessage(Static):
    message: reactive[Union[UserMessage, AIMessage]] = reactive(
        None, always_update=True, layout=True
    )

    def __init__(self, message: Union[UserMessage, AIMessage], **kwargs):
        super().__init__(**kwargs)
        self.message = message

    def render(self):
        return format_message(self.message)


class TUIToolMessage(Static):
    message: reactive[ToolMessage] = reactive(None, always_update=True, layout=True)

    def __init__(self, message: ToolMessage, **kwargs):
        super().__init__(**kwargs)
        self.message = message

    def render(self):
        return format_tool_message(self.message)



================================================
FILE: src/controlflow/utilities/__init__.py
================================================
[Empty file]


================================================
FILE: src/controlflow/utilities/asyncio.py
================================================
import asyncio
from typing import TypeVar

T = TypeVar("T")

BACKGROUND_TASKS = set()


def create_task(coro):
    """
    Creates async background tasks in a way that is safe from garbage
    collection.

    See
    https://textual.textualize.io/blog/2023/02/11/the-heisenbug-lurking-in-your-async-code/

    Example:

    async def my_coro(x: int) -> int:
        return x + 1

    # safely submits my_coro for background execution
    create_task(my_coro(1))
    """  # noqa: E501
    task = asyncio.create_task(coro)
    BACKGROUND_TASKS.add(task)
    task.add_done_callback(BACKGROUND_TASKS.discard)
    return task



================================================
FILE: src/controlflow/utilities/context.py
================================================
"""Module for defining context utilities."""

import contextvars
from contextlib import contextmanager
from typing import Any, Generator


class ScopedContext:
    """
    `ScopedContext` provides a context management mechanism using `contextvars`.

    This class allows setting and retrieving key-value pairs in a scoped context,
    which is preserved across asynchronous tasks and threads within the same context.

    Attributes:
        _context_storage (ContextVar): A context variable to store the context data.

    Example:
        Basic Usage of ScopedContext
        ```python
        context = ScopedContext()
        with context(key="value"):
            assert context.get("key") == "value"
        # Outside the context, the value is no longer available.
        assert context.get("key") is None
        ```
    """

    def __init__(self, initial_value: dict = None):
        """Initializes the ScopedContext with an initial value dictionary."""
        self._context_storage = contextvars.ContextVar(
            "scoped_context_storage", default=initial_value or {}
        )

    def get(self, key: str, default: Any = None) -> Any:
        return self._context_storage.get().get(key, default)

    def __getitem__(self, key: str) -> Any:
        notfound = object()
        result = self.get(key, default=notfound)
        if result == notfound:
            raise KeyError(key)
        return result

    def set(self, **kwargs: Any) -> None:
        ctx = self._context_storage.get()
        token = self._context_storage.set(ctx | kwargs)
        return token

    @contextmanager
    def __call__(self, **kwargs: Any) -> Generator[None, None, Any]:
        current_context_copy = self._context_storage.get().copy()
        token = self.set(**kwargs)
        try:
            yield
        finally:
            try:
                self._context_storage.reset(token)
            except ValueError as exc:
                if "was created in a different context" in str(exc).lower():
                    # the only way we can reach this line is if the setup and
                    # teardown of this context are run in different frames or
                    # threads (which happens with pytest fixtures!), in which case
                    # the token is considered invalid. This catch serves as a
                    # "manual" reset of the context values
                    self._context_storage.set(current_context_copy)
                else:
                    raise


ctx = ScopedContext(
    dict(
        flow=None,
        tasks=None,
        agent=None,
        orchestrator=None,
        tui=None,
    )
)



================================================
FILE: src/controlflow/utilities/general.py
================================================
import hashlib
import json
import re
import textwrap
from typing import Optional, Union

import prefect
from pydantic import BaseModel, ConfigDict

# flag for unset defaults
NOTSET = "__NOTSET__"


def hash_objects(input_data: tuple, len: int = 8) -> str:
    """
    Generates a fast, stable MD5 hash for the given tuple of input data.

    Args:
        input_data (tuple): The tuple of data to hash.

    Returns:
        str: The hexadecimal digest of the MD5 hash.
    """
    # Serialize the tuple into a JSON string
    serialized_data = json.dumps(input_data, sort_keys=True)

    # Create an MD5 hash object
    hasher = hashlib.md5()

    # Update the hash object with the serialized string
    hasher.update(serialized_data.encode("utf-8"))

    # Return the hexadecimal digest of the hash
    return hasher.hexdigest()[:len]


def unwrap(text: str) -> str:
    """
    Given a multi-line string, dedent, remove newlines within paragraphs, but keep paragraph breaks.
    """
    # Dedent the text
    dedented_text = textwrap.dedent(text)

    # Remove newlines within paragraphs, but keep paragraph breaks
    cleaned_text = re.sub(r"(?<!\n)\n(?!\n)", " ", dedented_text)

    # Remove leading and trailing whitespace
    cleaned_text = cleaned_text.strip()

    return cleaned_text


class ControlFlowModel(BaseModel):
    model_config = ConfigDict(
        validate_assignment=True,
        extra="forbid",
        ignored_types=(prefect.Flow, prefect.Task),
    )


class PandasDataFrame(ControlFlowModel):
    """Schema for a pandas dataframe"""

    data: Union[
        list[list[Union[str, int, float, bool]]],
        dict[str, list[Union[str, int, float, bool]]],
    ]
    columns: Optional[list[str]] = None
    index: Optional[list[str]] = None
    dtype: Optional[dict[str, str]] = None


class PandasSeries(ControlFlowModel):
    """Schema for a pandas series"""

    data: list[Union[str, int, float]]
    index: Optional[list[str]] = None
    name: Optional[str] = None
    dtype: Optional[str] = None


def safe_issubclass(cls: type, subclass: type) -> bool:
    """
    `issubclass` raises a TypeError if cls is not a type. This helper function
    safely checks if cls is a type and then checks if it is a subclass of
    subclass.
    """
    try:
        return isinstance(cls, type) and issubclass(cls, subclass)
    except TypeError:
        return False



================================================
FILE: src/controlflow/utilities/jinja.py
================================================
import inspect
import os
from datetime import datetime
from zoneinfo import ZoneInfo

from jinja2 import Environment as JinjaEnvironment
from jinja2 import PackageLoader, StrictUndefined, select_autoescape

global_fns = {
    "now": lambda: datetime.now(ZoneInfo("UTC")),
    "inspect": inspect,
    "getcwd": os.getcwd,
    "zip": zip,
}

prompt_env = JinjaEnvironment(
    loader=PackageLoader("controlflow.orchestration", "prompt_templates"),
    autoescape=select_autoescape(default_for_string=False),
    trim_blocks=True,
    lstrip_blocks=True,
    auto_reload=True,
    undefined=StrictUndefined,
)

prompt_env.globals.update(global_fns)



================================================
FILE: src/controlflow/utilities/logging.py
================================================
import logging
from functools import lru_cache
from typing import Optional

import controlflow


@lru_cache()
def get_logger(name: Optional[str] = None) -> logging.Logger:
    """
    Retrieves a logger with the given name, or the root logger if no name is given.

    Args:
        name: The name of the logger to retrieve.

    Returns:
        The logger with the given name, or the root logger if no name is given.

    Example:
        Basic Usage of `get_logger`
        ```python
        from controlflow.utilities.logging import get_logger

        logger = get_logger("controlflow.test")
        logger.info("This is a test") # Output: controlflow.test: This is a test

        debug_logger = get_logger("controlflow.debug")
        debug_logger.debug_kv("TITLE", "log message", "green")
        ```
    """
    parent_logger = logging.getLogger("controlflow")

    if name:
        # Append the name if given but allow explicit full names e.g. "controlflow.test"
        # should not become "controlflow.controlflow.test"
        if not name.startswith(parent_logger.name + "."):
            logger = parent_logger.getChild(name)
        else:
            logger = logging.getLogger(name)
    else:
        logger = parent_logger

    return logger


def setup_logging(level: Optional[str] = None) -> None:
    logger = get_logger()

    if level is not None:
        logger.setLevel(level)
    else:
        logger.setLevel(controlflow.settings.log_level)


def deprecated(message: str, version: str):
    """
    Decorator to mark a function as deprecated.

    Args:
        message (str): The deprecation message.
        version (str): The version in which the function is deprecated.

    Returns:
        function: The decorated function.

    Example:
        @deprecated("This function is deprecated", "1.0")
        def my_function():
            pass
    """

    def decorator(func):
        def wrapper(*args, **kwargs):
            get_logger(__file__).warn(
                f"WARNING: {func.__name__} is deprecated as of version {version}. {message}".strip(),
            )
            return func(*args, **kwargs)

        return wrapper

    return decorator



================================================
FILE: src/controlflow/utilities/marvin.py
================================================
# import inspect
# from contextlib import contextmanager
# from typing import Any, Callable

# import marvin.ai.text
# from marvin.client.openai import AsyncMarvinClient
# from marvin.settings import temporary_settings as temporary_marvin_settings
# from openai.types.chat import ChatCompletion
# from prefect import task as prefect_task

# from controlflow.utilities.prefect import (
#     create_json_artifact,
# )

# original_classify_async = marvin.classify_async
# original_cast_async = marvin.cast_async
# original_extract_async = marvin.extract_async
# original_generate_async = marvin.generate_async
# original_paint_async = marvin.paint_async
# original_speak_async = marvin.speak_async
# original_transcribe_async = marvin.transcribe_async


# class AsyncControlFlowClient(AsyncMarvinClient):
#     async def generate_chat(self, **kwargs: Any) -> "ChatCompletion":
#         super_method = super().generate_chat

#         @prefect_task(task_run_name="Generate OpenAI chat completion")
#         async def _generate_chat(**kwargs):
#             messages = kwargs.get("messages", [])
#             create_json_artifact(key="prompt", data=messages)
#             response = await super_method(**kwargs)
#             create_json_artifact(key="response", data=response)
#             return response

#         return await _generate_chat(**kwargs)


# def generate_task(name: str, original_fn: Callable):
#     if inspect.iscoroutinefunction(original_fn):

#         @prefect_task(name=name)
#         async def wrapper(*args, **kwargs):
#             create_json_artifact(key="args", data=[args, kwargs])
#             result = await original_fn(*args, **kwargs)
#             create_json_artifact(key="result", data=result)
#             return result
#     else:

#         @prefect_task(name=name)
#         def wrapper(*args, **kwargs):
#             create_json_artifact(key="args", data=[args, kwargs])
#             result = original_fn(*args, **kwargs)
#             create_json_artifact(key="result", data=result)
#             return result

#     return wrapper


# @contextmanager
# def patch_marvin():
#     with temporary_marvin_settings(default_async_client_cls=AsyncControlFlowClient):
#         try:
#             marvin.ai.text.classify_async = generate_task(
#                 "marvin.classify", original_classify_async
#             )
#             marvin.ai.text.cast_async = generate_task(
#                 "marvin.cast", original_cast_async
#             )
#             marvin.ai.text.extract_async = generate_task(
#                 "marvin.extract", original_extract_async
#             )
#             marvin.ai.text.generate_async = generate_task(
#                 "marvin.generate", original_generate_async
#             )
#             marvin.ai.images.paint_async = generate_task(
#                 "marvin.paint", original_paint_async
#             )
#             marvin.ai.audio.speak_async = generate_task(
#                 "marvin.speak", original_speak_async
#             )
#             marvin.ai.audio.transcribe_async = generate_task(
#                 "marvin.transcribe", original_transcribe_async
#             )
#             yield
#         finally:
#             marvin.ai.text.classify_async = original_classify_async
#             marvin.ai.text.cast_async = original_cast_async
#             marvin.ai.text.extract_async = original_extract_async
#             marvin.ai.text.generate_async = original_generate_async
#             marvin.ai.images.paint_async = original_paint_async
#             marvin.ai.audio.speak_async = original_speak_async
#             marvin.ai.audio.transcribe_async = original_transcribe_async



================================================
FILE: src/controlflow/utilities/prefect.py
================================================
from contextlib import contextmanager
from typing import (
    Any,
)
from uuid import UUID

import prefect
import prefect.cache_policies
import prefect.serializers
import prefect.tasks
from prefect import get_client as get_prefect_client
from prefect.artifacts import ArtifactRequest
from prefect.context import (
    FlowRunContext,
    TaskRunContext,
)
from pydantic import TypeAdapter

import controlflow


def prefect_task(*args, **kwargs):
    """
    A decorator that creates a Prefect task with ControlFlow defaults
    """

    # TODO: only open in Flow context?

    kwargs.setdefault("log_prints", controlflow.settings.log_prints)
    kwargs.setdefault("cache_policy", prefect.cache_policies.NONE)
    kwargs.setdefault("result_serializer", "json")

    return prefect.task(*args, **kwargs)


def prefect_flow(*args, **kwargs):
    """
    A decorator that creates a Prefect flow with ControlFlow defaults
    """

    kwargs.setdefault("log_prints", controlflow.settings.log_prints)
    kwargs.setdefault("result_serializer", "json")

    return prefect.flow(*args, **kwargs)


def create_markdown_artifact(
    key: str,
    markdown: str,
    description: str = None,
    task_run_id: UUID = None,
    flow_run_id: UUID = None,
) -> None:
    """
    Create a Markdown artifact.
    """
    tr_context = TaskRunContext.get()
    fr_context = FlowRunContext.get()

    if tr_context:
        task_run_id = task_run_id or tr_context.task_run.id
    if fr_context:
        flow_run_id = flow_run_id or fr_context.flow_run.id

    client = get_prefect_client(sync_client=True)

    client.create_artifact(
        artifact=ArtifactRequest(
            key=key,
            data=markdown,
            description=description,
            type="markdown",
            task_run_id=task_run_id,
            flow_run_id=flow_run_id,
        )
    )


def create_json_artifact(
    key: str,
    data: Any,
    description: str = None,
    task_run_id: UUID = None,
    flow_run_id: UUID = None,
) -> None:
    """
    Create a JSON artifact.
    """

    try:
        markdown = TypeAdapter(type(data)).dump_json(data, indent=2).decode()
        markdown = f"```json\n{markdown}\n```"
    except Exception:
        markdown = str(data)

    create_markdown_artifact(
        key=key,
        markdown=markdown,
        description=description,
        task_run_id=task_run_id,
        flow_run_id=flow_run_id,
    )


def create_python_artifact(
    key: str,
    code: str,
    description: str = None,
    task_run_id: UUID = None,
    flow_run_id: UUID = None,
) -> None:
    """
    Create a Python artifact.
    """

    create_markdown_artifact(
        key=key,
        markdown=f"```python\n{code}\n```",
        description=description,
        task_run_id=task_run_id,
        flow_run_id=flow_run_id,
    )


def prefect_task_context(**kwargs):
    """
    Creates a Prefect task that starts when the context is entered and ends when
    it closes. This is useful for creating a Prefect task that is not tied to a
    specific function but governs a block of code. Note that some features, like
    retries and caching, will not work.
    """
    supported_kwargs = {
        "name",
        "description",
        "task_run_name",
        "tags",
        "version",
        "timeout_seconds",
        "log_prints",
        "on_completion",
        "on_failure",
    }
    unsupported_kwargs = set(kwargs.keys()) - set(supported_kwargs)
    if unsupported_kwargs:
        raise ValueError(
            f"Unsupported keyword arguments for a task context provided: "
            f"{unsupported_kwargs}. Consider using a @task-decorated function instead."
        )

    @contextmanager
    @prefect_task(**kwargs)
    def task_context():
        yield

    return task_context()


def prefect_flow_context(**kwargs):
    """
    Creates a Prefect flow that starts when the context is entered and ends when
    it closes. This is useful for creating a Prefect flow that is not tied to a
    specific function but governs a block of code. Note that some features, like
    retries and caching, will not work.
    """

    supported_kwargs = {
        "name",
        "description",
        "flow_run_name",
        "tags",
        "version",
        "timeout_seconds",
        "log_prints",
        "on_completion",
        "on_failure",
    }
    unsupported_kwargs = set(kwargs.keys()) - set(supported_kwargs)
    if unsupported_kwargs:
        raise ValueError(
            f"Unsupported keyword arguments for a flow context provided: "
            f"{unsupported_kwargs}. Consider using a @flow-decorated function instead."
        )

    @contextmanager
    @prefect_flow(**kwargs)
    def flow_context():
        yield

    return flow_context()



================================================
FILE: src/controlflow/utilities/rich.py
================================================
from rich.console import Console

console = Console()



================================================
FILE: src/controlflow/utilities/tasks.py
================================================
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    TypeVar,
)

from controlflow.utilities.logging import get_logger

if TYPE_CHECKING:
    from controlflow.tasks.task import Task

T = TypeVar("T")
logger = get_logger(__name__)


def visit_task_collection(
    val: Any, visitor: Callable, recursion_limit: int = 10, _counter: int = 0
) -> list["Task"]:
    """
    Recursively visits a task collection and applies a visitor function to each task.

    Args:
        val (Any): The task collection to visit.
        visitor (Callable): The visitor function to apply to each task.
        recursion_limit (int, optional): The maximum recursion limit. Defaults to 3.
        _counter (int, optional): Internal counter to track recursion depth. Defaults to 0.

    Returns:
        list["Task"]: The modified task collection after applying the visitor function.

    """
    from controlflow.tasks.task import Task

    if _counter >= recursion_limit:
        return val

    if isinstance(val, dict):
        result = {}
        for key, value in list(val.items()):
            result[key] = visit_task_collection(
                value,
                visitor=visitor,
                recursion_limit=recursion_limit,
                _counter=_counter + 1,
            )
        return result
    elif isinstance(val, (list, set, tuple)):
        result = []
        for item in val:
            result.append(
                visit_task_collection(
                    item,
                    visitor=visitor,
                    recursion_limit=recursion_limit,
                    _counter=_counter + 1,
                )
            )
        return type(val)(result)
    elif isinstance(val, Task):
        return visitor(val)

    return val


def collect_tasks(val: T) -> list["Task"]:
    """
    Given a collection of tasks, returns a list of all tasks in the collection.
    """

    tasks = []

    def visit_task(task: "Task"):
        tasks.append(task)
        return task

    visit_task_collection(val, visit_task)
    return tasks


def resolve_tasks(val: T) -> T:
    """
    Given a collection of tasks, runs them to completion and returns the results.
    """

    def visit_task(task: "Task"):
        return task.run()

    return visit_task_collection(val, visit_task)


def any_incomplete(tasks: list["Task"]) -> bool:
    return any(t.is_incomplete() for t in tasks)


def all_complete(tasks: list["Task"]) -> bool:
    return all(t.is_complete() for t in tasks)


def all_successful(tasks: list["Task"]) -> bool:
    return all(t.is_successful() for t in tasks)


def any_failed(tasks: list["Task"]) -> bool:
    return any(t.is_failed() for t in tasks)


def none_failed(tasks: list["Task"]) -> bool:
    return not any_failed(tasks)



================================================
FILE: src/controlflow/utilities/testing.py
================================================
import json
import uuid
from contextlib import contextmanager
from typing import Union

from langchain_core.language_models.fake_chat_models import FakeMessagesListChatModel

import controlflow
from controlflow.events.history import InMemoryHistory
from controlflow.llm.messages import AIMessage, BaseMessage, ToolCall
from controlflow.tasks.task import Task

COUNTER = 0


def SimpleTask(**kwargs):
    global COUNTER
    COUNTER += 1

    kwargs.setdefault("objective", "test")
    kwargs.setdefault("result_type", None)
    kwargs.setdefault("context", {})["__counter__"] = str(COUNTER)

    return Task(**kwargs)


class FakeLLM(FakeMessagesListChatModel):
    def __init__(self, *, responses: list[Union[str, BaseMessage]] = None, **kwargs):
        super().__init__(responses=[], **kwargs)
        self.set_responses(responses or ["Hello! This is a response from the FakeLLM."])

    def set_responses(self, responses: list[Union[str, BaseMessage]]):
        messages = []

        for r in responses:
            if isinstance(r, str):
                messages.append(AIMessage(content=r))
            elif isinstance(r, dict):
                messages.append(
                    AIMessage(
                        content="",
                        tool_calls=[
                            ToolCall(name=r["name"], args=r.get("args", {}), id="")
                        ],
                    )
                )
            else:
                messages.append(r)

        if any(not isinstance(m, BaseMessage) for m in messages):
            raise ValueError(
                "Responses must be provided as either a list of strings, tool call dicts, or AIMessages. "
                "Each item in the list will be emitted in a cycle when the LLM is called."
            )

        self.responses = messages

    def bind_tools(self, *args, **kwargs):
        """When binding tools, passthrough"""
        return self

    def get_num_tokens_from_messages(self, messages: list) -> int:
        """Approximate token counter for messages"""
        return len(str(messages))


@contextmanager
def record_events():
    """
    Context manager for recording all messages in a flow, useful for testing.


    with record_events() as events:
        cf.Task("say hello").run()

    assert events[0].content == "Hello!"

    """
    history = InMemoryHistory(history={})
    old_default_history = controlflow.defaults.history
    controlflow.defaults.history = history

    events = []

    try:
        yield events
    finally:
        controlflow.defaults.history = old_default_history

        _events_buffer = []
        for _, thread_events in history.history.items():
            for event in thread_events:
                event = event.copy()
                _events_buffer.append(event)

        events.extend(sorted(_events_buffer, key=lambda m: m.timestamp))



================================================
FILE: tests/__init__.py
================================================
[Empty file]


================================================
FILE: tests/conftest.py
================================================
import pytest
from prefect.testing.utilities import prefect_test_harness

from .fixtures import *


@pytest.fixture(autouse=True, scope="session")
def prefect_test_fixture():
    """
    Run Prefect against temporary sqlite database
    """
    with prefect_test_harness():
        yield



================================================
FILE: tests/test_decorator.py
================================================
import asyncio

import controlflow


class TestDecorator:
    def test_decorator(self):
        @controlflow.task
        def write_poem(topic: str) -> str:
            """write a poem about `topic`"""

        task = write_poem.as_task("AI")
        assert task.name == "write_poem"
        assert task.objective == "write a poem about `topic`"
        assert task.result_type is str

    def test_decorator_can_return_context(self):
        @controlflow.task
        def write_poem(topic: str) -> str:
            return f"write a poem about {topic}"

        task = write_poem.as_task("AI")
        assert task.context["Additional context"] == "write a poem about AI"

    def test_return_annotation(self):
        @controlflow.task
        def generate_tags(text: str) -> list[str]:
            """Generate a list of tags for the given text."""

        task = generate_tags.as_task("Fly me to the moon")
        assert task.result_type == list[str]

    def test_objective_can_be_provided_as_kwarg(self):
        @controlflow.task(objective="Write a poem about `topic`")
        def write_poem(topic: str) -> str:
            """Writes a poem."""

        task = write_poem.as_task("AI")
        assert task.objective == "Write a poem about `topic`"

    def test_run_task(self):
        @controlflow.task
        def extract_fruit(text: str) -> list[str]:
            return "Extract any fruit mentioned in the text; all lowercase"

        result = extract_fruit("I like apples and bananas")
        assert result == ["apples", "bananas"]


class TestFlowDecorator:
    def test_sync_flow_decorator(self):
        @controlflow.flow
        def sync_flow():
            return 10

        result = sync_flow()
        assert result == 10

    async def test_async_flow_decorator(self):
        @controlflow.flow
        async def async_flow():
            await asyncio.sleep(0.1)
            return 10

        result = await async_flow()
        assert result == 10

    def test_flow_decorator_preserves_function_metadata(self):
        @controlflow.flow
        def flow_with_metadata():
            """This is a test flow."""
            return 10

        assert flow_with_metadata.__name__ == "flow_with_metadata"
        assert flow_with_metadata.__doc__ == "This is a test flow."

    def test_flow_decorator_with_arguments(self):
        @controlflow.flow(thread="test_thread", instructions="Test instructions")
        def flow_with_args(x: int):
            return x + 10

        result = flow_with_args(5)
        assert result == 15

    async def test_async_flow_decorator_with_arguments(self):
        @controlflow.flow(
            thread="async_test_thread", instructions="Async test instructions"
        )
        async def async_flow_with_args(x: int):
            await asyncio.sleep(0.1)
            return x + 10

        result = await async_flow_with_args(5)
        assert result == 15

    def test_flow_decorator_partial_application(self):
        custom_flow = controlflow.flow(thread="custom_thread")

        @custom_flow
        def partial_flow():
            return 10

        result = partial_flow()
        assert result == 10

    def test_flow_decorator_with_context_kwargs(self):
        @controlflow.flow(context_kwargs=["x", "z"])
        def flow_with_context(x: int, y: int, z: str):
            flow = controlflow.flows.get_flow()
            return flow.context

        result = flow_with_context(1, 2, "test")
        assert result == {"x": 1, "z": "test"}

    def test_flow_decorator_without_context_kwargs(self):
        @controlflow.flow
        def flow_without_context(x: int, y: int, z: str):
            flow = controlflow.flows.get_flow()
            return flow.context

        result = flow_without_context(1, 2, "test")
        assert result == {}

    async def test_async_flow_decorator_with_context_kwargs(self):
        @controlflow.flow(context_kwargs=["a", "b"])
        async def async_flow_with_context(a: int, b: str, c: float):
            flow = controlflow.flows.get_flow()
            return flow.context

        result = await async_flow_with_context(10, "hello", 3.14)
        assert result == {"a": 10, "b": "hello"}


class TestTaskDecorator:
    def test_task_decorator_sync_as_task(self):
        @controlflow.task
        def write_poem(topic: str) -> str:
            """write a two-line poem about `topic`"""

        task = write_poem.as_task("AI")
        assert task.name == "write_poem"
        assert task.objective == "write a two-line poem about `topic`"
        assert task.result_type is str

    def test_task_decorator_async_as_task(self):
        @controlflow.task
        async def write_poem(topic: str) -> str:
            """write a two-line poem about `topic`"""

        task = write_poem.as_task("AI")
        assert task.name == "write_poem"
        assert task.objective == "write a two-line poem about `topic`"
        assert task.result_type is str

    def test_task_decorator_sync(self):
        @controlflow.task
        def write_poem(topic: str) -> str:
            """write a two-line poem about `topic`"""

        assert write_poem("AI")

    async def test_task_decorator_async(self):
        @controlflow.task
        async def write_poem(topic: str) -> str:
            """write a two-line poem about `topic`"""

        assert await write_poem("AI")



================================================
FILE: tests/test_defaults.py
================================================
import pydantic
import pytest
from langchain_openai import ChatOpenAI

import controlflow
import controlflow.events.history
import controlflow.llm


def test_default_model_failed_validation():
    with pytest.raises(
        pydantic.ValidationError,
        match="Input must be an instance of dict or BaseChatModel",
    ):
        controlflow.defaults.model = 5


def test_set_default_model():
    model = ChatOpenAI(temperature=0.1)
    controlflow.defaults.model = model
    assert controlflow.Agent().get_model() is model


def test_default_agent_failed_validation():
    with pytest.raises(
        pydantic.ValidationError,
        match="Input should be a valid dictionary or instance of Agent",
    ):
        controlflow.defaults.agent = 5


def test_set_default_agent():
    agent = controlflow.Agent()
    controlflow.defaults.agent = agent
    assert controlflow.Task("").get_agents() == [agent]


def test_default_history_failed_validation():
    with pytest.raises(
        pydantic.ValidationError,
        match="Input should be a valid dictionary or instance of History",
    ):
        controlflow.defaults.history = 5


def test_set_default_history():
    history = controlflow.events.history.InMemoryHistory()
    controlflow.defaults.history = history
    assert controlflow.Flow().history is history



================================================
FILE: tests/test_instructions.py
================================================
from controlflow.instructions import get_instructions, instructions


def test_instructions_context():
    assert get_instructions() == []
    with instructions("abc"):
        assert get_instructions() == ["abc"]
    assert get_instructions() == []


def test_instructions_context_nested():
    assert get_instructions() == []
    with instructions("abc"):
        assert get_instructions() == ["abc"]
        with instructions("def"):
            assert get_instructions() == ["abc", "def"]
        assert get_instructions() == ["abc"]
    assert get_instructions() == []


def test_instructions_none():
    assert get_instructions() == []
    with instructions(None):
        assert get_instructions() == []
    with instructions(""):
        assert get_instructions() == []
    assert get_instructions() == []



================================================
FILE: tests/test_planning.py
================================================
class TestGenerateSubtasks:
    def test_generate_subtasks(self):
        pass



================================================
FILE: tests/test_run.py
================================================
import pytest

import controlflow
from controlflow import Stream, instructions
from controlflow.events.base import Event
from controlflow.events.events import AgentMessage
from controlflow.llm.messages import AIMessage
from controlflow.orchestration.conditions import AnyComplete, AnyFailed, MaxLLMCalls
from controlflow.orchestration.handler import Handler
from controlflow.run import run, run_async, run_tasks, run_tasks_async
from controlflow.tasks.task import Task
from tests.fixtures.controlflow import default_fake_llm


class TestHandlers:
    class ExampleHandler(Handler):
        def __init__(self):
            self.events = []
            self.agent_messages = []

        def on_event(self, event: Event):
            self.events.append(event)

        def on_agent_message(self, event: AgentMessage):
            self.agent_messages.append(event)

    def test_run_with_handlers(self, default_fake_llm):
        handler = self.ExampleHandler()
        run("what's 2 + 2", result_type=int, handlers=[handler], max_llm_calls=1)
        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1

    async def test_run_async_with_handlers(self, default_fake_llm):
        handler = self.ExampleHandler()
        await run_async(
            "what's 2 + 2", result_type=int, handlers=[handler], max_llm_calls=1
        )

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1


def test_run():
    result = run("what's 2 + 2", result_type=int)
    assert result == 4


async def test_run_async():
    result = await run_async("what's 2 + 2", result_type=int)
    assert result == 4


class TestRunUntil:
    def test_any_complete(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("complete only task 2"):
            run_tasks([task1, task2], run_until=AnyComplete())

        assert task2.is_complete()
        assert task1.is_incomplete()

    def test_any_failed(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("fail only task 2"):
            run_tasks([task1, task2], run_until=AnyFailed(), raise_on_failure=False)

        assert task2.is_failed()
        assert not task1.is_failed()

    def test_max_llm_calls(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("say hi but do not complete any tasks"):
            run_tasks([task1, task2], run_until=MaxLLMCalls(1))

        assert task2.is_incomplete()
        assert task1.is_incomplete()

    def test_min_complete(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")
        task3 = Task("Task 3")

        with instructions("complete tasks 1 and 2"):
            run_tasks([task1, task2, task3], run_until=AnyComplete(min_complete=2))

        assert task1.is_complete()
        assert task2.is_complete()
        assert task3.is_incomplete()

    def test_min_failed(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")
        task3 = Task("Task 3")

        with instructions("fail tasks 1 and 3. Don't work on task 2."):
            run_tasks(
                [task1, task2, task3],
                run_until=AnyFailed(min_failed=2),
                raise_on_failure=False,
            )

        assert task1.is_failed()
        assert task2.is_incomplete()
        assert task3.is_failed()


class TestRunUntilAsync:
    async def test_any_complete(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("complete only task 2"):
            await run_tasks_async([task1, task2], run_until=AnyComplete())

        assert task2.is_complete()
        assert task1.is_incomplete()

    async def test_any_failed(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("fail only task 2"):
            await run_tasks_async(
                [task1, task2], run_until=AnyFailed(), raise_on_failure=False
            )

        assert task2.is_failed()
        assert not task1.is_failed()

    async def test_max_llm_calls(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")

        with instructions("say hi but do not complete any tasks"):
            await run_tasks_async([task1, task2], run_until=MaxLLMCalls(1))

        assert task2.is_incomplete()
        assert task1.is_incomplete()

    async def test_min_complete(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")
        task3 = Task("Task 3")

        with instructions("complete tasks 1 and 2"):
            await run_tasks_async(
                [task1, task2, task3], run_until=AnyComplete(min_complete=2)
            )

        assert task1.is_complete()
        assert task2.is_complete()
        assert task3.is_incomplete()

    async def test_min_failed(self):
        task1 = Task("Task 1")
        task2 = Task("Task 2")
        task3 = Task("Task 3")

        with instructions("fail tasks 1 and 3. Don't work on task 2."):
            await run_tasks_async(
                [task1, task2, task3],
                run_until=AnyFailed(min_failed=2),
                raise_on_failure=False,
            )

        assert task1.is_failed()
        assert task2.is_incomplete()
        assert task3.is_failed()


class TestRunStreaming:
    # Helper function to collect async iterator results
    async def collect_stream(self, ait):
        return [x async for x in ait]

    @pytest.fixture
    def task(self, default_fake_llm):
        task = controlflow.Task("say hello", id="12345")

        response = AIMessage(
            id="run-2af8bb73-661f-4ec3-92ff-d7d8e3074926",
            name="Marvin",
            role="ai",
            content="",
            tool_calls=[
                {
                    "name": "mark_task_12345_successful",
                    "args": {"result": "Hello!"},
                    "id": "call_ZEPdV8mCgeBe5UHjKzm6e3pe",
                    "type": "tool_call",
                }
            ],
        )

        default_fake_llm.set_responses(["Hello!", response])

        return task

    def test_stream_all(self, default_fake_llm):
        result = run("what's 2 + 2", stream=True, max_llm_calls=1)
        r = list(result)
        assert len(r) > 5

    async def test_stream_all_async(self, default_fake_llm):
        result = await run_async("what's 2 + 2", stream=True, max_llm_calls=1)
        r = await self.collect_stream(result)
        assert len(r) > 5

    def test_stream_task(self, task):
        result = list(task.run(stream=True))
        assert result[0][0].event == "orchestrator-start"
        assert result[1][0].event == "agent-turn-start"
        assert result[-1][0].event == "orchestrator-end"
        assert any(r[0].event == "agent-message" for r in result)
        assert any(r[0].event == "agent-message-delta" for r in result)
        assert any(r[0].event == "agent-content" for r in result)
        assert any(r[0].event == "agent-content-delta" for r in result)
        assert any(r[0].event == "agent-tool-call" for r in result)

    async def test_stream_task_async(self, task):
        result = await task.run_async(stream=True)
        r = await self.collect_stream(result)
        assert r[0][0].event == "orchestrator-start"
        assert r[1][0].event == "agent-turn-start"
        assert r[-1][0].event == "orchestrator-end"
        assert any(x[0].event == "agent-message" for x in r)
        assert any(x[0].event == "agent-message-delta" for x in r)
        assert any(x[0].event == "agent-content" for x in r)
        assert any(x[0].event == "agent-content-delta" for x in r)
        assert any(x[0].event == "agent-tool-call" for x in r)

    def test_stream_content(self, task):
        result = list(task.run(stream=Stream.CONTENT))
        assert all(
            r[0].event in ("agent-content", "agent-content-delta") for r in result
        )

    async def test_stream_content_async(self, task):
        result = await task.run_async(stream=Stream.CONTENT)
        r = await self.collect_stream(result)
        assert all(x[0].event in ("agent-content", "agent-content-delta") for x in r)

    def test_stream_tools(self, task):
        result = list(task.run(stream=Stream.TOOLS))
        assert all(
            r[0].event in ("agent-tool-call", "agent-tool-call-delta", "tool-result")
            for r in result
        )

    async def test_stream_tools_async(self, task):
        result = await task.run_async(stream=Stream.TOOLS)
        r = await self.collect_stream(result)
        assert all(
            x[0].event in ("agent-tool-call", "agent-tool-call-delta", "tool-result")
            for x in r
        )

    def test_stream_completion_tools(self, task):
        result = list(task.run(stream=Stream.COMPLETION_TOOLS))
        assert all(
            r[0].event in ("agent-tool-call", "agent-tool-call-delta", "tool-result")
            for r in result
        )

    async def test_stream_completion_tools_async(self, task):
        result = await task.run_async(stream=Stream.COMPLETION_TOOLS)
        r = await self.collect_stream(result)
        assert all(
            x[0].event in ("agent-tool-call", "agent-tool-call-delta", "tool-result")
            for x in r
        )

    def test_stream_task_events(self, task):
        result = list(task.run(stream=Stream.TASK_EVENTS))
        assert result[-1][0].event == "task-success"
        assert result[0][0].task is task

    async def test_stream_task_events_async(self, task):
        result = await task.run_async(stream=Stream.TASK_EVENTS)
        r = await self.collect_stream(result)
        assert r[-1][0].event == "task-success"
        assert r[0][0].task is task



================================================
FILE: tests/test_settings.py
================================================
import importlib

import openai
import pytest
from prefect.logging import get_logger

import controlflow
import controlflow.llm.models
from controlflow.settings import temporary_settings


def test_defaults():
    # ensure that debug settings etc. are not misconfigured during development
    # change these settings to match whatever the default should be
    assert controlflow.settings.tools_raise_on_error is False
    assert controlflow.settings.tools_verbose is True
    # 4o is the default
    assert controlflow.settings.llm_model == "openai/gpt-4o-mini"
    assert controlflow.settings.prefect_log_level == "DEBUG"


def test_temporary_settings():
    assert controlflow.settings.tools_raise_on_error is False
    with temporary_settings(tools_raise_on_error=True):
        assert controlflow.settings.tools_raise_on_error is True
    assert controlflow.settings.tools_raise_on_error is False


def test_prefect_settings_apply_at_runtime(caplog):
    prefect_logger = get_logger()
    controlflow.settings.prefect_log_level = "WARNING"
    prefect_logger.warning("test-log-1")
    controlflow.settings.prefect_log_level = "ERROR"
    prefect_logger.warning("test-log-2")
    controlflow.settings.prefect_log_level = "DEBUG"
    prefect_logger.warning("test-log-3")

    assert "test-log-1" in caplog.text
    assert "test-log-2" not in caplog.text
    assert "test-log-3" in caplog.text


def test_import_without_default_api_key_warns_but_does_not_fail(monkeypatch, caplog):
    try:
        with monkeypatch.context() as m:
            # remove the OPENAI_API_KEY environment variable
            m.delenv("OPENAI_API_KEY", raising=False)

            # Clear any previous logs
            caplog.clear()

            # Import the library
            with caplog.at_level("DEBUG"):
                # Reload the library to apply changes
                defaults_module = importlib.import_module("controlflow.defaults")
                importlib.reload(defaults_module)
                importlib.reload(controlflow)

            # Check if the warning was logged
            assert any(
                record.levelname == "WARNING"
                and "The default LLM model could not be created" in record.message
                for record in caplog.records
            ), "The expected warning was not logged"
    finally:
        defaults_module = importlib.import_module("controlflow.defaults")
        importlib.reload(defaults_module)
        importlib.reload(controlflow)


def test_import_without_default_api_key_errors_when_loading_model(monkeypatch):
    try:
        with monkeypatch.context() as m:
            # remove the OPENAI_API_KEY environment variable
            m.delenv("OPENAI_API_KEY", raising=False)

            # Reload the library to apply changes
            defaults_module = importlib.import_module("controlflow.defaults")
            importlib.reload(defaults_module)
            importlib.reload(controlflow)

            with pytest.raises(
                openai.OpenAIError, match="api_key client option must be set"
            ):
                controlflow.llm.models.get_default_model()

            with pytest.raises(
                ValueError,
                match="No model provided and no default model could be loaded",
            ):
                controlflow.Agent().get_model()
    finally:
        defaults_module = importlib.import_module("controlflow.defaults")
        importlib.reload(defaults_module)
        importlib.reload(controlflow)


def test_import_without_api_key_for_non_default_model_warns_but_does_not_fail(
    monkeypatch, caplog
):
    try:
        with monkeypatch.context() as m:
            # remove the OPENAI_API_KEY environment variable
            m.delenv("OPENAI_API_KEY", raising=False)
            m.setenv("CONTROLFLOW_LLM_MODEL", "anthropic/not-a-model")

            # Clear any previous logs
            caplog.clear()

            # Import the library
            with caplog.at_level("WARNING"):
                # Reload the library to apply changes
                defaults_module = importlib.import_module("controlflow.defaults")
                importlib.reload(defaults_module)
                importlib.reload(controlflow)

            # Check if the warning was logged
            assert any(
                record.levelname == "WARNING"
                and "The default LLM model could not be created" in record.message
                for record in caplog.records
            ), "The expected warning was not logged"
    finally:
        defaults_module = importlib.import_module("controlflow.defaults")
        importlib.reload(defaults_module)
        importlib.reload(controlflow)



================================================
FILE: tests/agents/__init__.py
================================================
[Empty file]


================================================
FILE: tests/agents/test_agents.py
================================================
import pytest
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

import controlflow
from controlflow.agents import Agent
from controlflow.events.base import Event
from controlflow.events.events import AgentMessage
from controlflow.instructions import instructions
from controlflow.llm.rules import AnthropicRules, LLMRules, OpenAIRules
from controlflow.orchestration.handler import Handler
from controlflow.tasks.task import Task


class TestAgentInitialization:
    def test_positional_arg(self):
        agent = Agent("talk like a pirate")
        assert agent.instructions == "talk like a pirate"

    def test_agent_default_model(self):
        agent = Agent()

        # None indicates it will be loaded from the default model
        assert agent.model is None
        assert agent.get_model() is controlflow.defaults.model

    def test_agent_model(self):
        model = ChatOpenAI(model="gpt-4o-mini")
        agent = Agent(model=model)

        # None indicates it will be loaded from the default model
        assert agent.model is model
        assert agent.get_model() is model

    def test_agent_model_from_string(self):
        agent1 = Agent(model="openai/gpt-4o-mini")
        assert isinstance(agent1.model, ChatOpenAI)
        assert agent1.model.model_name == "gpt-4o-mini"

        agent2 = Agent(model="anthropic/claude-3-haiku-20240307")
        assert isinstance(agent2.model, ChatAnthropic)
        assert agent2.model.model == "claude-3-haiku-20240307"

    def test_agent_model_with_invalid_format(self):
        with pytest.raises(ValueError, match="The model `gpt-4o` is not valid."):
            Agent(model="gpt-4o")

    def test_agent_model_from_unsupported_provider(self):
        with pytest.raises(
            ValueError, match="Could not load provider `abc` automatically"
        ):
            Agent(model="abc/def")

    def test_agent_loads_instructions_at_creation(self):
        with instructions("test instruction"):
            agent = Agent()

        assert agent.instructions and "test instruction" in agent.instructions

    @pytest.mark.skip(reason="IDs are not stable right now")
    def test_stable_id(self):
        agent = Agent(name="Test Agent")
        assert agent.id == "69dd1abd"

    def test_id_includes_instructions(self):
        a1 = Agent()
        a2 = Agent(instructions="abc")
        a3 = Agent(instructions="def")
        a4 = Agent(instructions="abc", description="xyz")

        assert a1.id != a2.id != a3.id != a4.id


class TestDefaultAgent:
    def test_default_agent(self):
        assert controlflow.defaults.agent.name == "Marvin"
        assert Task("task").get_agents() == [controlflow.defaults.agent]

    def test_default_agent_has_no_tools(self):
        assert controlflow.defaults.agent.tools == []

    def test_default_agent_has_no_model(self):
        assert controlflow.defaults.agent.model is None

    def test_default_agent_can_be_assigned(self):
        # baseline
        assert controlflow.defaults.agent.name == "Marvin"

        new_default_agent = Agent(name="New Agent")
        controlflow.defaults.agent = new_default_agent

        assert controlflow.defaults.agent.name == "New Agent"
        assert Task("task").get_agents() == [new_default_agent]
        assert Task("task").get_agents()[0].name == "New Agent"

    def test_updating_the_default_model_updates_the_default_agent_model(self):
        new_model = ChatOpenAI(model="gpt-4o-mini")
        controlflow.defaults.model = new_model

        new_agent = controlflow.defaults.agent
        assert new_agent.model is None
        assert new_agent.get_model() is new_model

        task = Task("task")
        assert task.get_agents()[0].model is None
        assert task.get_agents()[0].get_model() is new_model


class TestAgentPrompt:
    def test_default_prompt(self):
        agent = Agent()
        assert agent.prompt is None

    def test_default_template(self):
        agent = Agent()
        prompt = agent.get_prompt()
        assert prompt.startswith("# Agent")

    def test_custom_prompt(self):
        agent = Agent(prompt="Custom Prompt")
        prompt = agent.get_prompt()
        assert prompt == "Custom Prompt"

    def test_custom_templated_prompt(self):
        agent = Agent(name="abc", prompt="{{ agent.name }}")
        prompt = agent.get_prompt()
        assert prompt == "abc"


class TestAgentSerialization:
    def test_serialize_for_prompt(self):
        agent = Agent(name="Test", description="A test agent", interactive=True)
        serialized = agent.serialize_for_prompt()
        assert serialized["name"] == "Test"
        assert serialized["description"] == "A test agent"
        assert serialized["interactive"] is True
        assert "id" in serialized
        assert "tools" in serialized

    def test_serialize_tools(self):
        def dummy_tool():
            """Dummy tool description"""
            pass

        agent = Agent(name="Test", tools=[dummy_tool])
        serialized_tools = agent._serialize_tools(agent.tools)
        assert len(serialized_tools) == 1
        assert serialized_tools[0]["name"] == "dummy_tool"
        assert serialized_tools[0]["description"] == "Dummy tool description"


class TestAgentLLMRules:
    def test_get_llm_rules(self):
        agent = Agent(name="Test")
        rules = agent.get_llm_rules()
        assert isinstance(rules, LLMRules)


class TestAgentContext:
    def test_context_manager(self):
        agent = Agent(name="Test")
        with agent:
            from controlflow.utilities.context import ctx

            assert ctx.get("agent") is agent


class TestHandlers:
    class ExampleHandler(Handler):
        def __init__(self):
            self.events = []
            self.agent_messages = []

        def on_event(self, event: Event):
            self.events.append(event)

        def on_agent_message(self, event: AgentMessage):
            self.agent_messages.append(event)

    @pytest.mark.usefixtures("default_fake_llm")
    def test_agent_run_with_handlers(self):
        handler = self.ExampleHandler()
        agent = Agent()
        agent.run(
            "Calculate 2 + 2", result_type=int, handlers=[handler], max_llm_calls=1
        )

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1

    @pytest.mark.asyncio
    @pytest.mark.usefixtures("default_fake_llm")
    async def test_agent_run_async_with_handlers(self):
        handler = self.ExampleHandler()
        agent = Agent()
        await agent.run_async(
            "Calculate 2 + 2", result_type=int, handlers=[handler], max_llm_calls=1
        )

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1


class TestLLMRules:
    def test_llm_rules_from_model_openai(self):
        agent = Agent(model=ChatOpenAI(model="gpt-4o-mini"))
        rules = agent.get_llm_rules()
        assert isinstance(rules, OpenAIRules)

    def test_llm_rules_from_model_anthropic(self):
        agent = Agent(model=ChatAnthropic(model="claude-3-haiku-20240307"))
        rules = agent.get_llm_rules()
        assert isinstance(rules, AnthropicRules)

    def test_custom_llm_rules(self):
        rules = LLMRules(model=None)
        agent = Agent(llm_rules=rules, model=ChatOpenAI(model="gpt-4o-mini"))
        assert agent.get_llm_rules() is rules



================================================
FILE: tests/ai_tests/__init__.py
================================================
[Empty file]


================================================
FILE: tests/ai_tests/test_tasks.py
================================================
import pytest
from pydantic import BaseModel

from controlflow import Task


class Name(BaseModel):
    first: str
    last: str


@pytest.mark.usefixtures("unit_test_instructions")
class TestTaskResults:
    def test_task_int_result(self):
        task = Task("return 3", result_type=int)
        assert task.run() == 3

    def test_task_pydantic_result(self):
        task = Task("the name is John Doe", result_type=Name)
        result = task.run()
        assert isinstance(result, Name)
        assert result == Name(first="John", last="Doe")



================================================
FILE: tests/cli/__init__.py
================================================
[Empty file]


================================================
FILE: tests/cli/test_cli.py
================================================
import prefect
from typer.testing import CliRunner

import controlflow
from controlflow.cli.main import app

runner = CliRunner()


def test_version():
    result = runner.invoke(app, ["version"])
    assert result.exit_code == 0
    assert f"ControlFlow version: {controlflow.__version__}" in result.stdout
    assert f"Prefect version: {prefect.__version__}" in result.stdout



================================================
FILE: tests/deprecated/__init__.py
================================================
[Empty file]


================================================
FILE: tests/deprecated/test_agent.py
================================================
import pytest

import controlflow


# deprecated in 0.9
def test_user_access():
    with pytest.warns(DeprecationWarning):
        a = controlflow.Agent(user_access=True)
        assert a.interactive is True



================================================
FILE: tests/deprecated/test_task.py
================================================
import pytest

import controlflow


def test_user_access():
    # deprecated in 0.9
    with pytest.warns(DeprecationWarning):
        t = controlflow.Task("test", user_access=True)
        assert t.interactive



================================================
FILE: tests/events/__init__.py
================================================
[Empty file]


================================================
FILE: tests/events/test_history.py
================================================
import threading

import pytest

from controlflow.events.events import UserMessage
from controlflow.events.history import FileHistory
from controlflow.flows import Flow


class TestFileHistory:
    def test_write_to_thread_id_file(self, tmp_path):
        h = FileHistory(base_path=tmp_path)
        event = UserMessage(content="test")
        thread_id = "abc"

        # assert a file called 'abc.json' does not exist in tmp_path
        assert not (tmp_path / f"{thread_id}.json").exists()

        h.add_events(thread_id, [event])

        # assert a file called 'abc.json' exists in tmp_path
        assert (tmp_path / f"{thread_id}.json").exists()

    def test_read_from_thread_id_file(self, tmp_path):
        h1 = FileHistory(base_path=tmp_path)
        h2 = FileHistory(base_path=tmp_path)
        event = UserMessage(content="test")
        thread_id = "abc"

        h1.add_events(thread_id, [event])
        # read with different history object
        assert h2.get_events(thread_id) == [event]

    def test_file_histories_respect_base_path(self, tmp_path):
        h1 = FileHistory(base_path=tmp_path)
        h2 = FileHistory(base_path=tmp_path / "subdir")
        event = UserMessage(content="test")
        thread_id = "abc"

        h1.add_events(thread_id, [event])
        # read with different history object
        assert h2.get_events(thread_id) == []
        assert h1.get_events(thread_id) == [event]

    def test_file_history_creates_dir(self, tmp_path):
        h = FileHistory(base_path=tmp_path / "subdir")
        event = UserMessage(content="test")
        thread_id = "abc"

        h.add_events(thread_id, [event])
        assert (tmp_path / "subdir" / f"{thread_id}.json").exists()

    def test_empty_event_content(self, tmp_path):
        """Test adding an event with empty content"""
        h = FileHistory(base_path=tmp_path)
        event = UserMessage(content="")
        thread_id = "abc"
        h.add_events(thread_id, [event])
        assert h.get_events(thread_id) == [event]

    def test_no_events_added(self, tmp_path):
        """Test no events are added and reading from an empty thread"""
        h = FileHistory(base_path=tmp_path)
        thread_id = "xyz"
        assert h.get_events(thread_id) == []

    def test_invalid_file_access(self, tmp_path):
        """Test for file permission errors or non-writable paths"""
        h = FileHistory(base_path="/invalid-path")
        event = UserMessage(content="test")
        thread_id = "abc"
        with pytest.raises(OSError):
            h.add_events(thread_id, [event])


class TestFileHistoryFlow:
    def test_flow_uses_file_history(self, tmp_path):
        f1 = Flow(thread_id="abc", history=FileHistory(base_path=tmp_path))
        f2 = Flow(thread_id="abc", history=FileHistory(base_path=tmp_path))
        event = UserMessage(content="test")
        f1.add_events([event])
        assert f2.get_events() == [event]

    def test_flow_sets_thread_id_for_file_history(self, tmp_path):
        f1 = Flow(thread_id="abc", history=FileHistory(base_path=tmp_path))
        f2 = Flow(thread_id="xyz", history=FileHistory(base_path=tmp_path))
        f3 = Flow(thread_id="abc", history=FileHistory(base_path=tmp_path))

        f1.add_events([UserMessage(content="test")])
        assert len(f1.get_events()) == 1
        assert len(f2.get_events()) == 0
        assert len(f3.get_events()) == 1

    def test_flow_empty_event_content(self, tmp_path):
        """Test flow handling of empty content events"""
        f = Flow(thread_id="abc", history=FileHistory(base_path=tmp_path))
        event = UserMessage(content="")
        f.add_events([event])
        assert f.get_events() == [event]



================================================
FILE: tests/fixtures/__init__.py
================================================
from .instructions import *
from .controlflow import *



================================================
FILE: tests/fixtures/controlflow.py
================================================
import chromadb
import pytest

import controlflow
from controlflow.events.history import InMemoryHistory
from controlflow.memory.providers.chroma import ChromaMemory
from controlflow.settings import temporary_settings
from controlflow.utilities.testing import FakeLLM


@pytest.fixture(autouse=True, scope="session")
def temp_controlflow_settings():
    with temporary_settings(
        enable_default_print_handler=False,
        log_all_messages=True,
        log_level="DEBUG",
        orchestrator_max_agent_turns=10,
        orchestrator_max_llm_calls=10,
    ):
        yield


@pytest.fixture(autouse=True)
def reset_settings_after_each_test():
    with temporary_settings():
        yield


@pytest.fixture(autouse=True)
def temp_controlflow_defaults(tmp_path, monkeypatch):
    # use in-memory history
    monkeypatch.setattr(
        controlflow.defaults,
        "history",
        InMemoryHistory(),
    )

    monkeypatch.setattr(
        controlflow.defaults,
        "memory_provider",
        ChromaMemory(
            client=chromadb.PersistentClient(path=str(tmp_path / "controlflow-memory"))
        ),
    )

    yield


@pytest.fixture(autouse=True)
def reset_defaults_after_each_test(monkeypatch):
    """
    Monkeypatch defaults to themselves, which will automatically reset them after every test
    """
    for k, v in controlflow.defaults.__dict__.items():
        monkeypatch.setattr(controlflow.defaults, k, v)
    yield


@pytest.fixture()
def fake_llm() -> FakeLLM:
    return FakeLLM(responses=[])


@pytest.fixture()
def default_fake_llm(fake_llm) -> FakeLLM:
    controlflow.defaults.model = fake_llm
    return fake_llm



================================================
FILE: tests/fixtures/instructions.py
================================================
import pytest

from controlflow import instructions


@pytest.fixture
def unit_test_instructions():
    with instructions(
        "You are being unit tested. Be as fast and concise as possible. Do not post unecessary messages."
    ):
        yield



================================================
FILE: tests/flows/__init__.py
================================================
[Empty file]


================================================
FILE: tests/flows/test_flows.py
================================================
from controlflow.agents import Agent
from controlflow.events.events import UserMessage
from controlflow.flows import Flow, get_flow
from controlflow.tasks.task import Task
from controlflow.utilities.context import ctx


class TestFlowInitialization:
    def test_flow_initialization(self):
        flow = Flow()
        assert flow.thread_id is not None
        assert len(flow.tools) == 0
        assert flow.default_agent is None
        assert flow.context == {}

    def test_flow_with_custom_tools(self):
        def tool1():
            pass

        def tool2():
            pass

        flow = Flow(tools=[tool1, tool2])
        assert len(flow.tools) == 2
        assert tool1 in flow.tools
        assert tool2 in flow.tools

    def test_flow_with_custom_context(self):
        flow = Flow(context={"key": "value"})
        assert len(flow.context) == 1
        assert flow.context["key"] == "value"


class TestFlowContext:
    def test_flow_context_manager(self):
        with Flow() as flow:
            assert ctx.get("flow") == flow
            assert ctx.get("tasks") is None
        assert ctx.get("flow") is None
        assert ctx.get("tasks") is None

    def test_get_flow_within_context(self):
        with Flow() as flow:
            assert get_flow() == flow

    def test_get_flow_without_context(self):
        assert get_flow() is None

    def test_reentrant_flow_context(self):
        flow = Flow()
        with flow:
            assert get_flow() is flow
            with flow:
                assert get_flow() is flow
                with flow:
                    assert get_flow() is flow
                assert get_flow() is flow
            assert get_flow() is flow
        assert get_flow() is None

    def test_get_flow_nested_contexts(self):
        with Flow() as flow1:
            assert get_flow() == flow1
            with Flow() as flow2:
                assert get_flow() == flow2
            assert get_flow() == flow1
        assert get_flow() is None

    def test_flow_context_resets_task_tracking(self):
        parent_task = Task("Parent task")
        with parent_task:
            assert ctx.get("tasks") == [parent_task]
            with Flow():
                assert ctx.get("tasks") is None
                nested_task = Task("Nested task")
                assert nested_task.parent is None
            assert ctx.get("tasks") == [parent_task]
        assert ctx.get("tasks") is None


class TestFlowHistory:
    def test_get_events_empty(self):
        flow = Flow()
        messages = flow.get_events()
        assert messages == []

    def test_load_parent_history(self):
        flow1 = Flow()
        flow1.add_events(
            [
                UserMessage(content="hello"),
                UserMessage(content="world"),
            ]
        )

        with flow1:
            flow2 = Flow()

        messages1 = flow1.get_events()
        assert len(messages1) == 2
        assert [m.content for m in messages1] == ["hello", "world"]

        messages2 = flow2.get_events()
        assert messages1 == messages2

    def test_load_parent_history_sorts_messages(self):
        flow1 = Flow()
        flow1.add_events(
            [
                UserMessage(content="hello"),
            ]
        )

        with flow1:
            flow2 = Flow()
            flow2.add_events([UserMessage(content="world")])

        flow1.add_events([UserMessage(content="goodbye")])

        messages1 = flow1.get_events()
        assert len(messages1) == 2
        assert [m.content for m in messages1] == ["hello", "goodbye"]

        messages2 = flow2.get_events()
        assert len(messages2) == 3
        assert [m.content for m in messages2] == ["hello", "world", "goodbye"]

    def test_disable_load_parent_history(self):
        flow1 = Flow()
        flow1.add_events(
            [
                UserMessage(content="hello"),
                UserMessage(content="world"),
            ]
        )

        with flow1:
            flow2 = Flow(load_parent_events=False)

        messages1 = flow1.get_events()
        assert len(messages1) == 2
        assert [m.content for m in messages1] == ["hello", "world"]

        messages2 = flow2.get_events()
        assert len(messages2) == 0

    def test_child_flow_messages_dont_go_to_parent(self):
        flow1 = Flow()
        flow1.add_events(
            [
                UserMessage(content="hello"),
                UserMessage(content="world"),
            ]
        )

        with flow1:
            flow2 = Flow()
            flow2.add_events([UserMessage(content="goodbye")])

            messages1 = flow1.get_events()
            assert len(messages1) == 2
            assert [m.content for m in messages1] == ["hello", "world"]

            messages2 = flow2.get_events()
            assert len(messages2) == 3
            assert [m.content for m in messages2] == ["hello", "world", "goodbye"]

    def test_flow_sets_thread_id_for_history(self, tmpdir):
        f1 = Flow(thread_id="abc")
        f2 = Flow(thread_id="xyz")
        f3 = Flow(thread_id="abc")

        f1.add_events([UserMessage(content="test")])
        assert len(f1.get_events()) == 1
        assert len(f2.get_events()) == 0
        assert len(f3.get_events()) == 1


class TestFlowCreatesDefaults:
    def test_flow_with_custom_agents(self):
        agent1 = Agent()
        flow = Flow(default_agent=agent1)  # Changed from 'agent'
        assert flow.default_agent == agent1  # Changed from 'agent'

    def test_flow_agent_becomes_task_default(self):
        agent = Agent()
        t1 = Task("t1")
        assert agent not in t1.get_agents()
        assert len(t1.get_agents()) == 1

        with Flow(default_agent=agent):  # Changed from 'agent'
            t2 = Task("t2")
            assert agent in t2.get_agents()
            assert len(t2.get_agents()) == 1


class TestFlowPrompt:
    def test_default_prompt(self):
        flow = Flow()
        assert flow.prompt is None

    def test_default_template(self):
        flow = Flow()
        prompt = flow.get_prompt()
        assert prompt.startswith("# Flow")

    def test_custom_prompt(self):
        flow = Flow(prompt="Custom Prompt")
        prompt = flow.get_prompt()
        assert prompt == "Custom Prompt"

    def test_custom_templated_prompt(self):
        flow = Flow(prompt="{{ flow.name }}", name="abc")
        prompt = flow.get_prompt()
        assert prompt == "abc"



================================================
FILE: tests/flows/test_graph.py
================================================
# test_graph.py
from controlflow.flows.graph import Edge, EdgeType, Graph
from controlflow.tasks.task import Task


def test_graph_initialization():
    graph = Graph()
    assert len(graph.tasks) == 0
    assert len(graph.edges) == 0


def test_add_task():
    graph = Graph()
    task = Task(objective="Test objective")
    graph.add_task(task)
    assert len(graph.tasks) == 1
    assert task in graph.tasks


def test_add_edge():
    graph = Graph()
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2")
    edge = Edge(upstream=task1, downstream=task2, type=EdgeType.DEPENDENCY)
    graph.add_edge(edge)
    assert len(graph.tasks) == 2
    assert task1 in graph.tasks
    assert task2 in graph.tasks
    assert len(graph.edges) == 1
    assert edge in graph.edges


def test_from_tasks():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2", depends_on=[task1])
    task3 = Task(objective="Task 3", parent=task2)
    graph = Graph(tasks=[task1, task2, task3])
    assert len(graph.tasks) == 3
    assert task1 in graph.tasks
    assert task2 in graph.tasks
    assert task3 in graph.tasks
    assert len(graph.edges) == 2
    assert any(
        edge.upstream == task1
        and edge.downstream == task2
        and edge.type == EdgeType.DEPENDENCY
        for edge in graph.edges
    )
    assert any(
        edge.upstream == task3
        and edge.downstream == task2
        and edge.type == EdgeType.SUBTASK
        for edge in graph.edges
    )


def test_upstream_edges():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2", depends_on=[task1])
    graph = Graph(tasks=[task1, task2])
    upstream_edges = graph.upstream_edges()
    assert len(upstream_edges[task1]) == 0
    assert len(upstream_edges[task2]) == 1
    assert upstream_edges[task2][0].upstream == task1


def test_downstream_edges():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2", depends_on=[task1])
    graph = Graph(tasks=[task1, task2])
    downstream_edges = graph.downstream_edges()
    assert len(downstream_edges[task1]) == 1
    assert len(downstream_edges[task2]) == 0
    assert downstream_edges[task1][0].downstream == task2


def test_topological_sort():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2", depends_on=[task1])
    task3 = Task(objective="Task 3", depends_on=[task2])
    task4 = Task(objective="Task 4", depends_on=[task3])
    graph = Graph(tasks=[task1, task2, task3, task4])
    sorted_tasks = graph.topological_sort()
    assert len(sorted_tasks) == 4
    assert sorted_tasks.index(task1) < sorted_tasks.index(task2)
    assert sorted_tasks.index(task2) < sorted_tasks.index(task3)
    assert sorted_tasks.index(task3) < sorted_tasks.index(task4)


def test_topological_sort_uses_time_to_tiebreak():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2")
    task3 = Task(objective="Task 3")
    task4 = Task(objective="Task 4")
    graph = Graph(tasks=[task1, task2, task3, task4])
    sorted_tasks = graph.topological_sort()
    assert sorted_tasks == [task1, task2, task3, task4]


def test_topological_sort_with_fan_in_and_fan_out():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2")
    task3 = Task(objective="Task 3")

    edge1 = Edge(upstream=task1, downstream=task2, type=EdgeType.DEPENDENCY)
    edge2 = Edge(upstream=task1, downstream=task3, type=EdgeType.DEPENDENCY)
    edge3 = Edge(upstream=task2, downstream=task3, type=EdgeType.DEPENDENCY)

    graph = Graph()
    graph.add_edge(edge1)
    graph.add_edge(edge2)
    graph.add_edge(edge3)

    sorted_tasks = graph.topological_sort()

    assert len(sorted_tasks) == 3
    assert sorted_tasks.index(task1) < sorted_tasks.index(task2)
    assert sorted_tasks.index(task1) < sorted_tasks.index(task3)
    assert sorted_tasks.index(task2) < sorted_tasks.index(task3)

    assert graph.topological_sort(tasks=[task3, task1]) == [task1, task3]


def test_upstream_tasks():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2")
    task3 = Task(objective="Task 3")

    edge1 = Edge(upstream=task1, downstream=task2, type=EdgeType.DEPENDENCY)
    edge2 = Edge(upstream=task1, downstream=task3, type=EdgeType.DEPENDENCY)
    edge3 = Edge(upstream=task2, downstream=task3, type=EdgeType.DEPENDENCY)

    graph = Graph()
    graph.add_edge(edge1)
    graph.add_edge(edge2)
    graph.add_edge(edge3)

    assert graph.upstream_tasks([task3]) == [task1, task2, task3]
    assert graph.upstream_tasks([task2]) == [task1, task2]
    assert graph.upstream_tasks([task1]) == [task1]

    assert graph.upstream_tasks([task1, task3]) == [task1, task2, task3]


def test_downstream_tasks():
    task1 = Task(objective="Task 1")
    task2 = Task(objective="Task 2")
    task3 = Task(objective="Task 3")

    edge1 = Edge(upstream=task1, downstream=task2, type=EdgeType.DEPENDENCY)
    edge2 = Edge(upstream=task1, downstream=task3, type=EdgeType.DEPENDENCY)
    edge3 = Edge(upstream=task2, downstream=task3, type=EdgeType.DEPENDENCY)

    graph = Graph()
    graph.add_edge(edge1)
    graph.add_edge(edge2)
    graph.add_edge(edge3)

    assert graph.downstream_tasks([task3]) == [task3]
    assert graph.downstream_tasks([task2]) == [task2, task3]
    assert graph.downstream_tasks([task1]) == [task1, task2, task3]

    # never include a start task in the downstream list
    assert graph.downstream_tasks([task1, task3]) == [task1, task2, task3]


# def test_parent_child_tracking():
#     with Flow() as flow:
#         with SimpleTask() as parent:
#             with SimpleTask() as child:
#                 grandchild = SimpleTask()

#     assert parent in flow.tasks
#     assert child in flow.tasks
#     assert grandchild in flow.tasks

#     assert len(flow.graph.edges) == 2



================================================
FILE: tests/flows/test_sign_guestbook.py
================================================
import pytest

from controlflow import Agent, Task, flow

# define agents

a = Agent(name="a")
b = Agent(name="b")
c = Agent(name="c")


# define tools

GUESTBOOK = []


def sign(name):
    """sign your name in the guestbook"""
    GUESTBOOK.append(name)


def view_guestbook():
    """view the guestbook"""
    return GUESTBOOK


# define flow


@flow
def guestbook_flow():
    task = Task(
        """
        Add your name to the list using the `sign` tool. All agents must
        sign their names for the task to be complete. You can read the sign to
        see if that has happened yet. You can not sign for another agent.
        """,
        agents=[a, b, c],
        tools=[sign, view_guestbook],
    )
    task.run()


# run test


@pytest.mark.skip(reason="Skipping test for now")
def test():
    guestbook_flow()
    assert GUESTBOOK == ["a", "b", "c"]



================================================
FILE: tests/llm/__init__.py
================================================
[Empty file]


================================================
FILE: tests/llm/test_models.py
================================================
import pytest
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_groq import ChatGroq
from langchain_ollama import ChatOllama
from langchain_openai import AzureChatOpenAI, ChatOpenAI

from controlflow.llm.models import get_model


def test_get_model_from_openai(monkeypatch):
    monkeypatch.setenv("OPENAI_API_KEY", "fake_openai_api_key")
    model = get_model("openai/gpt-4o-mini")
    assert isinstance(model, ChatOpenAI)
    assert model.model_name == "gpt-4o-mini"


def test_get_model_from_anthropic(monkeypatch):
    monkeypatch.setenv("ANTHROPIC_API_KEY", "fake_anthropic_api_key")
    model = get_model("anthropic/claude-3-haiku-20240307")
    assert isinstance(model, ChatAnthropic)
    assert model.model == "claude-3-haiku-20240307"


def test_get_azure_openai_model(monkeypatch):
    monkeypatch.setenv("AZURE_OPENAI_API_KEY", "fake_azure_openai_api_key")
    monkeypatch.setenv(
        "AZURE_OPENAI_ENDPOINT", "https://fake-endpoint.openai.azure.com"
    )
    monkeypatch.setenv("OPENAI_API_VERSION", "2024-05-01-preview")
    model = get_model("azure-openai/gpt-4")
    assert isinstance(model, AzureChatOpenAI)
    assert model.model_name == "gpt-4"


def test_get_google_model(monkeypatch):
    monkeypatch.setenv("GOOGLE_API_KEY", "fake_google_api_key")
    model = get_model("google/gemini-1.5-pro")
    assert isinstance(model, ChatGoogleGenerativeAI)
    assert model.model == "models/gemini-1.5-pro"


def test_get_groq_model(monkeypatch):
    monkeypatch.setenv("GROQ_API_KEY", "fake_groq_api_key")
    model = get_model("groq/mixtral-8x7b-32768")
    assert isinstance(model, ChatGroq)
    assert model.model_name == "mixtral-8x7b-32768"


def test_get_ollama_model(monkeypatch):
    model = get_model("ollama/qwen2.5")
    assert isinstance(model, ChatOllama)
    assert model.model == "qwen2.5"


def test_get_model_with_invalid_format():
    with pytest.raises(ValueError, match="The model `gpt-4o` is not valid."):
        get_model("gpt-4o")


def test_get_model_with_unsupported_provider():
    with pytest.raises(
        ValueError, match="Could not load provider `unsupported` automatically."
    ):
        get_model("unsupported/model-name")


def test_get_model_with_temperature(monkeypatch):
    monkeypatch.setenv("ANTHROPIC_API_KEY", "fake_anthropic_api_key")
    model = get_model("anthropic/claude-3-haiku-20240307", temperature=0.7)
    assert isinstance(model, ChatAnthropic)
    assert model.temperature == 0.7



================================================
FILE: tests/memory/__init__.py
================================================
[Empty file]


================================================
FILE: tests/memory/test_memory.py
================================================
import chromadb
import pytest

import controlflow
from controlflow.memory.providers.chroma import ChromaMemory


class TestMemory:
    def test_store_and_retrieve(self):
        m = controlflow.Memory(key="test", instructions="test")
        m.add("The number is 42")
        result = m.search("numbers")
        assert len(result) == 1
        assert "The number is 42" in result.values()

    def test_delete(self):
        m = controlflow.Memory(key="test", instructions="test")
        m_id = m.add("The number is 42")
        m.delete(m_id)
        result = m.search("numbers")
        assert len(result) == 0

    def test_search(self):
        m = controlflow.Memory(key="test", instructions="test")
        m.add("The number is 42")
        m.add("The number is 43")
        result = m.search("numbers")
        assert len(result) == 2
        assert "The number is 42" in result.values()
        assert "The number is 43" in result.values()


class TestMemoryProvider:
    def test_load_from_string_invalid(self):
        with pytest.raises(ValueError):
            controlflow.Memory(key="test", instructions="test", provider="invalid")

    def test_load_from_string_chroma_db(self):
        m = controlflow.Memory(key="test", instructions="test", provider="chroma-db")
        assert isinstance(m.provider, ChromaMemory)

    def test_load_from_instance(self, tmp_path):
        mp = ChromaMemory(
            client=chromadb.PersistentClient(path=str(tmp_path / "test_path"))
        )
        m = controlflow.Memory(key="test", instructions="test", provider=mp)



================================================
FILE: tests/orchestration/__init__.py
================================================
[Empty file]


================================================
FILE: tests/orchestration/test_orchestrator.py
================================================
from unittest.mock import MagicMock, patch

import pytest

import controlflow.orchestration.conditions
from controlflow.agents import Agent
from controlflow.flows import Flow
from controlflow.orchestration.orchestrator import Orchestrator
from controlflow.orchestration.turn_strategies import Popcorn, TurnStrategy
from controlflow.tasks.task import Task
from controlflow.utilities.testing import FakeLLM, SimpleTask


class TestOrchestratorLimits:
    @pytest.fixture
    def orchestrator(self, default_fake_llm):
        default_fake_llm.set_responses([dict(name="count_call")])
        self.calls = 0
        self.turns = 0

        class TwoCallTurnStrategy(TurnStrategy):
            """
            A turn strategy that ends a turn after 2 calls
            """

            calls: int = 0

            def get_tools(self, *args, **kwargs):
                return []

            def get_next_agent(self, current_agent, available_agents):
                return current_agent

            def begin_turn(ts_instance):
                self.turns += 1
                super().begin_turn()

            def should_end_turn(ts_self):
                ts_self.calls += 1
                # if this would be the third call, end the turn
                if ts_self.calls >= 3:
                    ts_self.calls = 0
                    return True
                # record a new call for the unit test
                # self.calls += 1
                return False

        def count_call():
            self.calls += 1

        agent = Agent(tools=[count_call])
        task = Task("Test task", agents=[agent])
        flow = Flow()
        orchestrator = Orchestrator(
            tasks=[task],
            flow=flow,
            agent=agent,
            turn_strategy=TwoCallTurnStrategy(),
        )
        return orchestrator

    def test_max_llm_calls(self, orchestrator):
        orchestrator.run(max_llm_calls=5)
        assert self.calls == 5

    def test_max_agent_turns(self, orchestrator):
        orchestrator.run(max_agent_turns=3)
        assert self.calls == 6

    def test_max_llm_calls_and_max_agent_turns(self, orchestrator):
        orchestrator.run(
            max_llm_calls=10,
            max_agent_turns=3,
            model_kwargs={"tool_choice": "required"},
        )
        assert self.calls == 6

    def test_default_limits(self, orchestrator):
        orchestrator.run(model_kwargs={"tool_choice": "required"})
        assert self.calls == 10  # Assuming the default max_llm_calls is 10


class TestOrchestratorCreation:
    def test_create_orchestrator_with_agent(self):
        agent = Agent()
        task = Task("Test task", agents=[agent])
        flow = Flow()
        orchestrator = Orchestrator(tasks=[task], flow=flow, agent=agent)

        assert orchestrator.agent == agent
        assert orchestrator.flow == flow
        assert orchestrator.tasks == [task]

    def test_create_orchestrator_without_agent(self):
        task = Task("Test task")
        flow = Flow()
        orchestrator = Orchestrator(tasks=[task], flow=flow, agent=None)

        assert orchestrator.agent is None
        assert orchestrator.flow == flow
        assert orchestrator.tasks == [task]

    def test_run_sets_agent_if_none(self):
        agent1 = Agent(id="agent1")
        agent2 = Agent(id="agent2")
        task = Task("Test task", agents=[agent1, agent2])
        flow = Flow()
        turn_strategy = Popcorn()
        orchestrator = Orchestrator(
            tasks=[task], flow=flow, agent=None, turn_strategy=turn_strategy
        )

        assert orchestrator.agent is None

        orchestrator.run(max_agent_turns=0)

        assert orchestrator.agent is not None
        assert orchestrator.agent in [agent1, agent2]

    def test_run_keeps_existing_agent_if_set(self):
        agent1 = Agent(id="agent1")
        agent2 = Agent(id="agent2")
        task = Task("Test task", agents=[agent1, agent2])
        flow = Flow()
        turn_strategy = Popcorn()
        orchestrator = Orchestrator(
            tasks=[task], flow=flow, agent=agent1, turn_strategy=turn_strategy
        )

        assert orchestrator.agent == agent1

        orchestrator.run(max_agent_turns=0)

        assert orchestrator.agent == agent1


class TestRunEndConditions:
    def test_run_until_all_complete(self, monkeypatch):
        task1 = SimpleTask()
        task2 = SimpleTask()
        orchestrator = Orchestrator(tasks=[task1, task2], flow=Flow(), agent=Agent())

        # Mock the run_agent_turn method
        def mock_run_agent_turn(*args, **kwargs):
            task1.mark_successful()
            task2.mark_successful()
            return 1

        monkeypatch.setitem(
            orchestrator.__dict__,
            "run_agent_turn",
            MagicMock(side_effect=mock_run_agent_turn),
        )

        orchestrator.run(run_until=controlflow.orchestration.conditions.AllComplete())

        assert all(task.is_complete() for task in orchestrator.tasks)

    def test_run_until_any_complete(self, monkeypatch):
        task1 = SimpleTask()
        task2 = SimpleTask()
        orchestrator = Orchestrator(tasks=[task1, task2], flow=Flow(), agent=Agent())

        # Mock the run_agent_turn method
        def mock_run_agent_turn(*args, **kwargs):
            task1.mark_successful()
            return 1

        monkeypatch.setitem(
            orchestrator.__dict__,
            "run_agent_turn",
            MagicMock(side_effect=mock_run_agent_turn),
        )

        orchestrator.run(run_until=controlflow.orchestration.conditions.AnyComplete())

        assert any(task.is_complete() for task in orchestrator.tasks)

    def test_run_until_fn_condition(self, monkeypatch):
        task1 = SimpleTask()
        task2 = SimpleTask()
        orchestrator = Orchestrator(tasks=[task1, task2], flow=Flow(), agent=Agent())

        # Mock the run_agent_turn method
        def mock_run_agent_turn(*args, **kwargs):
            task2.mark_successful()
            return 1

        monkeypatch.setitem(
            orchestrator.__dict__,
            "run_agent_turn",
            MagicMock(side_effect=mock_run_agent_turn),
        )

        orchestrator.run(
            run_until=controlflow.orchestration.conditions.FnCondition(
                lambda context: context.orchestrator.tasks[1].is_complete()
            )
        )

        assert task2.is_complete()

    def test_run_until_lambda_condition(self, monkeypatch):
        task1 = SimpleTask()
        task2 = SimpleTask()
        orchestrator = Orchestrator(tasks=[task1, task2], flow=Flow(), agent=Agent())

        # Mock the run_agent_turn method
        def mock_run_agent_turn(*args, **kwargs):
            task2.mark_successful()
            return 1

        monkeypatch.setitem(
            orchestrator.__dict__,
            "run_agent_turn",
            MagicMock(side_effect=mock_run_agent_turn),
        )

        orchestrator.run(
            run_until=lambda context: context.orchestrator.tasks[1].is_complete()
        )

        assert task2.is_complete()

    def test_compound_condition(self, monkeypatch):
        task1 = SimpleTask()
        task2 = SimpleTask()
        orchestrator = Orchestrator(tasks=[task1, task2], flow=Flow(), agent=Agent())

        # Mock the run_agent_turn method
        def mock_run_agent_turn(*args, **kwargs):
            return 1

        monkeypatch.setitem(
            orchestrator.__dict__,
            "run_agent_turn",
            MagicMock(side_effect=mock_run_agent_turn),
        )

        orchestrator.run(
            run_until=(
                # this condition will always fail
                controlflow.orchestration.conditions.FnCondition(lambda context: False)
                |
                # this condition will always pass
                controlflow.orchestration.conditions.FnCondition(lambda context: True)
            )
        )

        # assert to prove we reach this point and the run stopped
        assert True



================================================
FILE: tests/orchestration/test_rules.py
================================================
from typing import Union

import pytest
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from pydantic import BaseModel

from controlflow.llm.rules import OpenAIRules


class OpenAIFirst(BaseModel):
    model: Union[ChatOpenAI, AzureChatOpenAI]


class AzureFirst(BaseModel):
    model: Union[AzureChatOpenAI, ChatOpenAI]


class TestModelTypeValidation:
    """
    These tests document a bug in langchain's pydantic implementation where Union type
    validation depends on the order of types. This is tested as a canary since the
    behavior shouldn't affect controlflow - this test suite exists for reference only.
    """

    def test_openai_first_validation(self):
        """Test validation when ChatOpenAI is first in Union"""
        openai = ChatOpenAI(model="gpt-4")
        azure = AzureChatOpenAI(api_version="1", azure_endpoint="2")

        # OpenAI model should work
        model = OpenAIFirst(model=openai)
        assert isinstance(model.model, ChatOpenAI)

        # Azure model should fail
        with pytest.raises(Exception):
            OpenAIFirst(model=azure)

    def test_azure_first_validation(self):
        """Test validation when AzureChatOpenAI is first in Union"""
        openai = ChatOpenAI(model="gpt-4")
        azure = AzureChatOpenAI(api_version="1", azure_endpoint="2")

        # Azure model should work
        model = AzureFirst(model=azure)
        assert isinstance(model.model, AzureChatOpenAI)

        # OpenAI model should fail
        with pytest.raises(Exception):
            AzureFirst(model=openai)

    def test_controlflow_model_validation(self):
        """Test that controlflow's own typing accepts both model types"""
        openai = ChatOpenAI(model="gpt-4")
        azure = AzureChatOpenAI(api_version="1", azure_endpoint="2")

        # Both model types should work with OpenAIRules
        rules_openai = OpenAIRules(model=openai)
        assert isinstance(rules_openai.model, ChatOpenAI)

        rules_azure = OpenAIRules(model=azure)
        assert isinstance(rules_azure.model, AzureChatOpenAI)



================================================
FILE: tests/orchestration/test_turn_strategies.py
================================================
import pytest

from controlflow.agents.agent import Agent
from controlflow.orchestration.turn_strategies import (
    Moderated,
    MostBusy,
    Popcorn,
    Random,
    RoundRobin,
    SingleAgent,
)
from controlflow.tasks.task import Task


@pytest.fixture
def agents():
    return [Agent(name=f"Agent{i}") for i in range(1, 4)]


@pytest.fixture
def tasks(agents: list[Agent]):
    return [
        Task(objective=f"Task{i}", agents=[agents[i % len(agents)]]) for i in range(6)
    ]


@pytest.fixture
def available_agents(agents: list[Agent], tasks: list[Task]):
    return {
        agents[0]: tasks[0:3],
        agents[1]: tasks[3:5],
        agents[2]: tasks[5:6],
    }


def test_single_strategy(agents, available_agents):
    strategy = SingleAgent(agent=agents[0])
    current_agent = agents[0]

    tools = strategy.get_tools(current_agent, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "end_turn"

    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent == current_agent


def test_popcorn_strategy(agents, available_agents):
    strategy = Popcorn()
    current_agent = agents[0]

    tools = strategy.get_tools(current_agent, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "delegate_to_agent"

    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent == current_agent

    strategy.next_agent = agents[1]
    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent == agents[1]


def test_random_strategy(agents, available_agents):
    strategy = Random()
    current_agent = agents[0]

    tools = strategy.get_tools(current_agent, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "end_turn"

    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent in agents


def test_round_robin_strategy(agents, available_agents):
    strategy = RoundRobin()
    current_agent = agents[0]

    tools = strategy.get_tools(current_agent, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "end_turn"

    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent == agents[1]

    next_agent = strategy.get_next_agent(agents[2], available_agents)
    assert next_agent == agents[0]


def test_most_busy_strategy(agents, available_agents):
    strategy = MostBusy()
    current_agent = agents[0]

    tools = strategy.get_tools(current_agent, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "end_turn"

    next_agent = strategy.get_next_agent(current_agent, available_agents)
    assert next_agent == agents[0]  # Agent0 has the most tasks (3)


def test_moderated_strategy(agents, available_agents):
    moderator = agents[0]
    strategy = Moderated(moderator=moderator)

    tools = strategy.get_tools(moderator, available_agents)
    assert len(tools) == 1
    assert tools[0].name == "delegate_to_agent"

    tools = strategy.get_tools(agents[1], available_agents)
    assert len(tools) == 1
    assert tools[0].name == "end_turn"

    next_agent = strategy.get_next_agent(moderator, available_agents)
    assert next_agent == moderator

    strategy.next_agent = agents[1]
    next_agent = strategy.get_next_agent(moderator, available_agents)
    assert next_agent == agents[1]

    next_agent = strategy.get_next_agent(agents[1], available_agents)
    assert next_agent == moderator



================================================
FILE: tests/tasks/__init__.py
================================================
[Empty file]


================================================
FILE: tests/tasks/test_tasks.py
================================================
from enum import Enum
from typing import Annotated, Any, Dict, List, Literal

import pytest
from pydantic import BaseModel

import controlflow
from controlflow.agents import Agent
from controlflow.events.base import Event
from controlflow.events.events import AgentMessage
from controlflow.flows import Flow
from controlflow.instructions import instructions
from controlflow.orchestration.handler import AsyncHandler, Handler
from controlflow.tasks.task import (
    COMPLETE_STATUSES,
    INCOMPLETE_STATUSES,
    Task,
    TaskStatus,
)
from controlflow.utilities.context import ctx
from controlflow.utilities.testing import SimpleTask


def test_status_coverage():
    assert INCOMPLETE_STATUSES | COMPLETE_STATUSES == set(TaskStatus)


def test_context_open_and_close():
    assert ctx.get("tasks") is None
    with SimpleTask() as ta:
        assert ctx.get("tasks") == [ta]
        with SimpleTask() as tb:
            assert ctx.get("tasks") == [ta, tb]
        assert ctx.get("tasks") == [ta]
    assert ctx.get("tasks") is None


def test_task_requires_objective():
    with pytest.raises(ValueError):
        Task()


def test_task_initialization():
    task = Task(objective="Test objective")
    assert task.objective == "Test objective"
    assert task.status == TaskStatus.PENDING
    assert task.result is None


@pytest.mark.skip(reason="IDs are not stable right now")
def test_stable_id():
    t1 = Task(objective="Test Objective")
    t2 = Task(objective="Test Objective")
    t3 = Task(objective="Test Objective+")
    assert t1.id == t2.id == "9663272a"  # Update this line with the new ID
    assert t3.id != t1.id  # Ensure different objectives produce different IDs


def test_task_mark_successful_and_mark_failed():
    task = Task(objective="Test Objective", result_type=int)
    task.mark_successful(result=5)
    assert task.result == 5
    assert task.status == TaskStatus.SUCCESSFUL
    task.mark_failed(reason="test error")
    assert task.status == TaskStatus.FAILED
    assert task.result == "test error"


def test_task_loads_instructions_at_creation():
    with instructions("test instruction"):
        task = SimpleTask()

    assert "test instruction" in task.instructions


def test_task_dependencies():
    task1 = SimpleTask()
    task2 = SimpleTask(depends_on=[task1])
    assert task1 in task2.depends_on
    assert task2 in task1._downstreams


def test_task_subtasks():
    task1 = SimpleTask()
    task2 = SimpleTask(parent=task1)
    assert task2 in task1._subtasks
    assert task2.parent is task1


def test_task_parent_context():
    with SimpleTask() as task1:
        with SimpleTask() as task2:
            task3 = SimpleTask()

    assert task3.parent is task2
    assert task2.parent is task1
    assert task1.parent is None

    assert task1._subtasks == {task2}
    assert task2._subtasks == {task3}
    assert task3._subtasks == set()


def test_task_agent_assignment():
    agent = Agent()
    task = SimpleTask(agents=[agent])
    assert task.agents == [agent]
    assert task.get_agents() == [agent]


def test_task_bad_agent_assignment():
    with pytest.raises(ValueError):
        SimpleTask(agents=5)


def test_task_loads_agent_from_parent():
    agent = Agent()
    with SimpleTask(agents=[agent]):
        child = SimpleTask()

    assert child.agents is None
    assert child.get_agents() == [agent]


def test_task_loads_agent_from_flow():
    def_agent = controlflow.defaults.agent
    agent = Agent()
    with Flow(default_agent=agent):
        task = SimpleTask()

        assert task.agents is None
        assert task.get_agents() == [agent]

    # outside the flow context, pick up the default agent
    assert task.get_agents() == [def_agent]


def test_task_loads_agent_from_default_if_none_otherwise():
    agent = controlflow.defaults.agent
    task = SimpleTask()

    assert task.agents is None
    assert task.get_agents() == [agent]


def test_task_loads_agent_from_parent_before_flow():
    agent1 = Agent()
    agent2 = Agent()
    with Flow(default_agent=agent1):
        with SimpleTask(agents=[agent2]):
            child = SimpleTask()

    assert child.agents is None
    assert child.get_agents() == [agent2]


def test_completion_agents_default():
    task = Task(objective="Test task")
    assert task.completion_agents is None


def test_completion_agents_set():
    agent1 = Agent(name="Agent 1")
    agent2 = Agent(name="Agent 2")
    task = Task(objective="Test task", completion_agents=[agent1, agent2])
    assert task.completion_agents == [agent1, agent2]


class TestTaskStatus:
    def test_task_status_transitions(self):
        task = SimpleTask()
        assert task.is_incomplete()
        assert not task.is_running()
        assert not task.is_complete()
        assert not task.is_successful()
        assert not task.is_failed()
        assert not task.is_skipped()

        task.mark_successful()
        assert not task.is_incomplete()
        assert not task.is_running()
        assert task.is_complete()
        assert task.is_successful()
        assert not task.is_failed()
        assert not task.is_skipped()

        task = SimpleTask()
        task.mark_failed()
        assert not task.is_incomplete()
        assert task.is_complete()
        assert not task.is_successful()
        assert task.is_failed()
        assert not task.is_skipped()

        task = SimpleTask()
        task.mark_skipped()
        assert not task.is_incomplete()
        assert task.is_complete()
        assert not task.is_successful()
        assert not task.is_failed()
        assert task.is_skipped()

    def test_task_ready(self):
        task1 = SimpleTask()
        assert task1.is_ready()

    def test_task_not_ready_if_successful(self):
        task1 = SimpleTask()
        task1.mark_successful()
        assert not task1.is_ready()

    def test_task_not_ready_if_failed(self):
        task1 = SimpleTask()
        task1.mark_failed()
        assert not task1.is_ready()

    def test_task_not_ready_if_dependencies_are_ready(self):
        task1 = SimpleTask()
        task2 = SimpleTask(depends_on=[task1])
        assert task1.is_ready()
        assert not task2.is_ready()

    def test_task_ready_if_dependencies_are_ready(self):
        task1 = SimpleTask()
        task2 = SimpleTask(depends_on=[task1])
        task1.mark_successful()
        assert not task1.is_ready()
        assert task2.is_ready()

    def test_task_hash(self):
        task1 = SimpleTask()
        task2 = SimpleTask()
        assert hash(task1) != hash(task2)


class TestTaskPrompt:
    def test_default_prompt(self):
        task = SimpleTask()
        assert task.prompt is None

    def test_default_template(self):
        task = SimpleTask()
        prompt = task.get_prompt()
        assert prompt.startswith("- id:")
        assert "- objective: test" in prompt
        assert "- context:" in prompt

    def test_custom_prompt(self):
        task = SimpleTask(prompt="Custom Prompt")
        prompt = task.get_prompt()
        assert prompt == "Custom Prompt"

    def test_custom_templated_prompt(self):
        task = SimpleTask(prompt="{{ task.objective }}", objective="abc")
        prompt = task.get_prompt()
        assert prompt == "abc"


class TestResultType:
    def test_int_result(self):
        task = Task("choose 5", result_type=int)
        task.mark_successful(result=5)
        assert task.result == 5

    def test_str_result(self):
        task = Task("choose 5", result_type=str)
        task.mark_successful(result="5")
        assert task.result == "5"

    def test_typed_dict_result(self):
        task = Task("", result_type=dict[str, int])
        task.mark_successful(result={"a": 5, "b": "6"})
        assert task.result == {"a": 5, "b": 6}

    def test_special_list_type_result(self):
        # test capitalized List type
        task = Task("", result_type=List[int])
        task.mark_successful(result=[5, 6])
        assert task.result == [5, 6]

    def test_special_dict_type_result(self):
        # test capitalized Dict type
        task = Task("", result_type=Dict[str, int])
        task.mark_successful(result={"a": 5, "b": "6"})
        assert task.result == {"a": 5, "b": 6}

    def test_pydantic_result(self):
        class Name(BaseModel):
            first: str
            last: str

        task = Task("The character said his name is John Doe", result_type=Name)
        task.run()
        assert task.result == Name(first="John", last="Doe")

    def test_annotated_result(self):
        task = Task(
            "generate any result that satisfies the result type",
            result_type=Annotated[str, "a 5 digit zip code"],
        )
        task.run()
        assert len(task.result) == 5
        assert int(task.result)


class TestResultTypeConstrainedChoice:
    class Letter(BaseModel):
        letter: str

        def __hash__(self):
            return id(self)

    A = Letter(letter="a")
    B = Letter(letter="b")
    C = Letter(letter="c")

    def test_tuple_of_ints_result(self):
        task = Task("choose 5", result_type=(4, 5, 6))
        task.mark_successful(result=5)
        assert task.result == 5

    def test_tuple_of_ints_validates(self):
        task = Task("choose 5", result_type=(4, 5, 6))
        with pytest.raises(ValueError):
            task.mark_successful(result=7)

    def test_list_of_strings_result(self):
        # test list of strings result
        task = Task(
            "Choose the second letter of the alphabet", result_type=["b", "c", "a"]
        )
        task.run()
        assert task.result == "b"

    def test_list_of_objects_result(self):
        # test list of strings result
        task = Task(
            "Choose the second letter of the alphabet",
            result_type=[self.A, self.C, self.B],
        )
        task.run()
        assert task.result is self.B

    def test_tuple_of_objects_result(self):
        # test list of strings result
        task = Task(
            "Choose the second letter of the alphabet",
            result_type=(self.A, self.C, self.B),
        )
        task.run()
        assert task.result is self.B

    def test_set_of_objects_result(self):
        # test list of strings result
        task = Task(
            "Choose the second letter of the alphabet",
            result_type={self.A, self.C, self.B},
        )
        task.run()
        assert task.result is self.B

    def test_literal_string_result(self):
        task = Task(
            "Choose the second letter of the alphabet",
            result_type=Literal["a", "c", "b"],
        )
        task.run()
        assert task.result == "b"

    def test_enum_result(self):
        class Letters(Enum):
            A = "a"
            B = "b"
            C = "c"

        task = Task("Choose the second letter of the alphabet", result_type=Letters)
        task.run()
        assert task.result is Letters.B

    def test_literal_object_result(self):
        # this is bad syntax, but works
        task = Task(
            "Choose the second letter of the alphabet",
            result_type=Literal[self.A, self.B, self.C],  # noqa
        )
        task.run()
        assert task.result is self.B

    def test_list_of_literals_result(self):
        task = Task(
            "Choose the second and third letters of the alphabet",
            result_type=list[Literal["a", "b", "c"]],
        )
        task.run()
        assert task.result == ["b", "c"]

    def test_map_labels_to_values(self):
        task = Task(
            "Choose the right label, in order provided in context",
            context=dict(goals=["the second letter", "the first letter"]),
            result_type=list[Literal["a", "b", "c"]],
        )
        task.run()
        assert task.result == ["b", "a"]


class TestResultValidator:
    def test_result_validator(self):
        def validate_even(value: int) -> int:
            if value % 2 != 0:
                raise ValueError("Value must be even")
            return value

        task = Task(
            "choose an even number", result_type=int, result_validator=validate_even
        )
        task.mark_successful(result=4)
        assert task.result == 4

        with pytest.raises(ValueError, match="Value must be even"):
            task.mark_successful(result=5)

    def test_result_validator_with_constraints(self):
        def validate_range(value: int) -> int:
            if not 10 <= value <= 20:
                raise ValueError("Value must be between 10 and 20")
            return value

        task = Task("choose a number", result_type=int, result_validator=validate_range)
        task.mark_successful(result=15)
        assert task.result == 15

        with pytest.raises(ValueError, match="Value must be between 10 and 20"):
            task.mark_successful(result=5)

    def test_result_validator_with_modification(self):
        def round_to_nearest_ten(value: int) -> int:
            return round(value, -1)

        task = Task(
            "choose a number", result_type=int, result_validator=round_to_nearest_ten
        )
        task.mark_successful(result=44)
        assert task.result == 40

        task.mark_successful(result=46)
        assert task.result == 50

    def test_result_validator_with_pydantic_model(self):
        class User(BaseModel):
            name: str
            age: int

        def validate_adult(user: User) -> User:
            if user.age < 18:
                raise ValueError("User must be an adult")
            return user

        task = Task(
            "create an adult user", result_type=User, result_validator=validate_adult
        )
        task.mark_successful(result={"name": "John", "age": 25})
        assert task.result == User(name="John", age=25)

        with pytest.raises(ValueError, match="User must be an adult"):
            task.mark_successful(result={"name": "Jane", "age": 16})

    def test_result_validator_applied_after_type_coercion(self):
        def always_return_none(value: Any) -> None:
            return None

        task = Task(
            "do something with no result",
            result_type=None,
            result_validator=always_return_none,
        )

        with pytest.raises(
            ValueError, match="Task has result_type=None, but a result was provided"
        ):
            task.mark_successful(result="anything")


class TestSuccessTool:
    def test_success_tool(self):
        task = Task("choose 5", result_type=int)
        tool = task.get_success_tool()
        tool.run(input=dict(result=5))
        assert task.is_successful()
        assert task.result == 5

    def test_success_tool_with_list_of_options(self):
        task = Task('choose "good"', result_type=["bad", "good", "medium"])
        tool = task.get_success_tool()
        tool.run(input=dict(result=1))
        assert task.is_successful()
        assert task.result == "good"

    def test_success_tool_with_list_of_options_requires_int(self):
        task = Task('choose "good"', result_type=["bad", "good", "medium"])
        tool = task.get_success_tool()
        with pytest.raises(ValueError):
            tool.run(input=dict(result="good"))

    def test_tuple_of_ints_result(self):
        task = Task("choose 5", result_type=(4, 5, 6))
        tool = task.get_success_tool()
        tool.run(input=dict(result=1))
        assert task.result == 5

    def test_tuple_of_pydantic_models_result(self):
        class Person(BaseModel):
            name: str
            age: int

        task = Task(
            "Who is the oldest?",
            result_type=(Person(name="Alice", age=30), Person(name="Bob", age=35)),
        )
        tool = task.get_success_tool()
        tool.run(input=dict(result=1))
        assert task.result == Person(name="Bob", age=35)
        assert isinstance(task.result, Person)


class TestHandlers:
    class ExampleHandler(Handler):
        def __init__(self):
            self.events = []
            self.agent_messages = []

        def on_event(self, event: Event):
            self.events.append(event)

        def on_agent_message(self, event: AgentMessage):
            self.agent_messages.append(event)

    class AsyncExampleHandler(AsyncHandler):
        def __init__(self):
            self.events = []
            self.agent_messages = []

        async def on_event(self, event: Event):
            self.events.append(event)

        async def on_agent_message(self, event: AgentMessage):
            self.agent_messages.append(event)

    def test_task_run_with_handlers(self, default_fake_llm):
        handler = self.ExampleHandler()
        task = Task(objective="Calculate 2 + 2", result_type=int)
        task.run(handlers=[handler], max_llm_calls=1)

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1

    async def test_task_run_async_with_handlers(self, default_fake_llm):
        handler = self.ExampleHandler()
        task = Task(objective="Calculate 2 + 2", result_type=int)
        await task.run_async(handlers=[handler], max_llm_calls=1)

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1

    async def test_task_run_async_with_async_handlers(self, default_fake_llm):
        handler = self.AsyncExampleHandler()
        task = Task(objective="Calculate 2 + 2", result_type=int)
        await task.run_async(handlers=[handler], max_llm_calls=1)

        assert len(handler.events) > 0
        assert len(handler.agent_messages) == 1


class TestCompletionTools:
    def test_default_completion_tools(self):
        task = Task(objective="Test task")
        assert task.completion_tools is None
        tools = task.get_completion_tools()
        assert len(tools) == 2
        assert any(t.name == f"mark_task_{task.id}_successful" for t in tools)
        assert any(t.name == f"mark_task_{task.id}_failed" for t in tools)

    def test_only_succeed_tool(self):
        task = Task(objective="Test task", completion_tools=["SUCCEED"])
        tools = task.get_completion_tools()
        assert len(tools) == 1
        assert tools[0].name == f"mark_task_{task.id}_successful"

    def test_only_fail_tool(self):
        task = Task(objective="Test task", completion_tools=["FAIL"])
        tools = task.get_completion_tools()
        assert len(tools) == 1
        assert tools[0].name == f"mark_task_{task.id}_failed"

    def test_no_completion_tools(self):
        task = Task(objective="Test task", completion_tools=[])
        tools = task.get_completion_tools()
        assert len(tools) == 0

    def test_invalid_completion_tool(self):
        with pytest.raises(ValueError):
            Task(objective="Test task", completion_tools=["INVALID"])

    def test_manual_success_tool(self):
        task = Task(objective="Test task", completion_tools=[], result_type=int)
        success_tool = task.get_success_tool()
        success_tool.run(input=dict(result=5))
        assert task.is_successful()
        assert task.result == 5

    def test_manual_fail_tool(self):
        task = Task(objective="Test task", completion_tools=[])
        fail_tool = task.get_fail_tool()
        assert fail_tool.name == f"mark_task_{task.id}_failed"
        fail_tool.run(input=dict(reason="test error"))
        assert task.is_failed()
        assert task.result == "test error"

    def test_completion_tools_with_run(self):
        task = Task("Calculate 2 + 2", result_type=int, completion_tools=["SUCCEED"])
        result = task.run(max_llm_calls=1)
        assert result == 4
        assert task.is_successful()

    def test_no_completion_tools_with_run(self):
        task = Task("Calculate 2 + 2", result_type=int, completion_tools=[])
        task.run(max_llm_calls=1)
        assert task.is_incomplete()

    async def test_completion_tools_with_run_async(self):
        task = Task("Calculate 2 + 2", result_type=int, completion_tools=["SUCCEED"])
        result = await task.run_async(max_llm_calls=1)
        assert result == 4
        assert task.is_successful()

    async def test_no_completion_tools_with_run_async(self):
        task = Task("Calculate 2 + 2", result_type=int, completion_tools=[])
        await task.run_async(max_llm_calls=1)
        assert task.is_incomplete()



================================================
FILE: tests/tasks/test_validators.py
================================================
import pytest

from controlflow.tasks.validators import (
    between,
    chain,
    has_keys,
    has_len,
    is_email,
    is_url,
)


def test_chain():
    def add_one(x):
        return x + 1

    def multiply_by_two(x):
        return x * 2

    chained = chain(add_one, multiply_by_two)
    assert chained(3) == 8  # (3 + 1) * 2 = 8


def test_between():
    validator = between(min_value=0, max_value=10)
    assert validator(5) == 5
    with pytest.raises(ValueError):
        validator(-1)
    with pytest.raises(ValueError):
        validator(11)


def test_has_len():
    validator = has_len(min_length=2, max_length=5)
    assert validator([1, 2]) == [1, 2]
    assert validator("hello") == "hello"
    with pytest.raises(ValueError):
        validator([1])
    with pytest.raises(ValueError):
        validator([1, 2, 3, 4, 5, 6])


def test_is_email():
    validator = is_email()
    assert validator("user@example.com") == "user@example.com"
    with pytest.raises(ValueError):
        validator("not-an-email")


def test_is_url():
    validator = is_url()
    assert validator("https://www.example.com") == "https://www.example.com"
    with pytest.raises(ValueError):
        validator("not-a-url")


def test_has_keys():
    validator = has_keys({"name", "age"})
    assert validator({"name": "John", "age": 30}) == {"name": "John", "age": 30}
    with pytest.raises(ValueError):
        validator({"name": "John"})


def test_validators_with_task():
    from controlflow.tasks.task import Task

    task = Task(
        objective="Get a valid email between 10 and 30 characters",
        result_type=str,
        result_validator=chain(has_len(min_length=10, max_length=30), is_email()),
    )

    assert task.validate_result("user@example.com") == "user@example.com"

    with pytest.raises(ValueError):
        task.validate_result("not-an-email")

    with pytest.raises(ValueError):
        task.validate_result("u@ex.com")

    with pytest.raises(ValueError):
        task.validate_result("very.long.email.address@example.com")



================================================
FILE: tests/tools/test_lc_tools.py
================================================
from unittest.mock import MagicMock

from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import BaseTool
from pydantic import BaseModel

import controlflow
from controlflow.events.events import AIMessage, ToolCall


class LCBaseToolInput(BaseModel):
    x: int


class LCBaseTool(BaseTool):
    name: str = "TestTool"
    description: str = "A test tool"
    args_schema: type[BaseModel] = LCBaseToolInput

    def _run(self, x: int) -> str:
        return str(x)


def test_lc_base_tool(default_fake_llm, monkeypatch):
    events = [
        AIMessage(
            content="",
            tool_calls=[
                ToolCall(
                    id="abc",
                    name="TestTool",
                    args={"x": 3},
                )
            ],
        )
    ]
    default_fake_llm.set_responses(events)
    tool = LCBaseTool()
    mock_run = MagicMock(return_value="3")
    tool.__dict__.update(dict(_run=mock_run))
    task = controlflow.Task(
        "Use the tool",
        tools=[tool],
        result_type=str,
    )
    task.run(max_agent_turns=1)
    mock_run.assert_called()


def test_ddg_tool(default_fake_llm, monkeypatch):
    events = [
        AIMessage(
            content="",
            tool_calls=[
                ToolCall(
                    id="abc",
                    name="duckduckgo_search",
                    args={"query": "top business headlines"},
                )
            ],
        )
    ]
    default_fake_llm.set_responses(events)
    tool = DuckDuckGoSearchRun()
    mock_run = MagicMock(return_value=["headline 1", "headline 2"])
    tool.__dict__.update(dict(_run=mock_run))
    task = controlflow.Task(
        "Retrieve and summarize today's two top business headlines",
        tools=[tool],
        result_type=list[str],
    )
    task.run(max_agent_turns=1)
    mock_run.assert_called()



================================================
FILE: tests/tools/test_tools.py
================================================
import random
from typing import Annotated

import pytest
from pydantic import Field

import controlflow
from controlflow.agents.agent import Agent
from controlflow.llm.messages import ToolMessage
from controlflow.tools.tools import Tool, handle_tool_call, tool


@pytest.mark.parametrize("style", ["decorator", "class"])
class TestToolFunctions_DecoratorAndClass:
    def test_decorator(self, style):
        def roll_die():
            return 2

        if style == "class":
            roll_die_tool = Tool.from_function(roll_die)
        elif style == "decorator":
            roll_die_tool = tool(roll_die)

        assert roll_die_tool.run({}) == 2

    async def test_decorator_async(self, style):
        async def roll_die():
            return 2

        if style == "class":
            roll_die_tool = Tool.from_function(roll_die)
        elif style == "decorator":
            roll_die_tool = tool(roll_die)

        assert roll_die_tool.run({}) == 2

    def test_tool_does_not_require_docstring(self, style):
        def roll_die():
            return random.randint(1, 6)

        if style == "class":
            roll_die_tool = Tool.from_function(roll_die)
        elif style == "decorator":
            roll_die_tool = tool(roll_die)

        assert roll_die_tool.description == "(No description provided)"

    def test_tool_gets_docstring_from_description(self, style):
        def roll_die():
            """Roll a die."""
            return random.randint(1, 6)

        if style == "class":
            roll_die_tool = Tool.from_function(roll_die)
        elif style == "decorator":
            roll_die_tool = tool(roll_die)

        assert roll_die_tool.description == "Roll a die."

    def test_tool_gets_name_from_function_name(self, style):
        def roll_die():
            """Roll a die."""
            return random.randint(1, 6)

        if style == "class":
            roll_die_tool = Tool.from_function(roll_die)
        elif style == "decorator":
            roll_die_tool = tool(roll_die)

        assert roll_die_tool.name == "roll_die"

    def test_args_schema_types(self, style):
        def add(a: int, b: float, c):
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add)
        elif style == "decorator":
            add_tool = tool(add)

        assert add_tool.parameters["properties"]["a"]["type"] == "integer"
        assert add_tool.parameters["properties"]["b"]["type"] == "number"
        assert "type" not in add_tool.parameters["properties"]["c"]

    def test_load_param_description_from_annotated(self, style):
        def add(a: Annotated[int, "the first number"], b: float):
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add)
        elif style == "decorator":
            add_tool = tool(add)

        assert (
            add_tool.parameters["properties"]["a"]["description"] == "the first number"
        )
        assert "description" not in add_tool.parameters["properties"]["b"]

    def test_load_param_description_from_field(self, style):
        def add(a: int = Field(description="The first number."), b: float = None):
            return a

        if style == "class":
            add_tool = Tool.from_function(add)
        elif style == "decorator":
            add_tool = tool(add)

        assert (
            add_tool.parameters["properties"]["a"]["description"] == "The first number."
        )
        assert "description" not in add_tool.parameters["properties"]["b"]

    def test_disable_loading_param_descriptions(self, style):
        def add(a: Annotated[int, "the first number"], b: float):
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add, include_param_descriptions=False)
        elif style == "decorator":
            add_tool = tool(add, include_param_descriptions=False)

        assert "description" not in add_tool.parameters["properties"]["a"]

    def test_return_val_in_description(self, style):
        def add(a: int, b: float) -> Annotated[float, "the sum of a and b"]:
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add)
        elif style == "decorator":
            add_tool = tool(add)

        assert "the sum of a and b" in add_tool.description

    def test_disable_loading_return_val_descriptions(self, style):
        def add(a: int, b: float) -> Annotated[float, "the sum of a and b"]:
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add, include_return_description=False)
        elif style == "decorator":
            add_tool = tool(add, include_return_description=False)

        assert "description" not in add_tool.parameters["properties"]["a"]

    def test_tool_instructions(self, style):
        def add(a: int, b: float) -> float:
            return a + b

        if style == "class":
            add_tool = Tool.from_function(add, instructions="test instructions!")
        elif style == "decorator":
            add_tool = tool(add, instructions="test instructions!")

        assert add_tool.instructions == "test instructions!"

    def test_description_too_long(self, style):
        def add(a: int, b: float) -> float:
            pass

        add.__doc__ = ["a" for _ in range(1025)]

        with pytest.raises(ValueError, match="description exceeds 1024 characters"):
            if style == "class":
                Tool.from_function(add)
            elif style == "decorator":
                tool(add)

    def test_custom_parameters(self, style):
        """Test that custom parameters override generated ones."""

        def add(a: int, b: float):
            return a + b

        custom_params = {
            "type": "object",
            "properties": {
                "x": {"type": "number", "description": "Custom parameter"},
                "y": {"type": "string"},
            },
            "required": ["x"],
        }

        if style == "class":
            tool_obj = Tool.from_function(add, parameters=custom_params)
        elif style == "decorator":
            tool_obj = tool(add, parameters=custom_params)

        assert tool_obj.parameters == custom_params
        assert "a" not in tool_obj.parameters["properties"]
        assert "b" not in tool_obj.parameters["properties"]
        assert (
            tool_obj.parameters["properties"]["x"]["description"] == "Custom parameter"
        )

    def test_custom_parameters_with_annotations(self, style):
        """Test that annotations still work with custom parameters if param names match."""

        def process(x: Annotated[float, "The x value"], y: str):
            return x

        custom_params = {
            "type": "object",
            "properties": {"x": {"type": "number"}, "y": {"type": "string"}},
            "required": ["x"],
        }

        if style == "class":
            tool_obj = Tool.from_function(process, parameters=custom_params)
        elif style == "decorator":
            tool_obj = tool(process, parameters=custom_params)

        assert tool_obj.parameters["properties"]["x"]["description"] == "The x value"
        assert "description" not in tool_obj.parameters["properties"]["y"]

    def test_custom_parameters_ignore_descriptions(self, style):
        """Test that include_param_descriptions=False works with custom parameters."""

        def process(x: Annotated[float, "The x value"], y: str):
            return x

        custom_params = {
            "type": "object",
            "properties": {"x": {"type": "number"}, "y": {"type": "string"}},
            "required": ["x"],
        }

        if style == "class":
            tool_obj = Tool.from_function(
                process, parameters=custom_params, include_param_descriptions=False
            )
        elif style == "decorator":
            tool_obj = tool(
                process, parameters=custom_params, include_param_descriptions=False
            )

        assert "description" not in tool_obj.parameters["properties"]["x"]
        assert "description" not in tool_obj.parameters["properties"]["y"]


class TestToolFunctions:
    def test_non_serializable_return_value(self):
        class Foo:
            pass

        @tool
        def foo() -> Foo:
            """test fn"""
            pass

        assert foo.name == "foo"
        assert foo.description == "test fn"

    def test_non_serializable_arg(self):
        class Foo:
            pass

        with pytest.raises(ValueError, match="Could not generate a schema for tool"):

            @tool
            def foo(x: Foo) -> str:
                """test fn"""
                pass


class TestToolDecorator:
    def test_provide_name(self):
        @tool(name="roll_die")
        def foo():
            return 2

        assert foo.name == "roll_die"

    def test_provide_description(self):
        @tool(description="Roll a die.")
        def foo():
            return 2

        assert foo.description == "Roll a die."


class TestRunTools:
    def run_tool(self):
        @tool
        def foo():
            return 2

        assert foo.run({}) == 2

    async def run_tool_async(self):
        @tool
        async def foo():
            return 2

        assert foo.run({}) == 2

    def run_with_args(self):
        @tool
        def add(a: int, b: int):
            return a + b

        assert add.run({"a": 2, "b": 3}) == 5

    def invocation_error(self):
        @tool
        def foo():
            raise ValueError("This is an error.")

        with pytest.raises(ValueError):
            foo.run({})


class TestHandleTools:
    def handle_tool_call(self):
        @tool
        def foo():
            return 2

        tool_call = {"name": "foo", "args": {}}
        message = handle_tool_call(tool_call, tools=[foo])
        assert isinstance(message, ToolMessage)
        assert message.content == "2"
        assert message.tool_call_id == tool_call["id"]
        assert message.tool_call == tool_call
        assert message.tool_result == 2
        assert message.tool_metadata == {}

    def handle_tool_call_with_args(self):
        @tool
        def add(a: int, b: int):
            return a + b

        tool_call = {"name": "add", "args": {"a": 2, "b": 3}}
        message = handle_tool_call(tool_call, tools=[add])
        assert message.content == "5"

    def handle_tool_call_with_async_tool(self):
        @tool
        async def foo():
            return 2

        tool_call = {"name": "foo", "args": {}}
        message = handle_tool_call(tool_call, tools=[foo])
        assert message.content == "2"

    def handle_error(self):
        @tool
        def foo():
            raise ValueError("This is an error.")

        tool_call = {"name": "foo", "args": {}}
        message = handle_tool_call(tool_call, tools=[foo])
        assert message.content == 'Error calling function "foo": This is an error.'
        assert message.tool_metadata["is_failed"]

    def handle_invalid_tool_call(self):
        tool_call = {"name": "foo", "args": {}}
        message = handle_tool_call(tool_call, tools=[])
        assert message.content == 'Function "foo" not found.'
        assert message.tool_metadata["is_failed"]

    def handle_tool_call_with_agent_id(self):
        @tool
        def foo():
            return 2

        agent = Agent(name="test-agent")

        tool_call = {"name": "foo", "args": {}}
        message = handle_tool_call(tool_call, tools=[foo], agent=agent)
        assert message.agent.name == "test-agent"
        assert message.agent.id == agent.id


class TestToolAvailability:
    x = None

    def signal(self, x):
        """You must use this tool to complete the task"""
        self.x = x

    @pytest.fixture(autouse=True)
    def reset_signal(self):
        self.x = None
        yield
        self.x = None

    def test_agent_tool(self):
        """
        Tests that an agent can use a tool assigned to it
        """
        agent = Agent(tools=[self.signal])
        controlflow.run(
            "Use the signal tool with x=10", agents=[agent], max_llm_calls=1
        )
        assert self.x == 10

    def test_task_tool(self):
        """
        Tests that an agent can use a tool assigned to a task
        """
        agent = Agent(name="test-agent")
        controlflow.run(
            "Use the signal tool with x=10",
            agents=[agent],
            max_llm_calls=1,
            tools=[self.signal],
        )
        assert self.x == 10

    def test_flow_tool(self):
        """
        Tests that an agent can use a tool assigned to a flow
        """
        agent = Agent(name="test-agent")

        with controlflow.Flow(tools=[self.signal]):
            controlflow.run(
                "Use the signal tool with x=10", agents=[agent], max_llm_calls=1
            )
        assert self.x == 10



================================================
FILE: tests/utilities/__init__.py
================================================
[Empty file]


================================================
FILE: tests/utilities/test_general.py
================================================
import controlflow.utilities.general as general


class TestUnwrap:
    def test_unwrap(self):
        assert general.unwrap("Hello, world!") == "Hello, world!"
        assert (
            general.unwrap("Hello, world!\nThis is a test.")
            == "Hello, world! This is a test."
        )
        assert (
            general.unwrap("Hello, world!\nThis is a test.\n\nThis is another test.")
            == "Hello, world! This is a test.\n\nThis is another test."
        )

    def test_unwrap_with_empty_string(self):
        assert general.unwrap("") == ""

    def test_unwrap_with_multiple_newlines(self):
        assert general.unwrap("\n\n\n") == ""

    def test_unwrap_with_multiline_string(self):
        assert (
            general.unwrap("""
            Hello, world!
            This is a test.
            This is another test.
        """)
            == "Hello, world! This is a test. This is another test."
        )

    def test_unwrap_with_multiline_string_and_newlines(self):
        assert (
            general.unwrap("""
            Hello, world!
            This is a test.
            
            This is another test.
        """)
            == "Hello, world! This is a test.\n\nThis is another test."
        )



================================================
FILE: tests/utilities/test_testing.py
================================================
import controlflow
from controlflow.llm.messages import AIMessage
from controlflow.utilities.testing import record_events


def test_record_events_empty():
    with record_events() as events:
        pass
    assert events == []


def test_record_task_events(default_fake_llm):
    task = controlflow.Task("say hello", id="12345")

    response = AIMessage(
        id="run-2af8bb73-661f-4ec3-92ff-d7d8e3074926",
        name="Marvin",
        role="ai",
        content="",
        tool_calls=[
            {
                "name": "mark_task_12345_successful",
                "args": {"result": "Hello!"},
                "id": "call_ZEPdV8mCgeBe5UHjKzm6e3pe",
                "type": "tool_call",
            }
        ],
    )

    default_fake_llm.set_responses([response])
    with record_events() as events:
        task.run()

    assert events[0].event == "orchestrator-message"

    assert events[1].event == "agent-message"
    assert response == events[1].ai_message

    assert events[3].event == "tool-result"
    assert events[3].tool_result.tool_call == {
        "name": "mark_task_12345_successful",
        "args": {"result": "Hello!"},
        "id": "call_ZEPdV8mCgeBe5UHjKzm6e3pe",
        "type": "tool_call",
    }
    tool_result = events[3].tool_result.model_dump()
    assert tool_result["tool_call"]["id"] == "call_ZEPdV8mCgeBe5UHjKzm6e3pe"
    assert tool_result["str_result"] == 'Task #12345 ("say hello") marked successful.'
    assert not tool_result["is_error"]
    assert tool_result["tool"]["metadata"]["is_completion_tool"]
    assert tool_result["tool"]["metadata"]["is_success_tool"]



================================================
FILE: .github/ai-labeler.yml
================================================
labels:
  - bug
  - breaking change
  - documentation
  - feature
  - enhancement
  - question
  - example
  - good first issue
  - tests
  - ignore in release notes:
    description: "Ignore this PR in release notes"
    instructions: |
      Administrative changes that don't need to be mentioned in release notes,
      such as CI configuration changes. Small changes, including typos, SHOULD
      be kept in the release notes; only changes that aren't relevant to
      behavior should be ignored.



================================================
FILE: .github/labeler.yml
================================================
documentation:
  - changed-files:
      - any-glob-to-any-file: "docs/**"

example:
  - changed-files:
      - any-glob-to-any-file:
          - "examples/**"
          - "docs/examples/**"

tests:
  - changed-files:
      - any-glob-to-any-file: "tests/**"



================================================
FILE: .github/release.yml
================================================
changelog:
  exclude:
    labels:
      - ignore in release notes

  categories:
    - title: New Features 🎉
      labels:
        - feature
        - enhancement
      exclude:
        labels:
          - breaking change

    - title: Fixes 🐞
      labels:
        - bug
      exclude:
        labels:
          - breaking change

    - title: Breaking Changes 🛫
      labels:
        - breaking change

    - title: Docs 📚
      labels:
        - documentation

    - title: Other Changes 🦾
      labels:
        - "*"



================================================
FILE: .github/ISSUE_TEMPLATE/bug.yml
================================================
name: 🐛 Bug Report
description: Report a bug or unexpected behavior in ControlFlow
labels: [bug, pending]

body:
  - type: markdown
    attributes:
      value: Thank you for contributing to ControlFlow! 🙏

  - type: textarea
    id: description
    attributes:
      label: Description
      description: |
        Please explain what you're experiencing and what you would expect to happen instead.

        Provide as much detail as possible to help us understand and solve your problem quickly.
    validations:
      required: true

  - type: textarea
    id: example
    attributes:
      label: Example Code
      description: >
        If applicable, please provide a self-contained,
        [minimal, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example)
        demonstrating the bug.

      placeholder: |
        import controlflow as cf

        ...
      render: Python

  - type: textarea
    id: version
    attributes:
      label: Version Information
      description: |
        Please provide information about your ControlFlow version, Prefect version, Python version, and OS.

        To get this information, run the following command in your terminal and paste the output below:

        ```bash
        controlflow version
        ```

        If there is other information that would be helpful, such as LLM provider, model, or package version, please include it as well.
      render: Text
    validations:
      required: true

  - type: textarea
    id: additional_context
    attributes:
      label: Additional Context
      description: |
        Add any other context about the problem here. This could include:
        - The full error message and traceback (if applicable)
        - Information about your environment (e.g., virtual environment, installed packages)
        - Steps to reproduce the issue
        - Any recent changes in your code or setup that might be relevant



================================================
FILE: .github/ISSUE_TEMPLATE/enhancement.yml
================================================
name: 💡 Enhancement Request
description: Suggest an idea or improvement for ControlFlow
labels: [enhancement, pending]

body:
  - type: markdown
    attributes:
      value: Thank you for contributing to ControlFlow! We value your ideas for improving the framework. 💡

  - type: textarea
    id: description
    attributes:
      label: Enhancement Description
      description: |
        Please describe the enhancement you'd like to see in ControlFlow.

        - What problem would this solve?
        - How would this improve your workflow or experience with ControlFlow?
        - Are there any alternative solutions you've considered?
    validations:
      required: true

  - type: textarea
    id: use_case
    attributes:
      label: Use Case
      description: |
        Describe a specific use case or scenario where this enhancement would be beneficial.
        If possible, provide an example of how you envision using this feature.

  - type: textarea
    id: example
    attributes:
      label: Proposed Implementation
      description: >
        If you have ideas about how this enhancement could be implemented,
        please share them here. Code snippets, pseudocode, or general approaches are welcome.
      render: Python



================================================
FILE: .github/workflows/ai-labeler.yml
================================================
name: AI Labeler

on:
  issues:
    types: [opened, reopened]
  pull_request:
    types: [opened, reopened]

jobs:
  ai-labeler:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
      - uses: jlowin/ai-labeler@v0.4.0
        with:
          include-repo-labels: true
          openai-api-key: ${{ secrets.OPENAI_API_KEY }}



================================================
FILE: .github/workflows/codeql.yml
================================================
# For most projects, this workflow file will not need changing; you simply need
# to commit it to your repository.
#
# You may wish to alter this file to override the set of languages analyzed,
# or to provide custom queries or build logic.
#
# ******** NOTE ********
# We have attempted to detect the languages in your repository. Please check
# the `language` matrix defined below to confirm you have the correct set of
# supported CodeQL languages.
#
name: "CodeQL"

on:
  push:
    branches: [ "main" ]
  schedule:
    - cron: '0 0 * * 0'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        - language: python
          build-mode: none
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"



================================================
FILE: .github/workflows/labeler.yml
================================================
name: "Pull Request Labeler"
on:
  - pull_request_target

jobs:
  labeler:
    permissions:
      contents: read
      pull-requests: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/labeler@v5



================================================
FILE: .github/workflows/publish-pypi.yml
================================================
name: Publish ControlFlow to PyPI
on:
  release:
    types: [published]
  workflow_dispatch:

jobs:
  publish-pypi-release:
    runs-on: ubuntu-latest
    environment: release
    permissions:
      contents: write
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: "**/pyproject.toml"
      - name: Install dependencies
        run: |
          pip install setuptools wheel build
      - name: Build
        run: |
          python -m build
      - name: Publish
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          verbose: true



================================================
FILE: .github/workflows/run-tests.yml
================================================
name: Run tests

env:
  # enable colored output
  # https://github.com/pytest-dev/pytest/issues/7443
  PY_COLORS: 1

on:
  push:
    branches: ["main"]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

jobs:
  run_tests:
    name: Python ${{ matrix.python-version }} on ${{ matrix.os }}
    timeout-minutes: 15
    strategy:
      matrix:
        # os: [ubuntu-latest, macos-latest, windows-latest]
        os: [ubuntu-latest]
        # python-version: ['3.9', '3.10', '3.11', '3.12']
        python-version: ["3.9", "3.12"]

    runs-on: ${{ matrix.os }}

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: download uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Install ControlFlow
        run: uv pip install --system ".[tests]"

      - name: Run tests
        run: pytest -vv
        if: ${{ !(github.event.pull_request.head.repo.fork) }}



================================================
FILE: .github/workflows/static-analysis.yml
================================================
name: Run static analysis

env:
  # enable colored output
  # https://github.com/pytest-dev/pytest/issues/7443
  PY_COLORS: 1

on:
  push:
    branches: ["main"]
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

jobs:

  static_analysis:
    timeout-minutes: 1

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.9"
      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1


